EXPRESSION_DATA = [
  {
    "checksum": "d84942130f9286958315563597a1bf2d1c3a97a551c830d48183669d7723b374",
    "created": "2022-05-17T11:31:02.650177+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:31:40.795246+0000",
    "id": 409764,
    "modified": "2022-05-17T11:31:04.007470+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r7_hr24_rc.tab.gz",
        "size": 51361,
        "total_size": 51361
      },
      "exp": {
        "file": "AX4_r7_hr24_rpkum_polya.tab.gz",
        "size": 117159,
        "total_size": 117159
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r7_hr24_rc_expressions.txt.gz",
        "size": 181847,
        "total_size": 181847
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488925,
      "exp_type": "polyA",
      "exp_set_json": 488927,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:31:03.481180+0000",
    "size": 2069844,
    "started": "2022-05-17T11:31:23.207470+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r7_hr24_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faf016b13390b7dcd3b4a/AX4_r7_hr24_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T113101Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=66554c074f2268d543c605622b2cf1e72d05820fa28045a98f389eaa62254184"
      },
      "exp": {
        "file": "AX4_r7_hr24_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faf016b13390b7dcd3b4a/AX4_r7_hr24_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T113102Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=f3e0f9d4eda3d1c58699e75ac68ea0efc7af613f50d44e04484d97279daa06d2"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r7_hr24",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:31:02.839336+0000",
      "duplicated": None,
      "id": 73070,
      "modified": "2022-05-17T11:31:04.461576+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r7_hr24",
      "settings": {

      },
      "slug": "ax4_r7_hr24",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r7_hr24",
    "slug": "ax4_r7_hr24",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "a507d4ff35fcbca5fea546da5b62860a53c5fbfed40a8b3837cf7e1603189b03",
    "created": "2022-05-17T11:30:59.011716+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:31:36.146322+0000",
    "id": 409763,
    "modified": "2022-05-17T11:31:00.572680+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r7_hr20_rc.tab.gz",
        "size": 51035,
        "total_size": 51035
      },
      "exp": {
        "file": "AX4_r7_hr20_rpkum_polya.tab.gz",
        "size": 116683,
        "total_size": 116683
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r7_hr20_rc_expressions.txt.gz",
        "size": 181045,
        "total_size": 181045
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488919,
      "exp_type": "polyA",
      "exp_set_json": 488921,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:31:00.100973+0000",
    "size": 2066845,
    "started": "2022-05-17T11:31:15.248358+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r7_hr20_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faf016b13390b7dcd3b49/AX4_r7_hr20_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T113058Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=c20ad882dada4bdd7758ac570b6dc208e114ff30b008a6ba812641a59dba7078"
      },
      "exp": {
        "file": "AX4_r7_hr20_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faf016b13390b7dcd3b49/AX4_r7_hr20_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T113058Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=ee9be719aa4d3343409235ed43144d038819900e6cd70c2ac00c8e9f0bb044a9"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r7_hr20",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:30:59.160694+0000",
      "duplicated": None,
      "id": 73069,
      "modified": "2022-05-17T11:31:01.049173+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r7_hr20",
      "settings": {

      },
      "slug": "ax4_r7_hr20",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r7_hr20",
    "slug": "ax4_r7_hr20",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "7c54650b3d98a18eaa48617cbbd7839cad1f0212129dee2c698fb1b6d70849c3",
    "created": "2022-05-17T11:30:56.025703+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:31:36.846695+0000",
    "id": 409762,
    "modified": "2022-05-17T11:30:57.152497+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r7_hr16_rc.tab.gz",
        "size": 51617,
        "total_size": 51617
      },
      "exp": {
        "file": "AX4_r7_hr16_rpkum_polya.tab.gz",
        "size": 116843,
        "total_size": 116843
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r7_hr16_rc_expressions.txt.gz",
        "size": 181741,
        "total_size": 181741
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488920,
      "exp_type": "polyA",
      "exp_set_json": 488923,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:30:56.850959+0000",
    "size": 2068421,
    "started": "2022-05-17T11:31:15.947539+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r7_hr16_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faf016b13390b7dcd3b47/AX4_r7_hr16_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T113055Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=2c291b81e5166cd7d0978b10cbb7b93276812da83055505e9d3e75d12561bb31"
      },
      "exp": {
        "file": "AX4_r7_hr16_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faf016b13390b7dcd3b47/AX4_r7_hr16_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T113055Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=e1814850ec850986b1ec2e45a0f439e3ff30d09f785a9f7f30bda6292f5defe7"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r7_hr16",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:30:56.225456+0000",
      "duplicated": None,
      "id": 73068,
      "modified": "2022-05-17T11:30:57.540401+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r7_hr16",
      "settings": {

      },
      "slug": "ax4_r7_hr16",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r7_hr16",
    "slug": "ax4_r7_hr16",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "c1d5badb390208350ed53ace6c6ba5176987a116282317156241a3a25bb1704b",
    "created": "2022-05-17T11:30:52.874312+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:31:29.211933+0000",
    "id": 409761,
    "modified": "2022-05-17T11:30:54.039269+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r7_hr12_rc.tab.gz",
        "size": 50796,
        "total_size": 50796
      },
      "exp": {
        "file": "AX4_r7_hr12_rpkum_polya.tab.gz",
        "size": 115658,
        "total_size": 115658
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r7_hr12_rc_expressions.txt.gz",
        "size": 179646,
        "total_size": 179646
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488913,
      "exp_type": "polyA",
      "exp_set_json": 488914,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:30:53.751769+0000",
    "size": 2060130,
    "started": "2022-05-17T11:31:08.305795+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r7_hr12_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faf016b13390b7dcd3b48/AX4_r7_hr12_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T113052Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=c616af9dcdcf7092970fc2cce8c5c0bc08f68c5d4e0784d91c308ad00c5d5354"
      },
      "exp": {
        "file": "AX4_r7_hr12_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faf016b13390b7dcd3b48/AX4_r7_hr12_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T113052Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=6a2d12c0762864462e8869fb11dd636def13422c26f4f6a0b09cdb254af6db10"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r7_hr12",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:30:53.119632+0000",
      "duplicated": None,
      "id": 73067,
      "modified": "2022-05-17T11:30:54.412503+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r7_hr12",
      "settings": {

      },
      "slug": "ax4_r7_hr12",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r7_hr12",
    "slug": "ax4_r7_hr12",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "f5d173780d8ad75c1a37a03e1145e5cbea4e0c1cb31adc7dd4c3c7de42f348a3",
    "created": "2022-05-17T11:30:49.510908+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:31:37.760450+0000",
    "id": 409760,
    "modified": "2022-05-17T11:30:50.809138+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r7_hr08_rc.tab.gz",
        "size": 51026,
        "total_size": 51026
      },
      "exp": {
        "file": "AX4_r7_hr08_rpkum_polya.tab.gz",
        "size": 114075,
        "total_size": 114075
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r7_hr08_rc_expressions.txt.gz",
        "size": 178269,
        "total_size": 178269
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488922,
      "exp_type": "polyA",
      "exp_set_json": 488924,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:30:50.497501+0000",
    "size": 2052453,
    "started": "2022-05-17T11:31:17.228987+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r7_hr08_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faf006b13390b7dcd3b46/AX4_r7_hr08_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T113048Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=89de03f462c801da21c5897d48b761a99f4df7c4ab2fcdf671633df42995232d"
      },
      "exp": {
        "file": "AX4_r7_hr08_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faf006b13390b7dcd3b46/AX4_r7_hr08_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T113048Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=9366d99b3607ec94829e2cc510e660a93cf2ecdfdbc8e67b746cedcaa89dee22"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r7_hr08",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:30:49.759844+0000",
      "duplicated": None,
      "id": 73066,
      "modified": "2022-05-17T11:30:51.296121+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r7_hr08",
      "settings": {

      },
      "slug": "ax4_r7_hr08",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r7_hr08",
    "slug": "ax4_r7_hr08",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "f6c3989c24414859bf59028190f3064bfcd0364a62769e9caaa38397fdcda292",
    "created": "2022-05-17T11:30:46.394509+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:31:34.064085+0000",
    "id": 409759,
    "modified": "2022-05-17T11:30:47.429978+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r7_hr06_rc.tab.gz",
        "size": 51112,
        "total_size": 51112
      },
      "exp": {
        "file": "AX4_r7_hr06_rpkum_polya.tab.gz",
        "size": 114561,
        "total_size": 114561
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r7_hr06_rc_expressions.txt.gz",
        "size": 178682,
        "total_size": 178682
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488917,
      "exp_type": "polyA",
      "exp_set_json": 488918,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:30:47.151529+0000",
    "size": 2055924,
    "started": "2022-05-17T11:31:13.870648+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r7_hr06_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faf006b13390b7dcd3b45/AX4_r7_hr06_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T113045Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=4db59794723cee771d4316d4563dcabf316d2e091fcfc4922078269b6695efd4"
      },
      "exp": {
        "file": "AX4_r7_hr06_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faf006b13390b7dcd3b45/AX4_r7_hr06_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T113045Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=ac5ba68a02ff37214d2e0805464e3058ba8c735b806a47c93f1233bf0d5abb82"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r7_hr06",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:30:46.538096+0000",
      "duplicated": None,
      "id": 73065,
      "modified": "2022-05-17T11:30:47.889840+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r7_hr06",
      "settings": {

      },
      "slug": "ax4_r7_hr06",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r7_hr06",
    "slug": "ax4_r7_hr06",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "c1f14da530bf72112a5c17c2028ebe1a23c27a5046b4308b07086661af75cac0",
    "created": "2022-05-17T11:30:42.784697+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:31:30.976024+0000",
    "id": 409758,
    "modified": "2022-05-17T11:30:44.360103+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r7_hr05_rc.tab.gz",
        "size": 50456,
        "total_size": 50456
      },
      "exp": {
        "file": "AX4_r7_hr05_rpkum_polya.tab.gz",
        "size": 112942,
        "total_size": 112942
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r7_hr05_rc_expressions.txt.gz",
        "size": 176330,
        "total_size": 176330
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488915,
      "exp_type": "polyA",
      "exp_set_json": 488916,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:30:44.132934+0000",
    "size": 2043895,
    "started": "2022-05-17T11:31:10.786195+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r7_hr05_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faf006b13390b7dcd3b44/AX4_r7_hr05_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T113042Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=8f20e679ad02d90b87e8160c1c181f0d75f84b09d3224fb73deb7d85a213214d"
      },
      "exp": {
        "file": "AX4_r7_hr05_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faf006b13390b7dcd3b44/AX4_r7_hr05_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T113042Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=4018a1a271aef224332f04072a1ed63b2dc8c402ee8ed1d9fd2668aac7dd0b13"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r7_hr05",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:30:43.068223+0000",
      "duplicated": None,
      "id": 73064,
      "modified": "2022-05-17T11:30:44.783195+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r7_hr05",
      "settings": {

      },
      "slug": "ax4_r7_hr05",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r7_hr05",
    "slug": "ax4_r7_hr05",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "e1d669c0d8a7ad8bb2970c417dc871d94d1435922b05f9310c7acc442c7310c1",
    "created": "2022-05-17T11:30:39.589224+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:31:41.660697+0000",
    "id": 409757,
    "modified": "2022-05-17T11:30:40.817258+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r7_hr04_rc.tab.gz",
        "size": 49348,
        "total_size": 49348
      },
      "exp": {
        "file": "AX4_r7_hr04_rpkum_polya.tab.gz",
        "size": 111413,
        "total_size": 111413
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r7_hr04_rc_expressions.txt.gz",
        "size": 173982,
        "total_size": 173982
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488926,
      "exp_type": "polyA",
      "exp_set_json": 488928,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:30:40.549791+0000",
    "size": 2034075,
    "started": "2022-05-17T11:31:23.640542+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r7_hr04_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faf006b133999c2cd3b32/AX4_r7_hr04_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T113038Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=ac4d021cb39312dfc530e5eaf8e0f6506b8972decaaeff635d05f0e26208e551"
      },
      "exp": {
        "file": "AX4_r7_hr04_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faf006b133999c2cd3b32/AX4_r7_hr04_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T113038Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=a787e6b83bff2233db209f0d429147f21b9819711c8592f4d236c308963debb4"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r7_hr04",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:30:39.794455+0000",
      "duplicated": None,
      "id": 73063,
      "modified": "2022-05-17T11:30:41.286472+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r7_hr04",
      "settings": {

      },
      "slug": "ax4_r7_hr04",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r7_hr04",
    "slug": "ax4_r7_hr04",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "4e935a8b3df6410140ea6ecd82b9e6454751155b6d3e77123f0d34e9fa60b8c9",
    "created": "2022-05-17T11:30:35.562845+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:31:10.807753+0000",
    "id": 409756,
    "modified": "2022-05-17T11:30:36.755095+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r7_hr03_rc.tab.gz",
        "size": 51263,
        "total_size": 51263
      },
      "exp": {
        "file": "AX4_r7_hr03_rpkum_polya.tab.gz",
        "size": 114130,
        "total_size": 114130
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r7_hr03_rc_expressions.txt.gz",
        "size": 178237,
        "total_size": 178237
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488905,
      "exp_type": "polyA",
      "exp_set_json": 488906,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:30:36.440180+0000",
    "size": 2052872,
    "started": "2022-05-17T11:30:55.315346+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r7_hr03_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faf006b133999c2cd3b33/AX4_r7_hr03_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T113034Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=04d87916cd3d751e5bff37554159e005c3a03a77118af1c0da79dede63a38f90"
      },
      "exp": {
        "file": "AX4_r7_hr03_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faf006b133999c2cd3b33/AX4_r7_hr03_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T113034Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=024243b1529f3b273e09b9c8f9d6d2fa34f02eb88ba53a9b0fc593b6b1cc9778"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r7_hr03",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:30:35.706662+0000",
      "duplicated": None,
      "id": 73062,
      "modified": "2022-05-17T11:30:37.447254+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r7_hr03",
      "settings": {

      },
      "slug": "ax4_r7_hr03",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r7_hr03",
    "slug": "ax4_r7_hr03",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "f22e95a91452e792b75d9124c5cce09eede504033fc5d14378f3f18d3cb8ccc0",
    "created": "2022-05-17T11:30:32.281447+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:31:21.096307+0000",
    "id": 409755,
    "modified": "2022-05-17T11:30:33.397886+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r7_hr02_rc.tab.gz",
        "size": 51182,
        "total_size": 51182
      },
      "exp": {
        "file": "AX4_r7_hr02_rpkum_polya.tab.gz",
        "size": 114420,
        "total_size": 114420
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r7_hr02_rc_expressions.txt.gz",
        "size": 178458,
        "total_size": 178458
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488909,
      "exp_type": "polyA",
      "exp_set_json": 488910,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:30:33.306654+0000",
    "size": 2053128,
    "started": "2022-05-17T11:31:05.445430+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r7_hr02_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faf006b13390b7dcd3b41/AX4_r7_hr02_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T113031Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=0be4dfb0052e2744246a839e012461c74875a15c426947473ac8fbf57b99dbff"
      },
      "exp": {
        "file": "AX4_r7_hr02_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faf006b13390b7dcd3b41/AX4_r7_hr02_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T113031Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=8bc1a1196c3a082a39665cd310625785caf9141d6f3b3a2dab367430995aa5cd"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r7_hr02",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:30:32.434211+0000",
      "duplicated": None,
      "id": 73061,
      "modified": "2022-05-17T11:30:33.813182+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r7_hr02",
      "settings": {

      },
      "slug": "ax4_r7_hr02",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r7_hr02",
    "slug": "ax4_r7_hr02",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "14aad47d7f35594620c8784e7679c72e7078ef5787a3a3f6a3e37d1d80f9a45d",
    "created": "2022-05-17T11:30:29.121289+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:30:59.248786+0000",
    "id": 409754,
    "modified": "2022-05-17T11:30:30.367393+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r7_hr01_rc.tab.gz",
        "size": 50882,
        "total_size": 50882
      },
      "exp": {
        "file": "AX4_r7_hr01_rpkum_polya.tab.gz",
        "size": 113879,
        "total_size": 113879
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r7_hr01_rc_expressions.txt.gz",
        "size": 177805,
        "total_size": 177805
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488901,
      "exp_type": "polyA",
      "exp_set_json": 488902,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:30:30.049366+0000",
    "size": 2051045,
    "started": "2022-05-17T11:30:44.753289+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r7_hr01_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faf006b13390b7dcd3b43/AX4_r7_hr01_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T113028Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=9e877c6d0d51567a93037c4b360fe54c9279a687c987c384ad1446c2552014f3"
      },
      "exp": {
        "file": "AX4_r7_hr01_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faf006b13390b7dcd3b43/AX4_r7_hr01_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T113028Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=bc8f3b3462bea592b9448aaf35cf5866695119f1ecc2d615ec359a25557e70a5"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r7_hr01",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:30:29.263601+0000",
      "duplicated": None,
      "id": 73060,
      "modified": "2022-05-17T11:30:30.869859+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r7_hr01",
      "settings": {

      },
      "slug": "ax4_r7_hr01",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r7_hr01",
    "slug": "ax4_r7_hr01",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "938cf63b376a15c991802e9298a119609fdddf7156f4bd651610d65da8875e5a",
    "created": "2022-05-17T11:30:25.571296+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:31:07.724950+0000",
    "id": 409753,
    "modified": "2022-05-17T11:30:27.047482+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r7_hr00_rc.tab.gz",
        "size": 51727,
        "total_size": 51727
      },
      "exp": {
        "file": "AX4_r7_hr00_rpkum_polya.tab.gz",
        "size": 114374,
        "total_size": 114374
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r7_hr00_rc_expressions.txt.gz",
        "size": 179039,
        "total_size": 179039
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488903,
      "exp_type": "polyA",
      "exp_set_json": 488904,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:30:26.666566+0000",
    "size": 2054576,
    "started": "2022-05-17T11:30:53.391836+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r7_hr00_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faf006b13390b7dcd3b42/AX4_r7_hr00_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T113024Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=6bfbcb9779ba492a174c2f57bfaf1919ea71f0b6c7e33995e7e9adf4f431ad12"
      },
      "exp": {
        "file": "AX4_r7_hr00_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faf006b13390b7dcd3b42/AX4_r7_hr00_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T113024Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=8669a1dc5cc9238e56387ce6879774ada02548c7d46a8fc903f25d445816d116"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r7_hr00",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:30:25.739530+0000",
      "duplicated": None,
      "id": 73059,
      "modified": "2022-05-17T11:30:27.509936+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r7_hr00",
      "settings": {

      },
      "slug": "ax4_r7_hr00",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r7_hr00",
    "slug": "ax4_r7_hr00",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "277d090a9ea5e8e098d6ace306fa52d083b9c837dbbe5aca892c0925e24e3637",
    "created": "2022-05-17T11:30:22.421411+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:31:27.046877+0000",
    "id": 409752,
    "modified": "2022-05-17T11:30:23.690267+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r6_hr24_rc.tab.gz",
        "size": 50281,
        "total_size": 50281
      },
      "exp": {
        "file": "AX4_r6_hr24_rpkum_polya.tab.gz",
        "size": 115736,
        "total_size": 115736
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r6_hr24_rc_expressions.txt.gz",
        "size": 179455,
        "total_size": 179455
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488911,
      "exp_type": "polyA",
      "exp_set_json": 488912,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:30:23.367161+0000",
    "size": 2058163,
    "started": "2022-05-17T11:31:06.363885+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r6_hr24_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faeac6b13390b7dcd3b40/AX4_r6_hr24_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T113021Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=9a18e048f6242010e9fbbaa4f02ed7af516ca45729cf385942dadee408a7f056"
      },
      "exp": {
        "file": "AX4_r6_hr24_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faeac6b13390b7dcd3b40/AX4_r6_hr24_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T113021Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=5b3e802979c4eae64cfe46ec4f09ffa20ec1ad924b032aa29e1b6c5e8739fafb"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r6_hr24",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:30:22.670420+0000",
      "duplicated": None,
      "id": 73058,
      "modified": "2022-05-17T11:30:24.120885+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r6_hr24",
      "settings": {

      },
      "slug": "ax4_r6_hr24",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r6_hr24",
    "slug": "ax4_r6_hr24",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "79c31896f0b166cb29816f20aa1d964fd243ff28e35fe031362451d301b7f4ff",
    "created": "2022-05-17T11:30:18.167966+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:30:49.624497+0000",
    "id": 409751,
    "modified": "2022-05-17T11:30:20.148788+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r6_hr20_rc.tab.gz",
        "size": 49593,
        "total_size": 49593
      },
      "exp": {
        "file": "AX4_r6_hr20_rpkum_polya.tab.gz",
        "size": 114968,
        "total_size": 114968
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r6_hr20_rc_expressions.txt.gz",
        "size": 178008,
        "total_size": 178008
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488899,
      "exp_type": "polyA",
      "exp_set_json": 488900,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:30:19.539982+0000",
    "size": 2052736,
    "started": "2022-05-17T11:30:34.382495+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r6_hr20_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faeab6b13390b7dcd3b3f/AX4_r6_hr20_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T113017Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=6e8e091321c57e4f8855b3df9ea1f71f958eb02d23a87f715da9144982ada520"
      },
      "exp": {
        "file": "AX4_r6_hr20_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faeab6b13390b7dcd3b3f/AX4_r6_hr20_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T113017Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=99c3af7a109eaa460f3745493a816c0d7da07d19b1f8d57c84d914ccbe10e508"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r6_hr20",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:30:18.500723+0000",
      "duplicated": None,
      "id": 73057,
      "modified": "2022-05-17T11:30:20.733477+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r6_hr20",
      "settings": {

      },
      "slug": "ax4_r6_hr20",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r6_hr20",
    "slug": "ax4_r6_hr20",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "91d385f86c2376319d7c195b4694012286a98576d7a473e9ed138412350fa961",
    "created": "2022-05-17T11:30:13.761647+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:31:14.907536+0000",
    "id": 409750,
    "modified": "2022-05-17T11:30:15.859125+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r6_hr16_rc.tab.gz",
        "size": 49756,
        "total_size": 49756
      },
      "exp": {
        "file": "AX4_r6_hr16_rpkum_polya.tab.gz",
        "size": 114813,
        "total_size": 114813
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r6_hr16_rc_expressions.txt.gz",
        "size": 177864,
        "total_size": 177864
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488907,
      "exp_type": "polyA",
      "exp_set_json": 488908,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:30:16.383880+0000",
    "size": 2051602,
    "started": "2022-05-17T11:30:59.289801+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r6_hr16_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faeab6b13390b7dcd3b3e/AX4_r6_hr16_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T113012Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=0e0c4b8cda52a345afbf381d801de5e40c54918ade9e49cac499c585b2319683"
      },
      "exp": {
        "file": "AX4_r6_hr16_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faeab6b13390b7dcd3b3e/AX4_r6_hr16_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T113013Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=ea97282c0bd2b3bdc7fe4b76f350d397d5e33ecc9f4d59f8617b6b5bf52278cf"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r6_hr16",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:30:14.260316+0000",
      "duplicated": None,
      "id": 73056,
      "modified": "2022-05-17T11:30:16.344136+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r6_hr16",
      "settings": {

      },
      "slug": "ax4_r6_hr16",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r6_hr16",
    "slug": "ax4_r6_hr16",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "5483843e032c5973b6c6324b84743fabb199b85548648bbecc11595ef1c4e900",
    "created": "2022-05-17T11:30:08.865630+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:30:46.164373+0000",
    "id": 409749,
    "modified": "2022-05-17T11:30:11.315132+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r6_hr12_rc.tab.gz",
        "size": 50247,
        "total_size": 50247
      },
      "exp": {
        "file": "AX4_r6_hr12_rpkum_polya.tab.gz",
        "size": 115332,
        "total_size": 115332
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r6_hr12_rc_expressions.txt.gz",
        "size": 178671,
        "total_size": 178671
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488897,
      "exp_type": "polyA",
      "exp_set_json": 488898,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:30:12.032030+0000",
    "size": 2054189,
    "started": "2022-05-17T11:30:30.839244+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r6_hr12_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faeab6b13390b7dcd3b3d/AX4_r6_hr12_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T113008Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d96ca8e4abf82f2b1664debab851ba610d0d299531c61c01ba481ca7493d4132"
      },
      "exp": {
        "file": "AX4_r6_hr12_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faeab6b13390b7dcd3b3d/AX4_r6_hr12_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T113008Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=539274926ab75df75a0bace45d37391ebff6a27468fcdf2c68035adafeda9f30"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r6_hr12",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:30:09.344199+0000",
      "duplicated": None,
      "id": 73055,
      "modified": "2022-05-17T11:30:11.961547+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r6_hr12",
      "settings": {

      },
      "slug": "ax4_r6_hr12",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r6_hr12",
    "slug": "ax4_r6_hr12",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "9b07c2d1fb711f16b582e5999ee3f342dcdff20d9ec71d1a4bcf6af1eebb6e5a",
    "created": "2022-05-17T11:30:04.441863+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:30:36.706079+0000",
    "id": 409748,
    "modified": "2022-05-17T11:30:06.451914+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r6_hr08_rc.tab.gz",
        "size": 50095,
        "total_size": 50095
      },
      "exp": {
        "file": "AX4_r6_hr08_rpkum_polya.tab.gz",
        "size": 113546,
        "total_size": 113546
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r6_hr08_rc_expressions.txt.gz",
        "size": 176604,
        "total_size": 176604
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488893,
      "exp_type": "polyA",
      "exp_set_json": 488894,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:30:06.356916+0000",
    "size": 2044785,
    "started": "2022-05-17T11:30:21.666446+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r6_hr08_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faeaa6b13390b7dcd3b3c/AX4_r6_hr08_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T113003Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=4351fc2d1cc8d1f9ab1b6db6aded44b5b774289cb48cc4adf51962b893b410ce"
      },
      "exp": {
        "file": "AX4_r6_hr08_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faeaa6b13390b7dcd3b3c/AX4_r6_hr08_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T113003Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=143b35c3a1778b8c1188fdd2e48e0032ca5f7e71723e197e760abc5fb9ca97ac"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r6_hr08",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:30:04.877858+0000",
      "duplicated": None,
      "id": 73054,
      "modified": "2022-05-17T11:30:07.154919+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r6_hr08",
      "settings": {

      },
      "slug": "ax4_r6_hr08",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r6_hr08",
    "slug": "ax4_r6_hr08",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "847850f375a8d5dcf1ee8a87efe64b926db7db22f83474a3445bf9451e8342b0",
    "created": "2022-05-17T11:29:59.642111+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:30:33.726441+0000",
    "id": 409747,
    "modified": "2022-05-17T11:30:01.965081+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r6_hr06_rc.tab.gz",
        "size": 49721,
        "total_size": 49721
      },
      "exp": {
        "file": "AX4_r6_hr06_rpkum_polya.tab.gz",
        "size": 112982,
        "total_size": 112982
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r6_hr06_rc_expressions.txt.gz",
        "size": 175665,
        "total_size": 175665
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488891,
      "exp_type": "polyA",
      "exp_set_json": 488892,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:30:02.864338+0000",
    "size": 2040901,
    "started": "2022-05-17T11:30:17.656204+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r6_hr06_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faeaa6b13390b7dcd3b3b/AX4_r6_hr06_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112958Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=08454e34041cb821f51104aa7ebf216f8780dafa72fe658e25fa7b6c9b299959"
      },
      "exp": {
        "file": "AX4_r6_hr06_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faeaa6b13390b7dcd3b3b/AX4_r6_hr06_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112958Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=c49b02ccbc8609cb175e02fe8da4201645eb1a3ce028bdd6c6ea51814c509806"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r6_hr06",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:30:00.301423+0000",
      "duplicated": None,
      "id": 73053,
      "modified": "2022-05-17T11:30:02.709745+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r6_hr06",
      "settings": {

      },
      "slug": "ax4_r6_hr06",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r6_hr06",
    "slug": "ax4_r6_hr06",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "ed95f435f02aeae3a84d13f804bd8a031845f8a0b0adfb31843e1f28ede820d7",
    "created": "2022-05-17T11:29:54.934803+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:30:42.787445+0000",
    "id": 409746,
    "modified": "2022-05-17T11:29:57.172909+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r6_hr05_rc.tab.gz",
        "size": 50127,
        "total_size": 50127
      },
      "exp": {
        "file": "AX4_r6_hr05_rpkum_polya.tab.gz",
        "size": 113683,
        "total_size": 113683
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r6_hr05_rc_expressions.txt.gz",
        "size": 176912,
        "total_size": 176912
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488895,
      "exp_type": "polyA",
      "exp_set_json": 488896,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:29:57.077556+0000",
    "size": 2046034,
    "started": "2022-05-17T11:30:27.088799+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r6_hr05_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faeaa6b13390b7dcd3b39/AX4_r6_hr05_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112954Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=f951ac16a1a0410bd7886494d452a00812a2ec90de9c0daef0e24599f953486f"
      },
      "exp": {
        "file": "AX4_r6_hr05_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faeaa6b13390b7dcd3b39/AX4_r6_hr05_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112954Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=b85dd77446aaae0d05b765f815431f5de3e2fee8dde4c81d0946b6f6b61a421d"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r6_hr05",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:29:55.292675+0000",
      "duplicated": None,
      "id": 73052,
      "modified": "2022-05-17T11:29:57.949724+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r6_hr05",
      "settings": {

      },
      "slug": "ax4_r6_hr05",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r6_hr05",
    "slug": "ax4_r6_hr05",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "7d290df4d1d9835dd243c2101acb123ba8ae12c83bc1fc1139baeba63b1360ef",
    "created": "2022-05-17T11:29:51.792607+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:30:28.291614+0000",
    "id": 409745,
    "modified": "2022-05-17T11:29:52.967835+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r6_hr04_rc.tab.gz",
        "size": 49697,
        "total_size": 49697
      },
      "exp": {
        "file": "AX4_r6_hr04_rpkum_polya.tab.gz",
        "size": 112081,
        "total_size": 112081
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r6_hr04_rc_expressions.txt.gz",
        "size": 174807,
        "total_size": 174807
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488889,
      "exp_type": "polyA",
      "exp_set_json": 488890,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:29:52.880887+0000",
    "size": 2036868,
    "started": "2022-05-17T11:30:11.843306+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r6_hr04_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faea96b133999c2cd3b30/AX4_r6_hr04_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112950Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=f5544832deef14742ea56c1390272a3099161876e542f0228193921ed81a56c9"
      },
      "exp": {
        "file": "AX4_r6_hr04_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faea96b133999c2cd3b30/AX4_r6_hr04_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112951Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=672a8c6bf8f3fb40fb7e8993bf793f34eba747944896bec669b885df8189655d"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r6_hr04",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:29:52.006120+0000",
      "duplicated": None,
      "id": 73051,
      "modified": "2022-05-17T11:29:53.367628+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r6_hr04",
      "settings": {

      },
      "slug": "ax4_r6_hr04",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r6_hr04",
    "slug": "ax4_r6_hr04",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "47f490aba25413800b8eb6b4d1b047e5f8ce4d01f497f1b68790cb7367f86085",
    "created": "2022-05-17T11:29:47.605778+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:30:24.973886+0000",
    "id": 409744,
    "modified": "2022-05-17T11:29:49.386036+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r6_hr03_rc.tab.gz",
        "size": 49728,
        "total_size": 49728
      },
      "exp": {
        "file": "AX4_r6_hr03_rpkum_polya.tab.gz",
        "size": 114092,
        "total_size": 114092
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r6_hr03_rc_expressions.txt.gz",
        "size": 176857,
        "total_size": 176857
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488887,
      "exp_type": "polyA",
      "exp_set_json": 488888,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:29:49.315934+0000",
    "size": 2046996,
    "started": "2022-05-17T11:30:05.182024+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r6_hr03_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faeaa6b13390b7dcd3b3a/AX4_r6_hr03_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112946Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=97ff1e76ae886e3e8082640b09cb187815674cd3707e4c7fa220386322dcdc12"
      },
      "exp": {
        "file": "AX4_r6_hr03_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faeaa6b13390b7dcd3b3a/AX4_r6_hr03_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112946Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=2a78faeb5e52809801cb4c2a4268aa3d5aa9a397ee359b6729b228d78b8fd73b"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r6_hr03",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:29:47.948953+0000",
      "duplicated": None,
      "id": 73050,
      "modified": "2022-05-17T11:29:50.061783+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r6_hr03",
      "settings": {

      },
      "slug": "ax4_r6_hr03",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r6_hr03",
    "slug": "ax4_r6_hr03",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "105d3a6becf29cdb6520c010a88c680194caf916da8eb706f3101fba81d4cd4a",
    "created": "2022-05-17T11:29:44.264062+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:30:23.083610+0000",
    "id": 409743,
    "modified": "2022-05-17T11:29:45.579016+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r6_hr02_rc.tab.gz",
        "size": 49314,
        "total_size": 49314
      },
      "exp": {
        "file": "AX4_r6_hr02_rpkum_polya.tab.gz",
        "size": 113301,
        "total_size": 113301
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r6_hr02_rc_expressions.txt.gz",
        "size": 175948,
        "total_size": 175948
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488883,
      "exp_type": "polyA",
      "exp_set_json": 488885,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:29:45.518722+0000",
    "size": 2043694,
    "started": "2022-05-17T11:30:00.655676+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r6_hr02_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faea96b133999c2cd3b31/AX4_r6_hr02_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112943Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=4cc19c3f0f3408f690993ed5a1ee3aa38b36b38d09d727d87580d47b4a7aeeec"
      },
      "exp": {
        "file": "AX4_r6_hr02_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faea96b133999c2cd3b31/AX4_r6_hr02_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112943Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=e243f46d3135c2df3cfb8d14f006c8b1e3561ec492f8ecc912746ad7c7e97cfc"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r6_hr02",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:29:44.418052+0000",
      "duplicated": None,
      "id": 73049,
      "modified": "2022-05-17T11:29:46.069276+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r6_hr02",
      "settings": {

      },
      "slug": "ax4_r6_hr02",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r6_hr02",
    "slug": "ax4_r6_hr02",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "60caaf60a152efd542de2394cef83763e57d04f1e9bd856925efd3ce2660206e",
    "created": "2022-05-17T11:29:40.087203+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:30:23.169531+0000",
    "id": 409742,
    "modified": "2022-05-17T11:29:41.797020+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r6_hr01_rc.tab.gz",
        "size": 48917,
        "total_size": 48917
      },
      "exp": {
        "file": "AX4_r6_hr01_rpkum_polya.tab.gz",
        "size": 112589,
        "total_size": 112589
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r6_hr01_rc_expressions.txt.gz",
        "size": 174574,
        "total_size": 174574
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488884,
      "exp_type": "polyA",
      "exp_set_json": 488886,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:29:41.446466+0000",
    "size": 2038176,
    "started": "2022-05-17T11:30:00.267285+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r6_hr01_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faeaa6b13390b7dcd3b38/AX4_r6_hr01_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112939Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=6a16d2ac5d6cc918a05435ecf82a72acb1632cf026714cbc5d20bf1f988186d7"
      },
      "exp": {
        "file": "AX4_r6_hr01_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faeaa6b13390b7dcd3b38/AX4_r6_hr01_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112939Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=07ed97f831c13e9ab51813e335aa4c3d0d24a2896a1ba8056fdbb01a9fd69a85"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r6_hr01",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:29:40.321241+0000",
      "duplicated": None,
      "id": 73048,
      "modified": "2022-05-17T11:29:42.677232+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r6_hr01",
      "settings": {

      },
      "slug": "ax4_r6_hr01",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r6_hr01",
    "slug": "ax4_r6_hr01",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "12324b613524d7c4170562eb6deabca7c8b27ecd61620354264f26966951a345",
    "created": "2022-05-17T11:29:36.634143+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:30:16.369310+0000",
    "id": 409741,
    "modified": "2022-05-17T11:29:38.005217+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r6_hr00_rc.tab.gz",
        "size": 49386,
        "total_size": 49386
      },
      "exp": {
        "file": "AX4_r6_hr00_rpkum_polya.tab.gz",
        "size": 112326,
        "total_size": 112326
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r6_hr00_rc_expressions.txt.gz",
        "size": 174746,
        "total_size": 174746
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488877,
      "exp_type": "polyA",
      "exp_set_json": 488879,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:29:37.598389+0000",
    "size": 2036790,
    "started": "2022-05-17T11:29:52.676417+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r6_hr00_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faeaa6b13390b7dcd3b37/AX4_r6_hr00_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112935Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=df0a27aa8268f6cb2fb09d20e2e5bc4931138702410dfe88c570d39d9728ae56"
      },
      "exp": {
        "file": "AX4_r6_hr00_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0faeaa6b13390b7dcd3b37/AX4_r6_hr00_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112936Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=3fb1f880745df712e4063a98757b8f3754ae45c413f75e32cc5579196471362a"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r6_hr00",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:29:36.797456+0000",
      "duplicated": None,
      "id": 73047,
      "modified": "2022-05-17T11:29:38.489785+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r6_hr00",
      "settings": {

      },
      "slug": "ax4_r6_hr00",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r6_hr00",
    "slug": "ax4_r6_hr00",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "968abfedfaf317cd4feb9f5a169e0d5ec2578e5786111b9859b35193df637556",
    "created": "2022-05-17T11:29:33.745112+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:30:17.382746+0000",
    "id": 409740,
    "modified": "2022-05-17T11:29:34.744623+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r5_hr24_rc.tab.gz",
        "size": 48594,
        "total_size": 48594
      },
      "exp": {
        "file": "AX4_r5_hr24_rpkum_polya.tab.gz",
        "size": 113682,
        "total_size": 113682
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r5_hr24_rc_expressions.txt.gz",
        "size": 175940,
        "total_size": 175940
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488878,
      "exp_type": "polyA",
      "exp_set_json": 488880,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:29:34.665846+0000",
    "size": 2045674,
    "started": "2022-05-17T11:29:54.104417+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r5_hr24_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fae0d6b13390b7dcd3b36/AX4_r5_hr24_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112933Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=8aaec9bd55e8217e30c8e1b052cd2b549a3e8c8b33ad5068d5c9b6ca70b00f56"
      },
      "exp": {
        "file": "AX4_r5_hr24_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fae0d6b13390b7dcd3b36/AX4_r5_hr24_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112933Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=5c6fb4e489221ca4ecd73654335ec56e3f4590628e4f89422c31deb0394431ae"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r5_hr24",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:29:33.897172+0000",
      "duplicated": None,
      "id": 73046,
      "modified": "2022-05-17T11:29:35.190000+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r5_hr24",
      "settings": {

      },
      "slug": "ax4_r5_hr24",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r5_hr24",
    "slug": "ax4_r5_hr24",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "a46f4e7f298cee7ca90b5d0ac66b43cec3b4cdf226165ee42ca848f7e65ddf8a",
    "created": "2022-05-17T11:29:30.238585+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:30:20.651815+0000",
    "id": 409739,
    "modified": "2022-05-17T11:29:31.700828+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r5_hr20_rc.tab.gz",
        "size": 48938,
        "total_size": 48938
      },
      "exp": {
        "file": "AX4_r5_hr20_rpkum_polya.tab.gz",
        "size": 113666,
        "total_size": 113666
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r5_hr20_rc_expressions.txt.gz",
        "size": 175946,
        "total_size": 175946
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488881,
      "exp_type": "polyA",
      "exp_set_json": 488882,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:29:31.584058+0000",
    "size": 2043746,
    "started": "2022-05-17T11:29:59.365180+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r5_hr20_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fae0c6b133999c2cd3b2f/AX4_r5_hr20_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112929Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=795ced1c7e24667bae605e71d33b93494568850e9a2108697ed46c9cc24ce9d2"
      },
      "exp": {
        "file": "AX4_r5_hr20_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fae0c6b133999c2cd3b2f/AX4_r5_hr20_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112929Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=70277e132141a174aaeab7ccd49da8b2dbebe64823cc7d08ac0cfa547e082674"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r5_hr20",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:29:30.484435+0000",
      "duplicated": None,
      "id": 73045,
      "modified": "2022-05-17T11:29:32.195858+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r5_hr20",
      "settings": {

      },
      "slug": "ax4_r5_hr20",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r5_hr20",
    "slug": "ax4_r5_hr20",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "72b9da525367f5d7d7b390f17f01b350159601e1b8d3e1958069b020faaaf714",
    "created": "2022-05-17T11:29:27.362474+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:30:08.877874+0000",
    "id": 409738,
    "modified": "2022-05-17T11:29:28.344900+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r5_hr16_rc.tab.gz",
        "size": 46070,
        "total_size": 46070
      },
      "exp": {
        "file": "AX4_r5_hr16_rpkum_polya.tab.gz",
        "size": 109732,
        "total_size": 109732
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r5_hr16_rc_expressions.txt.gz",
        "size": 169703,
        "total_size": 169703
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488871,
      "exp_type": "polyA",
      "exp_set_json": 488873,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:29:28.101363+0000",
    "size": 2017151,
    "started": "2022-05-17T11:29:46.980494+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r5_hr16_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fae0d6b13390b7dcd3b35/AX4_r5_hr16_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112926Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=5c8b3a3d379f258cdc8b74a4a992247f2b68e95c678ec18f08559af8ba1e4cde"
      },
      "exp": {
        "file": "AX4_r5_hr16_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fae0d6b13390b7dcd3b35/AX4_r5_hr16_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112926Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=91331d04897d34808ebac49239a83af1034ddc3e1d1c21a0e77ccb136a6d7e1d"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r5_hr16",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:29:27.511023+0000",
      "duplicated": None,
      "id": 73044,
      "modified": "2022-05-17T11:29:28.792863+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r5_hr16",
      "settings": {

      },
      "slug": "ax4_r5_hr16",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r5_hr16",
    "slug": "ax4_r5_hr16",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "e4b4afb9c5a12e603924765737591c9f6f54b5cf06fe6e19419b1d088c586563",
    "created": "2022-05-17T11:29:24.689464+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:30:02.165424+0000",
    "id": 409737,
    "modified": "2022-05-17T11:29:25.601974+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r5_hr12_rc.tab.gz",
        "size": 49406,
        "total_size": 49406
      },
      "exp": {
        "file": "AX4_r5_hr12_rpkum_polya.tab.gz",
        "size": 113270,
        "total_size": 113270
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r5_hr12_rc_expressions.txt.gz",
        "size": 175858,
        "total_size": 175858
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488867,
      "exp_type": "polyA",
      "exp_set_json": 488870,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:29:25.533142+0000",
    "size": 2041839,
    "started": "2022-05-17T11:29:40.600472+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r5_hr12_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fae0c6b133996d4cd3b4b/AX4_r5_hr12_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112923Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=3fd2a0bb458132f3dda9eb39957c630359da600a2c45f148b4224a87413c1be4"
      },
      "exp": {
        "file": "AX4_r5_hr12_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fae0c6b133996d4cd3b4b/AX4_r5_hr12_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112924Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=c83e0c3fad164269a61e3aae3dbd978dd6b29bd5adb088f0ec40b75648d345bf"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r5_hr12",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:29:24.837295+0000",
      "duplicated": None,
      "id": 73043,
      "modified": "2022-05-17T11:29:25.973539+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r5_hr12",
      "settings": {

      },
      "slug": "ax4_r5_hr12",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r5_hr12",
    "slug": "ax4_r5_hr12",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "623866181fef0583577a043ea030382890be4e8f7f5d88aa589c90dbdc899b45",
    "created": "2022-05-17T11:29:21.239059+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:30:12.270006+0000",
    "id": 409736,
    "modified": "2022-05-17T11:29:22.466197+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r5_hr08_rc.tab.gz",
        "size": 49803,
        "total_size": 49803
      },
      "exp": {
        "file": "AX4_r5_hr08_rpkum_polya.tab.gz",
        "size": 113352,
        "total_size": 113352
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r5_hr08_rc_expressions.txt.gz",
        "size": 176257,
        "total_size": 176257
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488875,
      "exp_type": "polyA",
      "exp_set_json": 488876,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:29:22.198483+0000",
    "size": 2043120,
    "started": "2022-05-17T11:29:49.006037+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r5_hr08_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fae0c6b13390b7dcd3b34/AX4_r5_hr08_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112920Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=fe7907a4159452976daf08b9c9013b0ad7f5bd946500b39233b4131d5d9c2318"
      },
      "exp": {
        "file": "AX4_r5_hr08_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fae0c6b13390b7dcd3b34/AX4_r5_hr08_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112920Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=b46796448af023df962c34ccac56b10e4b507435962e13297798ade4c9318ac7"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r5_hr08",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:29:21.389462+0000",
      "duplicated": None,
      "id": 73042,
      "modified": "2022-05-17T11:29:22.995316+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r5_hr08",
      "settings": {

      },
      "slug": "ax4_r5_hr08",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r5_hr08",
    "slug": "ax4_r5_hr08",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "eea3520ae55fe8cb68c9c9f4111c9d8080e82e6c517fbc131eaf21304da05fcb",
    "created": "2022-05-17T11:29:18.207265+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:30:09.448808+0000",
    "id": 409735,
    "modified": "2022-05-17T11:29:19.249220+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r5_hr06_rc.tab.gz",
        "size": 49480,
        "total_size": 49480
      },
      "exp": {
        "file": "AX4_r5_hr06_rpkum_polya.tab.gz",
        "size": 112206,
        "total_size": 112206
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r5_hr06_rc_expressions.txt.gz",
        "size": 174827,
        "total_size": 174827
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488872,
      "exp_type": "polyA",
      "exp_set_json": 488874,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:29:19.184056+0000",
    "size": 2037300,
    "started": "2022-05-17T11:29:46.198083+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r5_hr06_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fae0c6b13390b7dcd3b33/AX4_r5_hr06_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112917Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=630815c9efdb1d4b8daa1f5e59fa7a464c96bf5c853c27bd9185d032b55091c2"
      },
      "exp": {
        "file": "AX4_r5_hr06_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fae0c6b13390b7dcd3b33/AX4_r5_hr06_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112917Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=4c0590d413ad0fd8e79addc60d3b4d928fe35c18076ac341dfb9f7e4c4ad542c"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r5_hr06",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:29:18.356752+0000",
      "duplicated": None,
      "id": 73041,
      "modified": "2022-05-17T11:29:19.773686+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r5_hr06",
      "settings": {

      },
      "slug": "ax4_r5_hr06",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r5_hr06",
    "slug": "ax4_r5_hr06",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "4442473b1d63ba34fcb64000443972a5f97baf603c0731f26254af3e4117e9a9",
    "created": "2022-05-17T11:29:14.184457+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:29:52.087249+0000",
    "id": 409734,
    "modified": "2022-05-17T11:29:15.951868+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r5_hr05_rc.tab.gz",
        "size": 49377,
        "total_size": 49377
      },
      "exp": {
        "file": "AX4_r5_hr05_rpkum_polya.tab.gz",
        "size": 112188,
        "total_size": 112188
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r5_hr05_rc_expressions.txt.gz",
        "size": 174931,
        "total_size": 174931
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488861,
      "exp_type": "polyA",
      "exp_set_json": 488862,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:29:15.530099+0000",
    "size": 2037268,
    "started": "2022-05-17T11:29:34.266558+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r5_hr05_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fae0c6b13390b7dcd3b31/AX4_r5_hr05_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112913Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=fb3eed8ffd0865b8f5112e0a509eeb4774d57f038972514b06fd52d16067621f"
      },
      "exp": {
        "file": "AX4_r5_hr05_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fae0c6b13390b7dcd3b31/AX4_r5_hr05_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112913Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=085f3b9bfcb419393cd36e7a22e5447f40ff64ecf20a0677a49009aff468359c"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r5_hr05",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:29:14.528279+0000",
      "duplicated": None,
      "id": 73040,
      "modified": "2022-05-17T11:29:16.509515+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r5_hr05",
      "settings": {

      },
      "slug": "ax4_r5_hr05",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r5_hr05",
    "slug": "ax4_r5_hr05",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "46b1a677dd273dfe161a59290e86707fdb04f5e6fd2050ea92e84fd021d9da78",
    "created": "2022-05-17T11:29:10.628244+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:29:56.852741+0000",
    "id": 409733,
    "modified": "2022-05-17T11:29:12.087921+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r5_hr04_rc.tab.gz",
        "size": 48631,
        "total_size": 48631
      },
      "exp": {
        "file": "AX4_r5_hr04_rpkum_polya.tab.gz",
        "size": 111081,
        "total_size": 111081
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r5_hr04_rc_expressions.txt.gz",
        "size": 172898,
        "total_size": 172898
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488865,
      "exp_type": "polyA",
      "exp_set_json": 488866,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:29:11.695872+0000",
    "size": 2029377,
    "started": "2022-05-17T11:29:38.431274+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r5_hr04_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fae0a6b133996d4cd3b4a/AX4_r5_hr04_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112909Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=423cc696c515cd9cd17ab302bf55fb5d81f4233a7a8633c53ae98a5ec5e9043a"
      },
      "exp": {
        "file": "AX4_r5_hr04_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fae0a6b133996d4cd3b4a/AX4_r5_hr04_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112909Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=8b30b37b5c4b81a9547e5bcb68c8f6843b02a1cb968940e03a532304e4baf82f"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r5_hr04",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:29:10.879676+0000",
      "duplicated": None,
      "id": 73039,
      "modified": "2022-05-17T11:29:12.603532+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r5_hr04",
      "settings": {

      },
      "slug": "ax4_r5_hr04",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r5_hr04",
    "slug": "ax4_r5_hr04",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "b04b6962b62c3fe7c1d85f4100abee44f7997f1f0418fbe5f7c1feb375b654eb",
    "created": "2022-05-17T11:29:06.522185+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:29:53.327766+0000",
    "id": 409732,
    "modified": "2022-05-17T11:29:08.429145+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r5_hr03_rc.tab.gz",
        "size": 48431,
        "total_size": 48431
      },
      "exp": {
        "file": "AX4_r5_hr03_rpkum_polya.tab.gz",
        "size": 112043,
        "total_size": 112043
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r5_hr03_rc_expressions.txt.gz",
        "size": 173764,
        "total_size": 173764
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488863,
      "exp_type": "polyA",
      "exp_set_json": 488864,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:29:08.346577+0000",
    "size": 2033465,
    "started": "2022-05-17T11:29:35.847990+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r5_hr03_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fae0c6b13390b7dcd3b30/AX4_r5_hr03_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112905Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=6ed3017575c2890161af5ad13e74cb33469967d6822d5932e4a408113768f248"
      },
      "exp": {
        "file": "AX4_r5_hr03_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fae0c6b13390b7dcd3b30/AX4_r5_hr03_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112905Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=565b705b0417cbef90db68e020f10f80fd826461ef3003d18b53a51bfb94c6cd"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r5_hr03",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:29:06.915557+0000",
      "duplicated": None,
      "id": 73038,
      "modified": "2022-05-17T11:29:09.020296+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r5_hr03",
      "settings": {

      },
      "slug": "ax4_r5_hr03",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r5_hr03",
    "slug": "ax4_r5_hr03",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "5a316046bf870cc52100269b9c6dc651048ffcd6475bae39db21cf1b97426861",
    "created": "2022-05-17T11:29:02.910552+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:29:39.256706+0000",
    "id": 409731,
    "modified": "2022-05-17T11:29:04.217821+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r5_hr02_rc.tab.gz",
        "size": 48529,
        "total_size": 48529
      },
      "exp": {
        "file": "AX4_r5_hr02_rpkum_polya.tab.gz",
        "size": 112697,
        "total_size": 112697
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r5_hr02_rc_expressions.txt.gz",
        "size": 174711,
        "total_size": 174711
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488857,
      "exp_type": "polyA",
      "exp_set_json": 488858,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:29:03.861621+0000",
    "size": 2038986,
    "started": "2022-05-17T11:29:23.581748+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r5_hr02_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fae0a6b13396cd0cd3b4f/AX4_r5_hr02_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112902Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=2c36935d70da3d77d75348bdafb5d7636adcf4c0d470599ee0bea8d09db93943"
      },
      "exp": {
        "file": "AX4_r5_hr02_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fae0a6b13396cd0cd3b4f/AX4_r5_hr02_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112902Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=bf93eafa0e6f8eafa03a15cb3628b431110216ecee32d29fb2bd2c209591117c"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r5_hr02",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:29:03.158276+0000",
      "duplicated": None,
      "id": 73037,
      "modified": "2022-05-17T11:29:04.795416+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r5_hr02",
      "settings": {

      },
      "slug": "ax4_r5_hr02",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r5_hr02",
    "slug": "ax4_r5_hr02",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "546c4545a37d6daf83696ad52b6a0baa0cc5e531ec6929b3bc74122d39d0a20a",
    "created": "2022-05-17T11:28:59.381687+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:29:42.453913+0000",
    "id": 409730,
    "modified": "2022-05-17T11:29:00.719246+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r5_hr01_rc.tab.gz",
        "size": 46546,
        "total_size": 46546
      },
      "exp": {
        "file": "AX4_r5_hr01_rpkum_polya.tab.gz",
        "size": 108471,
        "total_size": 108471
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r5_hr01_rc_expressions.txt.gz",
        "size": 168523,
        "total_size": 168523
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488859,
      "exp_type": "polyA",
      "exp_set_json": 488860,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:29:00.496463+0000",
    "size": 2011462,
    "started": "2022-05-17T11:29:27.112613+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r5_hr01_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fae0c6b13390b7dcd3b2f/AX4_r5_hr01_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112858Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=0d37c2347e9f776bd17344ca9804a7a1946019d28171bf1ab596dd99b9cc19ee"
      },
      "exp": {
        "file": "AX4_r5_hr01_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fae0c6b13390b7dcd3b2f/AX4_r5_hr01_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112858Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=41ebefbd73eac4dbc6796b07a27810d0c8d8df1eb83b7cd92ae1b138c85d21d0"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r5_hr01",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:28:59.678339+0000",
      "duplicated": None,
      "id": 73036,
      "modified": "2022-05-17T11:29:01.149827+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r5_hr01",
      "settings": {

      },
      "slug": "ax4_r5_hr01",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r5_hr01",
    "slug": "ax4_r5_hr01",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "6a230700d4f3cbd2dad8d479b7206f85bc94b73c8bad0464e31cdb17d908fd79",
    "created": "2022-05-17T11:28:55.238032+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:30:01.601897+0000",
    "id": 409729,
    "modified": "2022-05-17T11:28:56.930594+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r5_hr00_rc.tab.gz",
        "size": 49097,
        "total_size": 49097
      },
      "exp": {
        "file": "AX4_r5_hr00_rpkum_polya.tab.gz",
        "size": 111864,
        "total_size": 111864
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r5_hr00_rc_expressions.txt.gz",
        "size": 174124,
        "total_size": 174124
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488868,
      "exp_type": "polyA",
      "exp_set_json": 488869,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:28:56.823967+0000",
    "size": 2034610,
    "started": "2022-05-17T11:29:40.550566+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r5_hr00_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fae0c6b13390b7dcd3b32/AX4_r5_hr00_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112854Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=e29039880a1f39bc9e89c461cc4cfac3674df3c29d057d14d65d531a84322830"
      },
      "exp": {
        "file": "AX4_r5_hr00_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fae0c6b13390b7dcd3b32/AX4_r5_hr00_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112854Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=5032a4cd6db890366671a22e49be31659171ba0d85cbe357a2e9e496150ab529"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r5_hr00",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:28:55.594270+0000",
      "duplicated": None,
      "id": 73035,
      "modified": "2022-05-17T11:28:57.798977+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r5_hr00",
      "settings": {

      },
      "slug": "ax4_r5_hr00",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r5_hr00",
    "slug": "ax4_r5_hr00",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "be81c9da9ec20eef7113f3f74bd880450dbd632b1e577fdcb5302f5a526f142c",
    "created": "2022-05-17T11:28:51.917328+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:29:24.349309+0000",
    "id": 409728,
    "modified": "2022-05-17T11:28:53.047227+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r4_hr24_rc.tab.gz",
        "size": 48570,
        "total_size": 48570
      },
      "exp": {
        "file": "AX4_r4_hr24_rpkum_polya.tab.gz",
        "size": 110290,
        "total_size": 110290
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r4_hr24_rc_expressions.txt.gz",
        "size": 172216,
        "total_size": 172216
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488851,
      "exp_type": "polyA",
      "exp_set_json": 488852,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:28:52.987414+0000",
    "size": 2027754,
    "started": "2022-05-17T11:29:08.007389+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r4_hr24_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5dfc0a946b13396cd0cd3b31/AX4_r4_hr24_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112851Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=172c17a10633df5a68c22ed422ff7071273621c54ad54dbdb4b81928c4df6ed4"
      },
      "exp": {
        "file": "AX4_r4_hr24_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5dfc0a946b13396cd0cd3b31/AX4_r4_hr24_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112851Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=00678b822ba4dada8cc810310721042d82ddd81af1b2e2f69b2a7ea562779535"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r4_hr24",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:28:52.079624+0000",
      "duplicated": None,
      "id": 73034,
      "modified": "2022-05-17T11:28:53.527069+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r4_hr24",
      "settings": {

      },
      "slug": "ax4_r4_hr24",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r4_hr24",
    "slug": "ax4_r4_hr24",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "5157b120b5ef149ac8397e9e4f3b3c57d94a7ae5d9279cf9a8630f382931fb05",
    "created": "2022-05-17T11:28:46.941698+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:29:32.480925+0000",
    "id": 409727,
    "modified": "2022-05-17T11:28:49.256796+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r4_hr20_rc.tab.gz",
        "size": 49601,
        "total_size": 49601
      },
      "exp": {
        "file": "AX4_r4_hr20_rpkum_polya.tab.gz",
        "size": 111711,
        "total_size": 111711
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r4_hr20_rc_expressions.txt.gz",
        "size": 174621,
        "total_size": 174621
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488855,
      "exp_type": "polyA",
      "exp_set_json": 488856,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:28:50.199951+0000",
    "size": 2038849,
    "started": "2022-05-17T11:29:16.959624+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r4_hr20_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5dfc0a956b13397107cd3b47/AX4_r4_hr20_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112846Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=03ead1d158d6d0e94278296a0f552b3a94690a619dccbf2d838927b5a19e8132"
      },
      "exp": {
        "file": "AX4_r4_hr20_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5dfc0a956b13397107cd3b47/AX4_r4_hr20_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112846Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=57ed8b42f34d25b2aefefa6d19f21a7e8267615b9d884adb0ddbc74d44010f6d"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r4_hr20",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:28:47.504392+0000",
      "duplicated": None,
      "id": 73033,
      "modified": "2022-05-17T11:28:50.174959+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r4_hr20",
      "settings": {

      },
      "slug": "ax4_r4_hr20",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r4_hr20",
    "slug": "ax4_r4_hr20",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "4f8c12926e56a950b915d6e9543188d989db925d35b628f3e21e9b0d4f4597c6",
    "created": "2022-05-17T11:28:43.333699+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:29:18.441717+0000",
    "id": 409726,
    "modified": "2022-05-17T11:28:44.612911+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r4_hr16_rc.tab.gz",
        "size": 49093,
        "total_size": 49093
      },
      "exp": {
        "file": "AX4_r4_hr16_rpkum_polya.tab.gz",
        "size": 110033,
        "total_size": 110033
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r4_hr16_rc_expressions.txt.gz",
        "size": 172430,
        "total_size": 172430
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488845,
      "exp_type": "polyA",
      "exp_set_json": 488847,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:28:44.476033+0000",
    "size": 2026928,
    "started": "2022-05-17T11:28:59.771253+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r4_hr16_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5dfc0a956b13397107cd3b48/AX4_r4_hr16_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112842Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=4c2245bf62d3e5b301b7c2cb188a3c1ccd0bf0bb04fc619154d7ada6a3229616"
      },
      "exp": {
        "file": "AX4_r4_hr16_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5dfc0a956b13397107cd3b48/AX4_r4_hr16_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112842Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d65ac047cc2c2012a8fb054bb5b35e7634cdce67b4e745f0431f47ca6c3d49b8"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r4_hr16",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:28:43.596317+0000",
      "duplicated": None,
      "id": 73032,
      "modified": "2022-05-17T11:28:45.222370+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r4_hr16",
      "settings": {

      },
      "slug": "ax4_r4_hr16",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r4_hr16",
    "slug": "ax4_r4_hr16",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "0f7e9678e0a8a0d9e5a0433c2b8b550576eade0c0bedc8e4a2afa10ca8a973c1",
    "created": "2022-05-17T11:28:40.237230+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:29:20.861411+0000",
    "id": 409725,
    "modified": "2022-05-17T11:28:41.318345+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r4_hr12_rc.tab.gz",
        "size": 50307,
        "total_size": 50307
      },
      "exp": {
        "file": "AX4_r4_hr12_rpkum_polya.tab.gz",
        "size": 111474,
        "total_size": 111474
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r4_hr12_rc_expressions.txt.gz",
        "size": 174932,
        "total_size": 174932
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488846,
      "exp_type": "polyA",
      "exp_set_json": 488848,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:28:41.259511+0000",
    "size": 2037373,
    "started": "2022-05-17T11:29:00.882986+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r4_hr12_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5dfc0a956b13397107cd3b46/AX4_r4_hr12_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112839Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=4cabb99e1b028a101e5ea229e0acdca64d9cbe37471fc926a9f4f6b85ef69060"
      },
      "exp": {
        "file": "AX4_r4_hr12_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5dfc0a956b13397107cd3b46/AX4_r4_hr12_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112839Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=2edb59507bab8d26538c64428a130b98e11f15d31c8d1c3d04b977599f6ff401"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r4_hr12",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:28:40.484112+0000",
      "duplicated": None,
      "id": 73031,
      "modified": "2022-05-17T11:28:41.768329+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r4_hr12",
      "settings": {

      },
      "slug": "ax4_r4_hr12",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r4_hr12",
    "slug": "ax4_r4_hr12",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "d0eb7e0cbe69b386ce5e57c15e727117f752fc2ebfcb2630d6b9f681ba84c457",
    "created": "2022-05-17T11:28:37.065121+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:29:21.510105+0000",
    "id": 409724,
    "modified": "2022-05-17T11:28:38.282220+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r4_hr08_rc.tab.gz",
        "size": 49572,
        "total_size": 49572
      },
      "exp": {
        "file": "AX4_r4_hr08_rpkum_polya.tab.gz",
        "size": 109581,
        "total_size": 109581
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r4_hr08_rc_expressions.txt.gz",
        "size": 172340,
        "total_size": 172340
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488849,
      "exp_type": "polyA",
      "exp_set_json": 488850,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:28:37.942297+0000",
    "size": 2024271,
    "started": "2022-05-17T11:29:05.771633+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r4_hr08_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5dfc0a956b13397107cd3b45/AX4_r4_hr08_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112836Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=b7b8e4b9ba2658bd4b59ef684fc96ee76ab5c72efff79961cf1d70b879ab8f9c"
      },
      "exp": {
        "file": "AX4_r4_hr08_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5dfc0a956b13397107cd3b45/AX4_r4_hr08_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112836Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=8db7169782f2551e69da084840df780cf618862719e6c522337be19f8ba7f161"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r4_hr08",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:28:37.338725+0000",
      "duplicated": None,
      "id": 73030,
      "modified": "2022-05-17T11:28:38.722407+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r4_hr08",
      "settings": {

      },
      "slug": "ax4_r4_hr08",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r4_hr08",
    "slug": "ax4_r4_hr08",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "2d36eb6ffbfc15e4a50e5868e0b96e4924c7c730a7471ed9220037381715c198",
    "created": "2022-05-17T11:28:33.581850+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:29:11.600362+0000",
    "id": 409723,
    "modified": "2022-05-17T11:28:34.932003+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r4_hr04_rc.tab.gz",
        "size": 49293,
        "total_size": 49293
      },
      "exp": {
        "file": "AX4_r4_hr04_rpkum_polya.tab.gz",
        "size": 109088,
        "total_size": 109088
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r4_hr04_rc_expressions.txt.gz",
        "size": 171548,
        "total_size": 171548
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488841,
      "exp_type": "polyA",
      "exp_set_json": 488842,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:28:34.583657+0000",
    "size": 2021485,
    "started": "2022-05-17T11:28:54.581688+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r4_hr04_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5dfc0a936b13397107cd3b44/AX4_r4_hr04_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112832Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=910804546b82d8170aeef1a7066d7e3aa83d5f39f290d8ca4e14f0f31d461526"
      },
      "exp": {
        "file": "AX4_r4_hr04_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5dfc0a936b13397107cd3b44/AX4_r4_hr04_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112832Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=69a41a7aa2b41d8e91aa84010238a1b2da183fa8fcf20f23c37e962bf0bc468c"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r4_hr04",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:28:33.787026+0000",
      "duplicated": None,
      "id": 73029,
      "modified": "2022-05-17T11:28:35.445141+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r4_hr04",
      "settings": {

      },
      "slug": "ax4_r4_hr04",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r4_hr04",
    "slug": "ax4_r4_hr04",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "0f2cc15ba8db6613f820433951fc0e5028dbdfe1ea8b61e9b7d6c2988bf02d06",
    "created": "2022-05-17T11:28:30.305823+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:29:15.500132+0000",
    "id": 409722,
    "modified": "2022-05-17T11:28:31.680903+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r4_hr00_rc.tab.gz",
        "size": 48448,
        "total_size": 48448
      },
      "exp": {
        "file": "AX4_r4_hr00_rpkum_polya.tab.gz",
        "size": 105811,
        "total_size": 105811
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r4_hr00_rc_expressions.txt.gz",
        "size": 166975,
        "total_size": 166975
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488843,
      "exp_type": "polyA",
      "exp_set_json": 488844,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:28:31.604046+0000",
    "size": 2001300,
    "started": "2022-05-17T11:28:58.666645+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r4_hr00_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5dfc0a936b13396cd0cd3b30/AX4_r4_hr00_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112829Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=62d35f670d53694fef5a0eb8586dea05979d1eff04d7e02b6f4caaeb1f2cb85a"
      },
      "exp": {
        "file": "AX4_r4_hr00_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5dfc0a936b13396cd0cd3b30/AX4_r4_hr00_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112829Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=042da82194c4dea43bdb77dcedfb7773a6cfed99b1850de5cea927d13102d773"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r4_hr00",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:28:30.580617+0000",
      "duplicated": None,
      "id": 73028,
      "modified": "2022-05-17T11:28:32.150195+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r4_hr00",
      "settings": {

      },
      "slug": "ax4_r4_hr00",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r4_hr00",
    "slug": "ax4_r4_hr00",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "9da43793a65ad08b4dc2aaa26497871482b68dac31808715d89c95bb6b89c9f2",
    "created": "2022-05-17T11:28:26.419485+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:29:27.658635+0000",
    "id": 409721,
    "modified": "2022-05-17T11:28:28.133003+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r3_hr24_rc.tab.gz",
        "size": 51000,
        "total_size": 51000
      },
      "exp": {
        "file": "AX4_r3_hr24_rpkum_polya.tab.gz",
        "size": 114105,
        "total_size": 114105
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r3_hr24_rc_expressions.txt.gz",
        "size": 178131,
        "total_size": 178131
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488853,
      "exp_type": "polyA",
      "exp_set_json": 488854,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:28:28.048245+0000",
    "size": 2052671,
    "started": "2022-05-17T11:29:12.011555+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r3_hr24_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5dfc04216b13396330cd3b4d/AX4_r3_hr24_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112825Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=78f438d8ac0729dc5d2fc9acc1f3b2ac71e470a8a20c63d9c58b046f1c34e691"
      },
      "exp": {
        "file": "AX4_r3_hr24_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5dfc04216b13396330cd3b4d/AX4_r3_hr24_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112825Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=27b10f66bf0f546c61ee11e16155ec850c139421390884e16d75bda5c97bc87d"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r3_hr24",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:28:26.732907+0000",
      "duplicated": None,
      "id": 73027,
      "modified": "2022-05-17T11:28:28.681714+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r3_hr24",
      "settings": {

      },
      "slug": "ax4_r3_hr24",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r3_hr24",
    "slug": "ax4_r3_hr24",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "1c2cb1bf6ef04a46a294ea88676278e4d1979f9c7bed23654118693a12564238",
    "created": "2022-05-17T11:28:23.082746+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:28:59.114805+0000",
    "id": 409720,
    "modified": "2022-05-17T11:28:24.421038+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r3_hr20_rc.tab.gz",
        "size": 50100,
        "total_size": 50100
      },
      "exp": {
        "file": "AX4_r3_hr20_rpkum_polya.tab.gz",
        "size": 112070,
        "total_size": 112070
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r3_hr20_rc_expressions.txt.gz",
        "size": 175421,
        "total_size": 175421
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488834,
      "exp_type": "polyA",
      "exp_set_json": 488837,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:28:23.989924+0000",
    "size": 2041440,
    "started": "2022-05-17T11:28:39.834534+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r3_hr20_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5dfc0a936b1339a7eacd3b59/AX4_r3_hr20_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112822Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=0f6181b01be43beee2c636842c75f27781523c857d97c22a31791e959e3fe754"
      },
      "exp": {
        "file": "AX4_r3_hr20_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5dfc0a936b1339a7eacd3b59/AX4_r3_hr20_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112822Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=de595ee578ca740fa453467fc5a31cf1eebb1df6aef1b1449f04a4dcc3551e13"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r3_hr20",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:28:23.251704+0000",
      "duplicated": None,
      "id": 73026,
      "modified": "2022-05-17T11:28:24.849075+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r3_hr20",
      "settings": {

      },
      "slug": "ax4_r3_hr20",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r3_hr20",
    "slug": "ax4_r3_hr20",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "ce6928ff6fb6e11d176ec15ccb8526b506b11bf6a3a36906063a6c19adcd3139",
    "created": "2022-05-17T11:28:19.729840+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:28:53.021249+0000",
    "id": 409719,
    "modified": "2022-05-17T11:28:21.061668+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r3_hr16_rc.tab.gz",
        "size": 50005,
        "total_size": 50005
      },
      "exp": {
        "file": "AX4_r3_hr16_rpkum_polya.tab.gz",
        "size": 111670,
        "total_size": 111670
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r3_hr16_rc_expressions.txt.gz",
        "size": 174791,
        "total_size": 174791
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488829,
      "exp_type": "polyA",
      "exp_set_json": 488830,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:28:20.838126+0000",
    "size": 2038101,
    "started": "2022-05-17T11:28:36.725785+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r3_hr16_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5dfc0a936b13397107cd3b43/AX4_r3_hr16_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112819Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=ef0f936a7f6f9b9d4ea267e2ad9c59a0f6958fed191b7c86facae1967ad1c551"
      },
      "exp": {
        "file": "AX4_r3_hr16_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5dfc0a936b13397107cd3b43/AX4_r3_hr16_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112819Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=727cf84c4017c4d4f288984d2ac71779987861d63c023a74e2d80d537be5110d"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r3_hr16",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:28:19.905689+0000",
      "duplicated": None,
      "id": 73025,
      "modified": "2022-05-17T11:28:21.494497+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r3_hr16",
      "settings": {

      },
      "slug": "ax4_r3_hr16",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r3_hr16",
    "slug": "ax4_r3_hr16",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "33d0d91b37a5ce6b6bad177d6acca8d126a0b6835699f99f4891f04cd5b3a879",
    "created": "2022-05-17T11:28:16.796449+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:28:58.379482+0000",
    "id": 409718,
    "modified": "2022-05-17T11:28:17.853793+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r3_hr12_rc.tab.gz",
        "size": 50822,
        "total_size": 50822
      },
      "exp": {
        "file": "AX4_r3_hr12_rpkum_polya.tab.gz",
        "size": 112453,
        "total_size": 112453
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r3_hr12_rc_expressions.txt.gz",
        "size": 176515,
        "total_size": 176515
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488832,
      "exp_type": "polyA",
      "exp_set_json": 488835,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:28:17.573601+0000",
    "size": 2043167,
    "started": "2022-05-17T11:28:38.394964+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r3_hr12_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5dfc0a936b13397107cd3b42/AX4_r3_hr12_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112816Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=22cf600612beb8fc41eb516ed26fe55d24412bd3a30395aa2aff3f7b60d20afe"
      },
      "exp": {
        "file": "AX4_r3_hr12_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5dfc0a936b13397107cd3b42/AX4_r3_hr12_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112816Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d57970d8d0438cf3e95f6656b6ec38315d923d8c2d5a00697a6710f7d9be8008"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r3_hr12",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:28:16.941387+0000",
      "duplicated": None,
      "id": 73024,
      "modified": "2022-05-17T11:28:18.330282+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r3_hr12",
      "settings": {

      },
      "slug": "ax4_r3_hr12",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r3_hr12",
    "slug": "ax4_r3_hr12",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "cd216d14ec1a7e26c0bfccdde1126f9d057e75f0cbdd18eca3505b199214b946",
    "created": "2022-05-17T11:28:13.501182+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:29:05.745218+0000",
    "id": 409717,
    "modified": "2022-05-17T11:28:14.754714+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r3_hr08_rc.tab.gz",
        "size": 50346,
        "total_size": 50346
      },
      "exp": {
        "file": "AX4_r3_hr08_rpkum_polya.tab.gz",
        "size": 110934,
        "total_size": 110934
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r3_hr08_rc_expressions.txt.gz",
        "size": 174083,
        "total_size": 174083
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488839,
      "exp_type": "polyA",
      "exp_set_json": 488840,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:28:14.478448+0000",
    "size": 2033007,
    "started": "2022-05-17T11:28:46.804432+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r3_hr08_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5dfc0a936b13397107cd3b41/AX4_r3_hr08_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112812Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=82c1399770c4aeacbe199f14bc514838a8fcaf9c343ccee504fa4e798ff81990"
      },
      "exp": {
        "file": "AX4_r3_hr08_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5dfc0a936b13397107cd3b41/AX4_r3_hr08_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112812Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=b34b0eeb1153e82ae9c9ae29c8587ed3cb106b1bd12baebb60a5e9797a60b982"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r3_hr08",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:28:13.690170+0000",
      "duplicated": None,
      "id": 73023,
      "modified": "2022-05-17T11:28:15.202358+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r3_hr08",
      "settings": {

      },
      "slug": "ax4_r3_hr08",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r3_hr08",
    "slug": "ax4_r3_hr08",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "fe10e3a6b6815010bec25023e09bdff475afd34e844ea56152452483877b4cdd",
    "created": "2022-05-17T11:28:10.245131+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:28:56.987046+0000",
    "id": 409716,
    "modified": "2022-05-17T11:28:11.586386+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r3_hr04_rc.tab.gz",
        "size": 50715,
        "total_size": 50715
      },
      "exp": {
        "file": "AX4_r3_hr04_rpkum_polya.tab.gz",
        "size": 110727,
        "total_size": 110727
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r3_hr04_rc_expressions.txt.gz",
        "size": 174260,
        "total_size": 174260
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488831,
      "exp_type": "polyA",
      "exp_set_json": 488833,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:28:11.257497+0000",
    "size": 2032814,
    "started": "2022-05-17T11:28:37.920889+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r3_hr04_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5dfc0a926b13396cd0cd3b2f/AX4_r3_hr04_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112809Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=09f92e3135e7789545fb463e7d77e31947b469eeaf57fc84c72d6e123e74a3e9"
      },
      "exp": {
        "file": "AX4_r3_hr04_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5dfc0a926b13396cd0cd3b2f/AX4_r3_hr04_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112809Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=e2e885ab55439968e58444f75647020bc23343cdd68054f79641dfee59263d7d"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r3_hr04",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:28:10.454185+0000",
      "duplicated": None,
      "id": 73022,
      "modified": "2022-05-17T11:28:12.017522+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r3_hr04",
      "settings": {

      },
      "slug": "ax4_r3_hr04",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r3_hr04",
    "slug": "ax4_r3_hr04",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "03c248f8664d298fe4ba276965321b22a735f44b27c505b06e6f5a468c4224e5",
    "created": "2022-05-17T11:28:06.557756+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:29:00.736493+0000",
    "id": 409715,
    "modified": "2022-05-17T11:28:08.175957+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r3_hr00_rc.tab.gz",
        "size": 48010,
        "total_size": 48010
      },
      "exp": {
        "file": "AX4_r3_hr00_rpkum_polya.tab.gz",
        "size": 105931,
        "total_size": 105931
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r3_hr00_rc_expressions.txt.gz",
        "size": 166672,
        "total_size": 166672
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488836,
      "exp_type": "polyA",
      "exp_set_json": 488838,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:28:08.096949+0000",
    "size": 2001571,
    "started": "2022-05-17T11:28:41.147561+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r3_hr00_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5dfc0a926b13397107cd3b40/AX4_r3_hr00_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112805Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=0b5f516c3a3bb05dfaad268e8e7c8cac5c87a03f270a90b1b841a9f194adc492"
      },
      "exp": {
        "file": "AX4_r3_hr00_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5dfc0a926b13397107cd3b40/AX4_r3_hr00_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112805Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=720fc1cd9ac43bc7ab917ce4495dfd6bc44c44a599afe7b1bf1c9d6d90bdbb37"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r3_hr00",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:28:07.039466+0000",
      "duplicated": None,
      "id": 73021,
      "modified": "2022-05-17T11:28:08.601613+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r3_hr00",
      "settings": {

      },
      "slug": "ax4_r3_hr00",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r3_hr00",
    "slug": "ax4_r3_hr00",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "2eaf5805a075828fcd4d2d962272e25e94a1302ee019c84c3d7524df15952e7a",
    "created": "2022-05-17T11:28:02.215159+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:28:35.170405+0000",
    "id": 409714,
    "modified": "2022-05-17T11:28:04.440917+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r2_hr24_rc.tab.gz",
        "size": 49744,
        "total_size": 49744
      },
      "exp": {
        "file": "AX4_r2_hr24_rpkum_polya.tab.gz",
        "size": 114946,
        "total_size": 114946
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r2_hr24_rc_expressions.txt.gz",
        "size": 178031,
        "total_size": 178031
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488821,
      "exp_type": "polyA",
      "exp_set_json": 488822,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:28:04.372130+0000",
    "size": 2053231,
    "started": "2022-05-17T11:28:19.472575+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r2_hr24_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf406b13390b7dcd3b67/AX4_r2_hr24_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112801Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=13df219dfaf1ed6d8fb2f91045519150c026fccd56eb0eed504348a3dfd05182"
      },
      "exp": {
        "file": "AX4_r2_hr24_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf406b13390b7dcd3b67/AX4_r2_hr24_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112801Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=facb21bba55eb0c124d65f9d3a4872acab717ffe29979c7ea75b3e7b3674e53b"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r2_hr24",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:28:02.592145+0000",
      "duplicated": None,
      "id": 73020,
      "modified": "2022-05-17T11:28:04.925594+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r2_hr24",
      "settings": {

      },
      "slug": "ax4_r2_hr24",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r2_hr24",
    "slug": "ax4_r2_hr24",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "2c1eacbd3e20bc6ad2a71872bdea46526b4eb00b90877265892ecd2a3e93867f",
    "created": "2022-05-17T11:27:57.935035+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:28:36.904791+0000",
    "id": 409713,
    "modified": "2022-05-17T11:27:59.768725+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r2_hr22_rc.tab.gz",
        "size": 49719,
        "total_size": 49719
      },
      "exp": {
        "file": "AX4_r2_hr22_rpkum_polya.tab.gz",
        "size": 114787,
        "total_size": 114787
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r2_hr22_rc_expressions.txt.gz",
        "size": 177623,
        "total_size": 177623
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488823,
      "exp_type": "polyA",
      "exp_set_json": 488824,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:28:00.739983+0000",
    "size": 2052122,
    "started": "2022-05-17T11:28:19.892343+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r2_hr22_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf406b13390b7dcd3b66/AX4_r2_hr22_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112757Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=7b9e3076e56015ec488b299d233274808d96b0bdb931ffaa5d381740cacc44a1"
      },
      "exp": {
        "file": "AX4_r2_hr22_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf406b13390b7dcd3b66/AX4_r2_hr22_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112757Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=54e91744219c1a2a126909f7919aa1b994f1341f1bc4b3d1fea9537cc3eb82d5"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r2_hr22",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:27:58.239278+0000",
      "duplicated": None,
      "id": 73019,
      "modified": "2022-05-17T11:28:00.411898+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r2_hr22",
      "settings": {

      },
      "slug": "ax4_r2_hr22",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r2_hr22",
    "slug": "ax4_r2_hr22",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "779a699fe67246d4e769ed88f0bc3d7088fb8768ed388f3ebee4d2a39075ddec",
    "created": "2022-05-17T11:27:53.462557+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:28:38.460721+0000",
    "id": 409712,
    "modified": "2022-05-17T11:27:55.356891+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r2_hr20_rc.tab.gz",
        "size": 49193,
        "total_size": 49193
      },
      "exp": {
        "file": "AX4_r2_hr20_rpkum_polya.tab.gz",
        "size": 114030,
        "total_size": 114030
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r2_hr20_rc_expressions.txt.gz",
        "size": 176375,
        "total_size": 176375
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488825,
      "exp_type": "polyA",
      "exp_set_json": 488826,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:27:55.260002+0000",
    "size": 2047264,
    "started": "2022-05-17T11:28:22.593862+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r2_hr20_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf406b13390b7dcd3b65/AX4_r2_hr20_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112752Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=924989fea20db437034ead9235a0a61cd46eb0ac41da5524f5a0f87301d6a0a7"
      },
      "exp": {
        "file": "AX4_r2_hr20_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf406b13390b7dcd3b65/AX4_r2_hr20_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112752Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=c2a2a4c754ddbd000a48820e6b9cae29040c02f0e3733e91ca9c8483a8c7bb50"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r2_hr20",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:27:53.684071+0000",
      "duplicated": None,
      "id": 73018,
      "modified": "2022-05-17T11:27:56.045674+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r2_hr20",
      "settings": {

      },
      "slug": "ax4_r2_hr20",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r2_hr20",
    "slug": "ax4_r2_hr20",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "a2b6d517b84982ee753e2956e0fa0ca43e30feeaeda00b6c21b8d273fd5dd720",
    "created": "2022-05-17T11:27:50.014000+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:28:51.447582+0000",
    "id": 409711,
    "modified": "2022-05-17T11:27:51.367014+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r2_hr18_rc.tab.gz",
        "size": 49261,
        "total_size": 49261
      },
      "exp": {
        "file": "AX4_r2_hr18_rpkum_polya.tab.gz",
        "size": 113728,
        "total_size": 113728
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r2_hr18_rc_expressions.txt.gz",
        "size": 176305,
        "total_size": 176305
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488827,
      "exp_type": "polyA",
      "exp_set_json": 488828,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:27:51.313649+0000",
    "size": 2046391,
    "started": "2022-05-17T11:28:34.752442+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r2_hr18_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf3f6b133999c2cd3b3c/AX4_r2_hr18_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112749Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=60e664a722fecc56879bd19f9630fed6f196d74cadfecc82f8a928588dee5ba4"
      },
      "exp": {
        "file": "AX4_r2_hr18_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf3f6b133999c2cd3b3c/AX4_r2_hr18_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112749Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=acf5e4eda76c33f1e9751fe91bbf4e0744b4521e79784c1f15b56b90613f612f"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r2_hr18",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:27:50.321273+0000",
      "duplicated": None,
      "id": 73017,
      "modified": "2022-05-17T11:27:51.879555+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r2_hr18",
      "settings": {

      },
      "slug": "ax4_r2_hr18",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r2_hr18",
    "slug": "ax4_r2_hr18",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "1614daee351f11515c0b4d7bbbbd8aa6ac73191059ed013243c66ff706669358",
    "created": "2022-05-17T11:27:46.703618+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:28:29.963027+0000",
    "id": 409710,
    "modified": "2022-05-17T11:27:48.113871+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r2_hr16_rc.tab.gz",
        "size": 50550,
        "total_size": 50550
      },
      "exp": {
        "file": "AX4_r2_hr16_rpkum_polya.tab.gz",
        "size": 114836,
        "total_size": 114836
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r2_hr16_rc_expressions.txt.gz",
        "size": 178597,
        "total_size": 178597
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488819,
      "exp_type": "polyA",
      "exp_set_json": 488820,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:27:47.844312+0000",
    "size": 2055184,
    "started": "2022-05-17T11:28:14.536912+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r2_hr16_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf3f6b13390b7dcd3b64/AX4_r2_hr16_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112745Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=209908ecb482876c43f1947c29b640c9a4156ced0f16653bcad6cbc145b51457"
      },
      "exp": {
        "file": "AX4_r2_hr16_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf3f6b13390b7dcd3b64/AX4_r2_hr16_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112745Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=353c3265eae41d665e7db87af91a0aa8b2de1b5ba2389afff3c6d0a308fcb988"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r2_hr16",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:27:47.041217+0000",
      "duplicated": None,
      "id": 73016,
      "modified": "2022-05-17T11:27:48.547157+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r2_hr16",
      "settings": {

      },
      "slug": "ax4_r2_hr16",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r2_hr16",
    "slug": "ax4_r2_hr16",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "c73c48b3d288aa652121389bdc7684f244a99abb6f5281a6884ab4f3878d621e",
    "created": "2022-05-17T11:27:42.879455+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:28:16.118782+0000",
    "id": 409709,
    "modified": "2022-05-17T11:27:44.318339+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r2_hr14_rc.tab.gz",
        "size": 50486,
        "total_size": 50486
      },
      "exp": {
        "file": "AX4_r2_hr14_rpkum_polya.tab.gz",
        "size": 114827,
        "total_size": 114827
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r2_hr14_rc_expressions.txt.gz",
        "size": 178403,
        "total_size": 178403
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488815,
      "exp_type": "polyA",
      "exp_set_json": 488816,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:27:44.232423+0000",
    "size": 2053743,
    "started": "2022-05-17T11:27:59.320561+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r2_hr14_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf3f6b13390b7dcd3b63/AX4_r2_hr14_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112742Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=02b06d30843f750bb3ab77666deaaa97b9c5f8c40a2d9eecbb1cd93ba282e272"
      },
      "exp": {
        "file": "AX4_r2_hr14_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf3f6b13390b7dcd3b63/AX4_r2_hr14_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112742Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=59a8ec8320e0b0fc621c00c5559d04723c9fb2f779bf1fdc98b7cc73be645a5f"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r2_hr14",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:27:43.024682+0000",
      "duplicated": None,
      "id": 73015,
      "modified": "2022-05-17T11:27:44.811438+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r2_hr14",
      "settings": {

      },
      "slug": "ax4_r2_hr14",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r2_hr14",
    "slug": "ax4_r2_hr14",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "812543a408d289b313ad985d082b6c5e1f9447dfe9eed523e248dc0b032fc12c",
    "created": "2022-05-17T11:27:39.226979+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:28:13.823389+0000",
    "id": 409708,
    "modified": "2022-05-17T11:27:40.765019+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r2_hr12_rc.tab.gz",
        "size": 50677,
        "total_size": 50677
      },
      "exp": {
        "file": "AX4_r2_hr12_rpkum_polya.tab.gz",
        "size": 114394,
        "total_size": 114394
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r2_hr12_rc_expressions.txt.gz",
        "size": 178029,
        "total_size": 178029
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488813,
      "exp_type": "polyA",
      "exp_set_json": 488814,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:27:40.698239+0000",
    "size": 2051906,
    "started": "2022-05-17T11:27:55.868504+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r2_hr12_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf3f6b13390b7dcd3b62/AX4_r2_hr12_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112738Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=f8b5abb4af996e09cdbcb2d595eb796fb8548011767058e2f3f32bf93b289c68"
      },
      "exp": {
        "file": "AX4_r2_hr12_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf3f6b13390b7dcd3b62/AX4_r2_hr12_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112738Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=7afa5f09b62fd28e5ed6cf6d4de0f34c274372e5f6a1c4ad40ae4a63f938b23e"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r2_hr12",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:27:39.511680+0000",
      "duplicated": None,
      "id": 73014,
      "modified": "2022-05-17T11:27:41.289969+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r2_hr12",
      "settings": {

      },
      "slug": "ax4_r2_hr12",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r2_hr12",
    "slug": "ax4_r2_hr12",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "9db05090b24947d8d06fb4838e374a2c4bce66bd25979962a6c6e4d85052fd8c",
    "created": "2022-05-17T11:27:36.029589+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:28:11.011410+0000",
    "id": 409707,
    "modified": "2022-05-17T11:27:37.238504+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r2_hr11_rc.tab.gz",
        "size": 50278,
        "total_size": 50278
      },
      "exp": {
        "file": "AX4_r2_hr11_rpkum_polya.tab.gz",
        "size": 114054,
        "total_size": 114054
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r2_hr11_rc_expressions.txt.gz",
        "size": 177170,
        "total_size": 177170
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488809,
      "exp_type": "polyA",
      "exp_set_json": 488811,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:27:36.956025+0000",
    "size": 2048744,
    "started": "2022-05-17T11:27:51.721125+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r2_hr11_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf3e6b13390b7dcd3b61/AX4_r2_hr11_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112734Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=74f13d27f46300c2f0c6ee9f6789e04a359b5640edf91ed9a9227c1787fb4645"
      },
      "exp": {
        "file": "AX4_r2_hr11_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf3e6b13390b7dcd3b61/AX4_r2_hr11_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112734Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=3961fc7c2597976db69472a4c22211f0fbd6bb19491b2626a8ca1eaeaf7651ba"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r2_hr11",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:27:36.248183+0000",
      "duplicated": None,
      "id": 73013,
      "modified": "2022-05-17T11:27:37.621048+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r2_hr11",
      "settings": {

      },
      "slug": "ax4_r2_hr11",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r2_hr11",
    "slug": "ax4_r2_hr11",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "46d1a3f1e88af28cab918d101ff3b25c7b1ceecc5bb942ce163d1a065f942f08",
    "created": "2022-05-17T11:27:32.028675+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:28:12.293421+0000",
    "id": 409706,
    "modified": "2022-05-17T11:27:33.116012+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r2_hr10_rc.tab.gz",
        "size": 48792,
        "total_size": 48792
      },
      "exp": {
        "file": "AX4_r2_hr10_rpkum_polya.tab.gz",
        "size": 112659,
        "total_size": 112659
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r2_hr10_rc_expressions.txt.gz",
        "size": 174784,
        "total_size": 174784
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488810,
      "exp_type": "polyA",
      "exp_set_json": 488812,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:27:32.830357+0000",
    "size": 2038485,
    "started": "2022-05-17T11:27:52.124740+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r2_hr10_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf3d6b13390b7dcd3b5f/AX4_r2_hr10_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112731Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=a480398070ccb9432b823f4c7c1c51f996f5c35e92522703ae6f0e873407ffd8"
      },
      "exp": {
        "file": "AX4_r2_hr10_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf3d6b13390b7dcd3b5f/AX4_r2_hr10_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112731Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=35f93dec1996a2badd4b6cc96c1405e546c3b480b92a1f5d559f34b1b6d8040f"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r2_hr10",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:27:32.171497+0000",
      "duplicated": None,
      "id": 73012,
      "modified": "2022-05-17T11:27:33.522405+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r2_hr10",
      "settings": {

      },
      "slug": "ax4_r2_hr10",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r2_hr10",
    "slug": "ax4_r2_hr10",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "dce7d20cfe493af5d52ebfafa9011f1e00271d895b22698569fef12242e5d590",
    "created": "2022-05-17T11:27:28.883425+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:28:08.358256+0000",
    "id": 409705,
    "modified": "2022-05-17T11:27:30.082356+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r2_hr09_rc.tab.gz",
        "size": 49536,
        "total_size": 49536
      },
      "exp": {
        "file": "AX4_r2_hr09_rpkum_polya.tab.gz",
        "size": 113108,
        "total_size": 113108
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r2_hr09_rc_expressions.txt.gz",
        "size": 176027,
        "total_size": 176027
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488806,
      "exp_type": "polyA",
      "exp_set_json": 488808,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:27:29.831166+0000",
    "size": 2042877,
    "started": "2022-05-17T11:27:48.344868+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r2_hr09_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf3d6b13390b7dcd3b60/AX4_r2_hr09_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112728Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=6d6cd79b659f1e3fc19fd4c5d4d44d6925175e6aad6f57b13173e5fd907a2c25"
      },
      "exp": {
        "file": "AX4_r2_hr09_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf3d6b13390b7dcd3b60/AX4_r2_hr09_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112728Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=f2ae2dbcfdc9aa125573f589cfd8fb0be1593bfe3f0a29a564ac3d96cad35eba"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r2_hr09",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:27:29.177316+0000",
      "duplicated": None,
      "id": 73011,
      "modified": "2022-05-17T11:27:30.463553+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r2_hr09",
      "settings": {

      },
      "slug": "ax4_r2_hr09",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r2_hr09",
    "slug": "ax4_r2_hr09",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "749f04780fa229ad625789a029f16e725f133ae173fe5ee2d4f5679fb463cfd6",
    "created": "2022-05-17T11:27:25.886348+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:28:24.187525+0000",
    "id": 409704,
    "modified": "2022-05-17T11:27:26.901338+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r2_hr08_rc.tab.gz",
        "size": 48225,
        "total_size": 48225
      },
      "exp": {
        "file": "AX4_r2_hr08_rpkum_polya.tab.gz",
        "size": 111290,
        "total_size": 111290
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r2_hr08_rc_expressions.txt.gz",
        "size": 172691,
        "total_size": 172691
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488817,
      "exp_type": "polyA",
      "exp_set_json": 488818,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:27:26.695023+0000",
    "size": 2029468,
    "started": "2022-05-17T11:28:09.510426+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r2_hr08_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf3d6b133999c2cd3b3b/AX4_r2_hr08_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112725Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=e268e9258b9f69314331d61e3df0e18b5515a2a27b7664703ed7073db160e70b"
      },
      "exp": {
        "file": "AX4_r2_hr08_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf3d6b133999c2cd3b3b/AX4_r2_hr08_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112725Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=2a00ef01682edb11dabe99e45b102f924596e7e18841189fc41b90b21e5fb41a"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r2_hr08",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:27:26.049687+0000",
      "duplicated": None,
      "id": 73010,
      "modified": "2022-05-17T11:27:27.279859+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r2_hr08",
      "settings": {

      },
      "slug": "ax4_r2_hr08",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r2_hr08",
    "slug": "ax4_r2_hr08",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "2cc1e6e9ef43589ea96fd9bd54d93625c503c8190d2a969d93ecf35d62c1f6fc",
    "created": "2022-05-17T11:27:22.587590+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:27:54.512712+0000",
    "id": 409703,
    "modified": "2022-05-17T11:27:23.850718+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r2_hr07_rc.tab.gz",
        "size": 48375,
        "total_size": 48375
      },
      "exp": {
        "file": "AX4_r2_hr07_rpkum_polya.tab.gz",
        "size": 110317,
        "total_size": 110317
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r2_hr07_rc_expressions.txt.gz",
        "size": 171809,
        "total_size": 171809
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488799,
      "exp_type": "polyA",
      "exp_set_json": 488800,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:27:23.506433+0000",
    "size": 2025973,
    "started": "2022-05-17T11:27:38.052011+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r2_hr07_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf3d6b13390b7dcd3b5e/AX4_r2_hr07_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112721Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=2a270e42772f9c0b6e800f8a15b3b758a42a65a788b83c2d333592a817395df2"
      },
      "exp": {
        "file": "AX4_r2_hr07_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf3d6b13390b7dcd3b5e/AX4_r2_hr07_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112722Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=2e37d7ae8ca38a0d8d72be7fb577202ca311ba3a0147e718773e3480dd3006b5"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r2_hr07",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:27:22.782369+0000",
      "duplicated": None,
      "id": 73009,
      "modified": "2022-05-17T11:27:24.394838+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r2_hr07",
      "settings": {

      },
      "slug": "ax4_r2_hr07",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r2_hr07",
    "slug": "ax4_r2_hr07",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "e7009fa95bfa6d26b58a90e99f3f0f7f9bbaca76c641280731cbae0754e77dce",
    "created": "2022-05-17T11:27:19.433524+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:28:07.491260+0000",
    "id": 409702,
    "modified": "2022-05-17T11:27:20.609506+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r2_hr06_rc.tab.gz",
        "size": 47298,
        "total_size": 47298
      },
      "exp": {
        "file": "AX4_r2_hr06_rpkum_polya.tab.gz",
        "size": 107671,
        "total_size": 107671
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r2_hr06_rc_expressions.txt.gz",
        "size": 168228,
        "total_size": 168228
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488805,
      "exp_type": "polyA",
      "exp_set_json": 488807,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:27:20.410690+0000",
    "size": 2010301,
    "started": "2022-05-17T11:27:47.036627+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r2_hr06_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf3d6b13390b7dcd3b5d/AX4_r2_hr06_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112718Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=1015d7e885465f37dd0849783ed9b5627873f98570da13e8e898ca87e33a41aa"
      },
      "exp": {
        "file": "AX4_r2_hr06_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf3d6b13390b7dcd3b5d/AX4_r2_hr06_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112718Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=051bbef93025bb8a77b4a8a79522e0d68f41e22698c1edea6eeeb54944810224"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r2_hr06",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:27:19.704361+0000",
      "duplicated": None,
      "id": 73008,
      "modified": "2022-05-17T11:27:21.141679+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r2_hr06",
      "settings": {

      },
      "slug": "ax4_r2_hr06",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r2_hr06",
    "slug": "ax4_r2_hr06",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "b29a3511f16d63687570095425acc6e0900fc42877eb94aa2b6548d9a7cc1136",
    "created": "2022-05-17T11:27:15.677908+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:27:48.023126+0000",
    "id": 409701,
    "modified": "2022-05-17T11:27:16.914020+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r2_hr05_rc.tab.gz",
        "size": 48638,
        "total_size": 48638
      },
      "exp": {
        "file": "AX4_r2_hr05_rpkum_polya.tab.gz",
        "size": 111857,
        "total_size": 111857
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r2_hr05_rc_expressions.txt.gz",
        "size": 173702,
        "total_size": 173702
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488793,
      "exp_type": "polyA",
      "exp_set_json": 488794,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:27:16.611372+0000",
    "size": 2034730,
    "started": "2022-05-17T11:27:31.235345+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r2_hr05_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf3c6b133999c2cd3b39/AX4_r2_hr05_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112715Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=1fd8031a9a5916da61c22a7f3c446d94a22221313a883ea6f9669ebf15b132d1"
      },
      "exp": {
        "file": "AX4_r2_hr05_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf3c6b133999c2cd3b39/AX4_r2_hr05_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112715Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=670b21ca90cada02512aab09f6257f7ad733a4737aec2dc3bca2d54f4214bddd"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r2_hr05",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:27:15.859923+0000",
      "duplicated": None,
      "id": 73007,
      "modified": "2022-05-17T11:27:17.579420+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r2_hr05",
      "settings": {

      },
      "slug": "ax4_r2_hr05",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r2_hr05",
    "slug": "ax4_r2_hr05",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "e0c32b5b06c35d9c33e2a8575104205c4ed4e76822f8e0e2ab37d6a16b0c3a80",
    "created": "2022-05-17T11:27:12.532208+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:27:50.639032+0000",
    "id": 409700,
    "modified": "2022-05-17T11:27:13.839316+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r2_hr04_rc.tab.gz",
        "size": 48617,
        "total_size": 48617
      },
      "exp": {
        "file": "AX4_r2_hr04_rpkum_polya.tab.gz",
        "size": 111106,
        "total_size": 111106
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r2_hr04_rc_expressions.txt.gz",
        "size": 172951,
        "total_size": 172951
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488796,
      "exp_type": "polyA",
      "exp_set_json": 488798,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:27:13.597314+0000",
    "size": 2031249,
    "started": "2022-05-17T11:27:33.446490+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r2_hr04_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf3c6b133999c2cd3b3a/AX4_r2_hr04_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112711Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=c97f70ba6d6ab44d1923ed70b6926d3c0324261168476a4c41e6ea73d108482a"
      },
      "exp": {
        "file": "AX4_r2_hr04_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf3c6b133999c2cd3b3a/AX4_r2_hr04_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112711Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=9e255b9c466edabaacec8d8307b1ca2f96b6dc4ab7eb68260829ec2e61aa688c"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r2_hr04",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:27:12.860413+0000",
      "duplicated": None,
      "id": 73006,
      "modified": "2022-05-17T11:27:14.262744+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r2_hr04",
      "settings": {

      },
      "slug": "ax4_r2_hr04",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r2_hr04",
    "slug": "ax4_r2_hr04",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "a2828b2281d2d25f4e1555220b15bbfce69a843bcf4084c8cb96bcd670db75a1",
    "created": "2022-05-17T11:27:08.337504+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:27:44.428218+0000",
    "id": 409699,
    "modified": "2022-05-17T11:27:10.031344+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r2_hr03_rc.tab.gz",
        "size": 49275,
        "total_size": 49275
      },
      "exp": {
        "file": "AX4_r2_hr03_rpkum_polya.tab.gz",
        "size": 112463,
        "total_size": 112463
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r2_hr03_rc_expressions.txt.gz",
        "size": 175162,
        "total_size": 175162
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488791,
      "exp_type": "polyA",
      "exp_set_json": 488792,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:27:09.730728+0000",
    "size": 2039204,
    "started": "2022-05-17T11:27:28.471638+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r2_hr03_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf3d6b13390b7dcd3b5c/AX4_r2_hr03_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112707Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=b9feebef5a788e20d0fc31a92525f94005aff9ab04a8c3d5cb9d214106d35d0a"
      },
      "exp": {
        "file": "AX4_r2_hr03_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf3d6b13390b7dcd3b5c/AX4_r2_hr03_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112707Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d589d6da98b01c7d108bc0a3c61ba7c822162decd1d29699bf348e43cc9a4b1d"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r2_hr03",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:27:08.864769+0000",
      "duplicated": None,
      "id": 73005,
      "modified": "2022-05-17T11:27:10.857946+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r2_hr03",
      "settings": {

      },
      "slug": "ax4_r2_hr03",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r2_hr03",
    "slug": "ax4_r2_hr03",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "1623077dde5ec998d494d0363da4bc960a1b10a8799ca42a1a8d7c416d35bec0",
    "created": "2022-05-17T11:27:04.938781+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:27:50.745232+0000",
    "id": 409698,
    "modified": "2022-05-17T11:27:06.147909+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r2_hr02_rc.tab.gz",
        "size": 48499,
        "total_size": 48499
      },
      "exp": {
        "file": "AX4_r2_hr02_rpkum_polya.tab.gz",
        "size": 111333,
        "total_size": 111333
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r2_hr02_rc_expressions.txt.gz",
        "size": 173286,
        "total_size": 173286
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488795,
      "exp_type": "polyA",
      "exp_set_json": 488797,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:27:05.877531+0000",
    "size": 2032942,
    "started": "2022-05-17T11:27:32.740664+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r2_hr02_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf3c6b13390b7dcd3b5b/AX4_r2_hr02_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112704Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=a158ef78d78b6cb1bd474afd4cd3350a03d6605f7e7714865514aab8965c97ee"
      },
      "exp": {
        "file": "AX4_r2_hr02_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf3c6b13390b7dcd3b5b/AX4_r2_hr02_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112704Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=016fce7c9a947756bdd9d3b798a817a589b8af5de97334b0daee98ede4877ac0"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r2_hr02",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:27:05.138941+0000",
      "duplicated": None,
      "id": 73004,
      "modified": "2022-05-17T11:27:06.533294+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r2_hr02",
      "settings": {

      },
      "slug": "ax4_r2_hr02",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r2_hr02",
    "slug": "ax4_r2_hr02",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "1c4d7855c4acf1f1896244bd4e21ec2966e96ec006839a38505cbc9f57b81fa7",
    "created": "2022-05-17T11:27:00.986009+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:28:05.244526+0000",
    "id": 409697,
    "modified": "2022-05-17T11:27:02.853225+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r2_hr01_rc.tab.gz",
        "size": 47087,
        "total_size": 47087
      },
      "exp": {
        "file": "AX4_r2_hr01_rpkum_polya.tab.gz",
        "size": 107398,
        "total_size": 107398
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r2_hr01_rc_expressions.txt.gz",
        "size": 167520,
        "total_size": 167520
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488803,
      "exp_type": "polyA",
      "exp_set_json": 488804,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:27:02.795987+0000",
    "size": 2007535,
    "started": "2022-05-17T11:27:46.160379+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r2_hr01_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf3c6b13390b7dcd3b59/AX4_r2_hr01_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112700Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=a6facd5bf2bf0a1aed144b65352cfcdeb4b14e62a53f0c3e440c602cb1df0a88"
      },
      "exp": {
        "file": "AX4_r2_hr01_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf3c6b13390b7dcd3b59/AX4_r2_hr01_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112700Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=a2b856b2b5cc313109c97f34dfdbafc663a1c7818a465a64820a1ad6a206f7ec"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r2_hr01",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:27:01.268233+0000",
      "duplicated": None,
      "id": 73003,
      "modified": "2022-05-17T11:27:03.469592+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r2_hr01",
      "settings": {

      },
      "slug": "ax4_r2_hr01",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r2_hr01",
    "slug": "ax4_r2_hr01",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "568940ee43771e8e004bb1ce0fc3dc57f0199be9a6906ad18624b4fb3aa7a906",
    "created": "2022-05-17T11:26:57.463711+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:28:01.045433+0000",
    "id": 409696,
    "modified": "2022-05-17T11:26:58.916892+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r2_hr00_rc.tab.gz",
        "size": 47749,
        "total_size": 47749
      },
      "exp": {
        "file": "AX4_r2_hr00_rpkum_polya.tab.gz",
        "size": 109245,
        "total_size": 109245
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r2_hr00_rc_expressions.txt.gz",
        "size": 170055,
        "total_size": 170055
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488801,
      "exp_type": "polyA",
      "exp_set_json": 488802,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:26:58.554921+0000",
    "size": 2016362,
    "started": "2022-05-17T11:27:41.524565+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r2_hr00_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf3c6b13390b7dcd3b5a/AX4_r2_hr00_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112656Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=812592ca763fb7823665b65dfa149ff6a2a83492add6c4b93c375c7f93bfd3e8"
      },
      "exp": {
        "file": "AX4_r2_hr00_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbf3c6b13390b7dcd3b5a/AX4_r2_hr00_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112656Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=a4608479711bed0efc3c0bb84009b567b1f28cfff4ec2788a5f1c3a5db7bee9d"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r2_hr00",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:26:57.703514+0000",
      "duplicated": None,
      "id": 73002,
      "modified": "2022-05-17T11:26:59.406649+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r2_hr00",
      "settings": {

      },
      "slug": "ax4_r2_hr00",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r2_hr00",
    "slug": "ax4_r2_hr00",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "c148ee37c41af607e208a5b49d3d03e6719b276e66c2aabb52c14d621ea54d8d",
    "created": "2022-05-17T11:26:52.781840+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:27:36.858923+0000",
    "id": 409695,
    "modified": "2022-05-17T11:26:55.248282+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r1_hr24_rc.tab.gz",
        "size": 50298,
        "total_size": 50298
      },
      "exp": {
        "file": "AX4_r1_hr24_rpkum_polya.tab.gz",
        "size": 115971,
        "total_size": 115971
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r1_hr24_rc_expressions.txt.gz",
        "size": 179737,
        "total_size": 179737
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488789,
      "exp_type": "polyA",
      "exp_set_json": 488790,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:26:55.913413+0000",
    "size": 2062276,
    "started": "2022-05-17T11:27:22.657504+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r1_hr24_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbec26b13390b7dcd3b58/AX4_r1_hr24_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112652Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=e0943a5864a2cfdd01cdcddaf0bf351ecfe450da4814bb6269ecf3956c701fd9"
      },
      "exp": {
        "file": "AX4_r1_hr24_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbec26b13390b7dcd3b58/AX4_r1_hr24_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112652Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=0aca982eb2236d6e6726eda3920ca4766e97becd5b11b23712e476aaae02c1c8"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r1_hr24",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:26:53.356414+0000",
      "duplicated": None,
      "id": 73001,
      "modified": "2022-05-17T11:26:55.904599+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r1_hr24",
      "settings": {

      },
      "slug": "ax4_r1_hr24",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r1_hr24",
    "slug": "ax4_r1_hr24",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "0e846a2768c929da533f09ea2e9dc4a6b3ebe81694b2e4173eccd931dce737d9",
    "created": "2022-05-17T11:26:48.590939+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:27:25.451501+0000",
    "id": 409694,
    "modified": "2022-05-17T11:26:50.123909+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r1_hr22_rc.tab.gz",
        "size": 49477,
        "total_size": 49477
      },
      "exp": {
        "file": "AX4_r1_hr22_rpkum_polya.tab.gz",
        "size": 113923,
        "total_size": 113923
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r1_hr22_rc_expressions.txt.gz",
        "size": 176848,
        "total_size": 176848
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488787,
      "exp_type": "polyA",
      "exp_set_json": 488788,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:26:51.371901+0000",
    "size": 2049289,
    "started": "2022-05-17T11:27:10.293593+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r1_hr22_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbec26b13390b7dcd3b57/AX4_r1_hr22_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112647Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=5afa2b03634e8726ad4196075b0f35a51d571d0646f2f888bdd8fd77fe29070d"
      },
      "exp": {
        "file": "AX4_r1_hr22_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbec26b13390b7dcd3b57/AX4_r1_hr22_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112647Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=359cb87b2ac7c4ca1cd7b06b351abb9bd281ca7a9c1bc8f90a868732e5139004"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r1_hr22",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:26:48.788612+0000",
      "duplicated": None,
      "id": 73000,
      "modified": "2022-05-17T11:26:51.062247+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r1_hr22",
      "settings": {

      },
      "slug": "ax4_r1_hr22",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r1_hr22",
    "slug": "ax4_r1_hr22",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "8b43571605a90c3a0a528f055b2050b40221d17e9e5ee4c2aa4bc3db61fcaa8d",
    "created": "2022-05-17T11:26:44.058577+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:27:18.939666+0000",
    "id": 409693,
    "modified": "2022-05-17T11:26:45.860823+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r1_hr20_rc.tab.gz",
        "size": 49593,
        "total_size": 49593
      },
      "exp": {
        "file": "AX4_r1_hr20_rpkum_polya.tab.gz",
        "size": 114201,
        "total_size": 114201
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r1_hr20_rc_expressions.txt.gz",
        "size": 177277,
        "total_size": 177277
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488782,
      "exp_type": "polyA",
      "exp_set_json": 488784,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:26:45.739920+0000",
    "size": 2051667,
    "started": "2022-05-17T11:27:01.319145+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r1_hr20_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbec16b13390b7dcd3b56/AX4_r1_hr20_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112643Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=dc6b43f1ffe04a4f22adc9981ced6dd32dc0f2166c7e69151a9ac5c967519bfb"
      },
      "exp": {
        "file": "AX4_r1_hr20_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbec16b13390b7dcd3b56/AX4_r1_hr20_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112643Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=8ea638abbac7d0dd9b8353e3df1bf5b41e6d3df520f6cbc46f6b1ba2a2281bfb"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r1_hr20",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:26:44.510966+0000",
      "duplicated": None,
      "id": 72999,
      "modified": "2022-05-17T11:26:46.773607+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r1_hr20",
      "settings": {

      },
      "slug": "ax4_r1_hr20",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r1_hr20",
    "slug": "ax4_r1_hr20",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "c107d920600a6a16409610298f64f65cae62430af3e5f1d9f829f144e79c00ac",
    "created": "2022-05-17T11:26:39.889647+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:27:18.804044+0000",
    "id": 409692,
    "modified": "2022-05-17T11:26:41.668824+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r1_hr18_rc.tab.gz",
        "size": 49864,
        "total_size": 49864
      },
      "exp": {
        "file": "AX4_r1_hr18_rpkum_polya.tab.gz",
        "size": 114209,
        "total_size": 114209
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r1_hr18_rc_expressions.txt.gz",
        "size": 177454,
        "total_size": 177454
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488781,
      "exp_type": "polyA",
      "exp_set_json": 488783,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:26:42.672170+0000",
    "size": 2050627,
    "started": "2022-05-17T11:27:01.531524+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r1_hr18_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbec16b13390b7dcd3b55/AX4_r1_hr18_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112639Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=eef49e30bc09fe9381353f354ca68d6db90d9e800fff51001924870df2f369a0"
      },
      "exp": {
        "file": "AX4_r1_hr18_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbec16b13390b7dcd3b55/AX4_r1_hr18_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112639Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=dd52b1c9973a5350fdea29d0b7357d6d5eb85c5b00b889858ea7a27f2a8d82b9"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r1_hr18",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:26:40.277536+0000",
      "duplicated": None,
      "id": 72998,
      "modified": "2022-05-17T11:26:42.369768+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r1_hr18",
      "settings": {

      },
      "slug": "ax4_r1_hr18",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r1_hr18",
    "slug": "ax4_r1_hr18",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "d2d96a3983d2e113543fe5af809d5157edc489c25b77bd0f494a813bf0b94495",
    "created": "2022-05-17T11:26:36.668378+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:27:20.893311+0000",
    "id": 409691,
    "modified": "2022-05-17T11:26:37.702902+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r1_hr16_rc.tab.gz",
        "size": 50966,
        "total_size": 50966
      },
      "exp": {
        "file": "AX4_r1_hr16_rpkum_polya.tab.gz",
        "size": 115603,
        "total_size": 115603
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r1_hr16_rc_expressions.txt.gz",
        "size": 179700,
        "total_size": 179700
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488785,
      "exp_type": "polyA",
      "exp_set_json": 488786,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:26:37.497008+0000",
    "size": 2059784,
    "started": "2022-05-17T11:27:04.314547+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r1_hr16_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbec16b13390b7dcd3b54/AX4_r1_hr16_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112636Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=43516cd4d6315e9bf00c8d1bc41ff27eb6671c6658a1abbde4e6237d2b702776"
      },
      "exp": {
        "file": "AX4_r1_hr16_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbec16b13390b7dcd3b54/AX4_r1_hr16_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112636Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=b5038db9fe41280109e162355a7a1a014024ced68223469ecdb3b6685ed9249e"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r1_hr16",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:26:36.854804+0000",
      "duplicated": None,
      "id": 72997,
      "modified": "2022-05-17T11:26:38.284483+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r1_hr16",
      "settings": {

      },
      "slug": "ax4_r1_hr16",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r1_hr16",
    "slug": "ax4_r1_hr16",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "df0c91e5a7d1c59bef18fbff3ac86d218bb201c6753f5f7207383660d01b8905",
    "created": "2022-05-17T11:26:33.694149+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:27:12.513343+0000",
    "id": 409690,
    "modified": "2022-05-17T11:26:34.782241+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r1_hr14_rc.tab.gz",
        "size": 50472,
        "total_size": 50472
      },
      "exp": {
        "file": "AX4_r1_hr14_rpkum_polya.tab.gz",
        "size": 114652,
        "total_size": 114652
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r1_hr14_rc_expressions.txt.gz",
        "size": 178445,
        "total_size": 178445
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488779,
      "exp_type": "polyA",
      "exp_set_json": 488780,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:26:34.585748+0000",
    "size": 2054238,
    "started": "2022-05-17T11:26:53.432607+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r1_hr14_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbec06b13390b7dcd3b53/AX4_r1_hr14_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112633Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=0a25a6fa33b2e032040bf8524937683aad4784382d724dd5fee18216860f71a5"
      },
      "exp": {
        "file": "AX4_r1_hr14_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbec06b13390b7dcd3b53/AX4_r1_hr14_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112633Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=de9706825e55ec5f96e73984d2e98cb998d2c8db9a0141a7a85fa8c21703a199"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r1_hr14",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:26:33.884335+0000",
      "duplicated": None,
      "id": 72996,
      "modified": "2022-05-17T11:26:35.170687+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r1_hr14",
      "settings": {

      },
      "slug": "ax4_r1_hr14",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r1_hr14",
    "slug": "ax4_r1_hr14",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "4e2caada684aa25245e3bec3df55e86568842ea920ad0e038cae75f254aac671",
    "created": "2022-05-17T11:26:30.511864+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:27:06.437389+0000",
    "id": 409689,
    "modified": "2022-05-17T11:26:31.712586+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r1_hr12_rc.tab.gz",
        "size": 51331,
        "total_size": 51331
      },
      "exp": {
        "file": "AX4_r1_hr12_rpkum_polya.tab.gz",
        "size": 115677,
        "total_size": 115677
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r1_hr12_rc_expressions.txt.gz",
        "size": 180163,
        "total_size": 180163
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488777,
      "exp_type": "polyA",
      "exp_set_json": 488778,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:26:31.660364+0000",
    "size": 2061295,
    "started": "2022-05-17T11:26:46.664668+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r1_hr12_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbec06b13390b7dcd3b52/AX4_r1_hr12_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112629Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=bc70956c997c3ffc769129a9a7a2bff67d121a1c6e9d5382f7a5f8912bd0d716"
      },
      "exp": {
        "file": "AX4_r1_hr12_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbec06b13390b7dcd3b52/AX4_r1_hr12_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112629Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=6f99b0e67560ce5faeff96ce338c16f0a9a7fd19bcf436ba069192ba926b41dc"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r1_hr12",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:26:30.732485+0000",
      "duplicated": None,
      "id": 72995,
      "modified": "2022-05-17T11:26:32.238065+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r1_hr12",
      "settings": {

      },
      "slug": "ax4_r1_hr12",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r1_hr12",
    "slug": "ax4_r1_hr12",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "6ca983d6b5b6524c8e14189111f60e1ef70db006e0fdd24a841981a8268d2359",
    "created": "2022-05-17T11:26:27.514282+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:27:04.298724+0000",
    "id": 409688,
    "modified": "2022-05-17T11:26:28.560356+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r1_hr11_rc.tab.gz",
        "size": 50310,
        "total_size": 50310
      },
      "exp": {
        "file": "AX4_r1_hr11_rpkum_polya.tab.gz",
        "size": 112833,
        "total_size": 112833
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r1_hr11_rc_expressions.txt.gz",
        "size": 176188,
        "total_size": 176188
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488774,
      "exp_type": "polyA",
      "exp_set_json": 488776,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:26:28.359812+0000",
    "size": 2043791,
    "started": "2022-05-17T11:26:42.925584+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r1_hr11_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbec06b13390b7dcd3b51/AX4_r1_hr11_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112626Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=7628fe8ca0b89008c9a28f2fad2b837a78d99b568d40261122972181341659bf"
      },
      "exp": {
        "file": "AX4_r1_hr11_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbec06b13390b7dcd3b51/AX4_r1_hr11_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112626Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=b8b9cd1c3c2eec1b99bf19c3d5e311ddd6eb30785b2140ea7975d2920e22fd15"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r1_hr11",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:26:27.710418+0000",
      "duplicated": None,
      "id": 72994,
      "modified": "2022-05-17T11:26:28.955190+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r1_hr11",
      "settings": {

      },
      "slug": "ax4_r1_hr11",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r1_hr11",
    "slug": "ax4_r1_hr11",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "3794dd6cf626d050c749de0618c56f3053da69d8701c09172f78e10f49e21c5e",
    "created": "2022-05-17T11:26:23.610548+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:27:03.709195+0000",
    "id": 409687,
    "modified": "2022-05-17T11:26:25.124839+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r1_hr10_rc.tab.gz",
        "size": 48975,
        "total_size": 48975
      },
      "exp": {
        "file": "AX4_r1_hr10_rpkum_polya.tab.gz",
        "size": 113003,
        "total_size": 113003
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r1_hr10_rc_expressions.txt.gz",
        "size": 175293,
        "total_size": 175293
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488772,
      "exp_type": "polyA",
      "exp_set_json": 488775,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:26:25.042988+0000",
    "size": 2041446,
    "started": "2022-05-17T11:26:41.824459+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r1_hr10_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbebf6b133999c2cd3b38/AX4_r1_hr10_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112622Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=db89462cd0095a1ef2eb3adaf76296672b6b13d58f1d4e289f4bd9e7ec71af2c"
      },
      "exp": {
        "file": "AX4_r1_hr10_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbebf6b133999c2cd3b38/AX4_r1_hr10_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112623Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=aa0fa93210942fb8cba08a47f88fb185087bf9d267b7197dbbc7c42f29c9acc1"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r1_hr10",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:26:23.977294+0000",
      "duplicated": None,
      "id": 72993,
      "modified": "2022-05-17T11:26:26.001689+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r1_hr10",
      "settings": {

      },
      "slug": "ax4_r1_hr10",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r1_hr10",
    "slug": "ax4_r1_hr10",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "c40c24150d257602a6651cc3751e88dcae5199ca1e2251d21ee463e9a24bb722",
    "created": "2022-05-17T11:26:20.101628+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:27:02.361037+0000",
    "id": 409686,
    "modified": "2022-05-17T11:26:21.468097+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r1_hr09_rc.tab.gz",
        "size": 49365,
        "total_size": 49365
      },
      "exp": {
        "file": "AX4_r1_hr09_rpkum_polya.tab.gz",
        "size": 112800,
        "total_size": 112800
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r1_hr09_rc_expressions.txt.gz",
        "size": 175347,
        "total_size": 175347
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488771,
      "exp_type": "polyA",
      "exp_set_json": 488773,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:26:21.037416+0000",
    "size": 2041852,
    "started": "2022-05-17T11:26:41.120636+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r1_hr09_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbec06b13390b7dcd3b50/AX4_r1_hr09_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112619Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=0f4d9d85878251caae3bf25d2fde2d04e11b3c7de535e7ac9e4c59629e15a30a"
      },
      "exp": {
        "file": "AX4_r1_hr09_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbec06b13390b7dcd3b50/AX4_r1_hr09_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112619Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=3fd5248b6471a7ca0d813a0c5064722e5abdadb4861d58c7c302a8e56aade9f8"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r1_hr09",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:26:20.243983+0000",
      "duplicated": None,
      "id": 72992,
      "modified": "2022-05-17T11:26:22.084000+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r1_hr09",
      "settings": {

      },
      "slug": "ax4_r1_hr09",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r1_hr09",
    "slug": "ax4_r1_hr09",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "cc9cc19696babc99c35682add2c096f0dabc389f3c4eea7d76389925bcbb2fd9",
    "created": "2022-05-17T11:26:16.947799+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:26:56.052533+0000",
    "id": 409685,
    "modified": "2022-05-17T11:26:18.129667+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r1_hr08_rc.tab.gz",
        "size": 50164,
        "total_size": 50164
      },
      "exp": {
        "file": "AX4_r1_hr08_rpkum_polya.tab.gz",
        "size": 113458,
        "total_size": 113458
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r1_hr08_rc_expressions.txt.gz",
        "size": 176629,
        "total_size": 176629
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488766,
      "exp_type": "polyA",
      "exp_set_json": 488768,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:26:17.812244+0000",
    "size": 2046478,
    "started": "2022-05-17T11:26:32.715998+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r1_hr08_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbebf6b13390b7dcd3b4e/AX4_r1_hr08_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112616Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=8980ff214d73fd6cbe5bc10a9f155a737738f3780e452530b258394f94caf969"
      },
      "exp": {
        "file": "AX4_r1_hr08_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbebf6b13390b7dcd3b4e/AX4_r1_hr08_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112616Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=e31dc76997b2ea448cccbfe1cead68911ca6e14fc93eadfb32c581f3abcf7ef8"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r1_hr08",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:26:17.091468+0000",
      "duplicated": None,
      "id": 72991,
      "modified": "2022-05-17T11:26:18.597625+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r1_hr08",
      "settings": {

      },
      "slug": "ax4_r1_hr08",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r1_hr08",
    "slug": "ax4_r1_hr08",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "38270c658bc29d512a80ff01065c7f684ce731e215db37e3a9ff3971b53e0f54",
    "created": "2022-05-17T11:26:13.563323+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:26:54.922695+0000",
    "id": 409684,
    "modified": "2022-05-17T11:26:15.015861+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r1_hr07_rc.tab.gz",
        "size": 48554,
        "total_size": 48554
      },
      "exp": {
        "file": "AX4_r1_hr07_rpkum_polya.tab.gz",
        "size": 111166,
        "total_size": 111166
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r1_hr07_rc_expressions.txt.gz",
        "size": 173069,
        "total_size": 173069
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488764,
      "exp_type": "polyA",
      "exp_set_json": 488767,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:26:14.766856+0000",
    "size": 2030687,
    "started": "2022-05-17T11:26:33.613690+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r1_hr07_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbebf6b13390b7dcd3b4f/AX4_r1_hr07_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112612Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=6aeed1b2d7afcfe14b65959684687ed533cbcff992640a0d020f914abeb675d6"
      },
      "exp": {
        "file": "AX4_r1_hr07_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbebf6b13390b7dcd3b4f/AX4_r1_hr07_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112612Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=93f479bb90fc6970be8094405ab5da2caaf65f51153de83183075a06f819c098"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r1_hr07",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:26:13.915849+0000",
      "duplicated": None,
      "id": 72990,
      "modified": "2022-05-17T11:26:15.427167+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r1_hr07",
      "settings": {

      },
      "slug": "ax4_r1_hr07",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r1_hr07",
    "slug": "ax4_r1_hr07",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "ce80fd107349fec33bbe58a78d2059b3e35040cdbbaeb3fb6d5c9837826e81ac",
    "created": "2022-05-17T11:26:10.599056+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:26:47.861269+0000",
    "id": 409683,
    "modified": "2022-05-17T11:26:11.683525+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r1_hr06_rc.tab.gz",
        "size": 47803,
        "total_size": 47803
      },
      "exp": {
        "file": "AX4_r1_hr06_rpkum_polya.tab.gz",
        "size": 109829,
        "total_size": 109829
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r1_hr06_rc_expressions.txt.gz",
        "size": 170936,
        "total_size": 170936
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488761,
      "exp_type": "polyA",
      "exp_set_json": 488762,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:26:11.421666+0000",
    "size": 2022069,
    "started": "2022-05-17T11:26:30.240212+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r1_hr06_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbebf6b133999c2cd3b37/AX4_r1_hr06_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112609Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=cf843ac5cedff94e9dd3f2ff138e5f0bce72d896705974783547dd8db9ec54d6"
      },
      "exp": {
        "file": "AX4_r1_hr06_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbebf6b133999c2cd3b37/AX4_r1_hr06_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112610Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=afeebeff8d1dca2f7888aeaa8b2653a3d68b7e4fedce59015ff7499162c9980a"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r1_hr06",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:26:10.746530+0000",
      "duplicated": None,
      "id": 72989,
      "modified": "2022-05-17T11:26:12.059082+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r1_hr06",
      "settings": {

      },
      "slug": "ax4_r1_hr06",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r1_hr06",
    "slug": "ax4_r1_hr06",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "3368e94fdd018940dbf2d085539e5adccd89feddc3292e6ca61f534176f5d49f",
    "created": "2022-05-17T11:26:07.636178+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:26:57.816542+0000",
    "id": 409682,
    "modified": "2022-05-17T11:26:08.609982+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r1_hr05_rc.tab.gz",
        "size": 47198,
        "total_size": 47198
      },
      "exp": {
        "file": "AX4_r1_hr05_rpkum_polya.tab.gz",
        "size": 108696,
        "total_size": 108696
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r1_hr05_rc_expressions.txt.gz",
        "size": 169315,
        "total_size": 169315
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488769,
      "exp_type": "polyA",
      "exp_set_json": 488770,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:26:08.419652+0000",
    "size": 2015441,
    "started": "2022-05-17T11:26:35.756641+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r1_hr05_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbebf6b133999c2cd3b36/AX4_r1_hr05_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112607Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=0d6328ddf8a44a7656e2405ff4c3c2ffaf1ed370da9dd0dd32ac141cf6e4e231"
      },
      "exp": {
        "file": "AX4_r1_hr05_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbebf6b133999c2cd3b36/AX4_r1_hr05_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112607Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=514efc9f71b625c6944aa472af81e662abf4306b6b1b8aec7e1ef5e08d3aedf8"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r1_hr05",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:26:07.803925+0000",
      "duplicated": None,
      "id": 72988,
      "modified": "2022-05-17T11:26:08.990169+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r1_hr05",
      "settings": {

      },
      "slug": "ax4_r1_hr05",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r1_hr05",
    "slug": "ax4_r1_hr05",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "55c0f7ff86c2f924deafca02bab25ec1418f0e08938d306dcd83418ed254fc8b",
    "created": "2022-05-17T11:26:04.649255+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:26:52.603261+0000",
    "id": 409681,
    "modified": "2022-05-17T11:26:05.782971+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r1_hr04_rc.tab.gz",
        "size": 48147,
        "total_size": 48147
      },
      "exp": {
        "file": "AX4_r1_hr04_rpkum_polya.tab.gz",
        "size": 110052,
        "total_size": 110052
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r1_hr04_rc_expressions.txt.gz",
        "size": 171641,
        "total_size": 171641
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488763,
      "exp_type": "polyA",
      "exp_set_json": 488765,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:26:05.492823+0000",
    "size": 2024911,
    "started": "2022-05-17T11:26:32.168584+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r1_hr04_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbebf6b13390b7dcd3b4d/AX4_r1_hr04_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112604Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=e289f40659825bf4a9bd27059ba203a8257ea6f669857666f1077bc5e1fe5cda"
      },
      "exp": {
        "file": "AX4_r1_hr04_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbebf6b13390b7dcd3b4d/AX4_r1_hr04_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112604Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d2e0d4942c5b4812f916290101061a985b5e0d86b1486d299053cdccbb1d941b"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r1_hr04",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:26:04.794453+0000",
      "duplicated": None,
      "id": 72987,
      "modified": "2022-05-17T11:26:06.182399+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r1_hr04",
      "settings": {

      },
      "slug": "ax4_r1_hr04",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r1_hr04",
    "slug": "ax4_r1_hr04",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "d57e32c16ebac9004f01bdf822f5b5b214212cc70a87f811b14331f894815809",
    "created": "2022-05-17T11:26:01.566537+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:26:33.843112+0000",
    "id": 409680,
    "modified": "2022-05-17T11:26:02.782604+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r1_hr03_rc.tab.gz",
        "size": 48046,
        "total_size": 48046
      },
      "exp": {
        "file": "AX4_r1_hr03_rpkum_polya.tab.gz",
        "size": 110427,
        "total_size": 110427
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r1_hr03_rc_expressions.txt.gz",
        "size": 171922,
        "total_size": 171922
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488756,
      "exp_type": "polyA",
      "exp_set_json": 488758,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:26:02.521176+0000",
    "size": 2026953,
    "started": "2022-05-17T11:26:17.108594+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r1_hr03_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbebf6b133999c2cd3b34/AX4_r1_hr03_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112600Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d9a6082e4a3aed0ed1c153c10310d6c50c80718c19a00ba167708b77c72c995d"
      },
      "exp": {
        "file": "AX4_r1_hr03_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbebf6b133999c2cd3b34/AX4_r1_hr03_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112600Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=452f9cde371cd4351078fc4022dc6caf097ffe6144bd2595aec7322d1cf363e8"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r1_hr03",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:26:01.727872+0000",
      "duplicated": None,
      "id": 72986,
      "modified": "2022-05-17T11:26:03.152603+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r1_hr03",
      "settings": {

      },
      "slug": "ax4_r1_hr03",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r1_hr03",
    "slug": "ax4_r1_hr03",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "e926c270af537691b0c0316ba753f2e98e222f05b19d4c7f526c6f2b0992bcc6",
    "created": "2022-05-17T11:25:58.441492+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:26:32.670133+0000",
    "id": 409679,
    "modified": "2022-05-17T11:25:59.614493+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r1_hr02_rc.tab.gz",
        "size": 48052,
        "total_size": 48052
      },
      "exp": {
        "file": "AX4_r1_hr02_rpkum_polya.tab.gz",
        "size": 111355,
        "total_size": 111355
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r1_hr02_rc_expressions.txt.gz",
        "size": 172940,
        "total_size": 172940
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488755,
      "exp_type": "polyA",
      "exp_set_json": 488757,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:25:59.377828+0000",
    "size": 2033444,
    "started": "2022-05-17T11:26:17.929676+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r1_hr02_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbebf6b133999c2cd3b35/AX4_r1_hr02_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112557Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=a754fb8a8527317dd0f63e465dd0d3858f0888c86ddef4b5ce9e80f68279a8e4"
      },
      "exp": {
        "file": "AX4_r1_hr02_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbebf6b133999c2cd3b35/AX4_r1_hr02_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112557Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=9a6739df64df574aa86f80e745231040717129bbe6a5b0c4f40568955fed1285"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r1_hr02",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:25:58.664567+0000",
      "duplicated": None,
      "id": 72985,
      "modified": "2022-05-17T11:26:00.000528+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r1_hr02",
      "settings": {

      },
      "slug": "ax4_r1_hr02",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r1_hr02",
    "slug": "ax4_r1_hr02",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "83b026e0927a2d741c64c341f677e1279d55be6e5e63f480d0520beffcce95b5",
    "created": "2022-05-17T11:25:55.486355+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:26:39.752956+0000",
    "id": 409678,
    "modified": "2022-05-17T11:25:56.636871+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r1_hr01_rc.tab.gz",
        "size": 46847,
        "total_size": 46847
      },
      "exp": {
        "file": "AX4_r1_hr01_rpkum_polya.tab.gz",
        "size": 107608,
        "total_size": 107608
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r1_hr01_rc_expressions.txt.gz",
        "size": 167935,
        "total_size": 167935
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488759,
      "exp_type": "polyA",
      "exp_set_json": 488760,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:25:56.238058+0000",
    "size": 2009778,
    "started": "2022-05-17T11:26:23.965579+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r1_hr01_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbebf6b13390b7dcd3b4b/AX4_r1_hr01_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112554Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=8a36c4220971c1a51fe01ffd8edd547c7c39c608157b1f2207374e6a73e21aa2"
      },
      "exp": {
        "file": "AX4_r1_hr01_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbebf6b13390b7dcd3b4b/AX4_r1_hr01_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112554Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=4b44afa7a3338ecc67dc78cbaa848ca0817ec9a54542190ce30ab979d9dc76f4"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r1_hr01",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:25:55.627825+0000",
      "duplicated": None,
      "id": 72984,
      "modified": "2022-05-17T11:25:57.027837+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r1_hr01",
      "settings": {

      },
      "slug": "ax4_r1_hr01",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r1_hr01",
    "slug": "ax4_r1_hr01",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "84b9e552b4760d63cb0e9d6b04fcb7e8a95547b1d87cec3ef3e3446b2985685b",
    "created": "2022-05-17T11:25:52.194766+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-05-17T11:26:22.533516+0000",
    "id": 409677,
    "modified": "2022-05-17T11:25:53.565557+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 1024,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "AX4_r1_hr00_rc.tab.gz",
        "size": 48342,
        "total_size": 48342
      },
      "exp": {
        "file": "AX4_r1_hr00_rpkum_polya.tab.gz",
        "size": 109959,
        "total_size": 109959
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "exp_set": {
        "file": "AX4_r1_hr00_rc_expressions.txt.gz",
        "size": 171500,
        "total_size": 171500
      },
      "species": "Dictyostelium discoideum",
      "exp_json": 488753,
      "exp_type": "polyA",
      "exp_set_json": 488754,
      "feature_type": "gene"
    },
    "scheduled": "2022-05-17T11:25:53.364087+0000",
    "size": 2022970,
    "started": "2022-05-17T11:26:08.206549+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "rc": {
        "file": "AX4_r1_hr00_rc.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbebf6b13390b7dcd3b4c/AX4_r1_hr00_rc.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112551Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=3ff5699dd96e838ed76e643130c2b2a2ac35f0ee82bbe24bf445065910b944f9"
      },
      "exp": {
        "file": "AX4_r1_hr00_rpkum_polya.tab.gz",
        "file_temp": "https://genialis-share-resource-dictyexpress-datasets-us-east-1.s3.amazonaws.com/5e0fbebf6b13390b7dcd3b4c/AX4_r1_hr00_rpkum_polya.tab.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVYUD35FKVJ5S77OY%2F20220517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220517T112551Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=2e0d076c762d73dc3d33dd58db9a73533fa5ccc10efaec11a628592afd978988"
      },
      "build": "dd-05-13-2009",
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_name": "AX4_r1_hr00",
      "exp_type": "polyA",
      "feature_type": "gene"
    },
    "process": {
      "created": "2022-03-16T08:17:53.313100+0000",
      "id": 2683,
      "modified": "2022-03-16T08:17:53.313120+0000",
      "is_active": True,
      "category": "Import:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ exp_name }}",
      "description": "Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    ",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (raw expression)",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features (raw count data). Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalized expression data. Supported extensions: .tab.gz (preferred), .tab.*, .txt.* or .tsv.*"
        },
        {
          "name": "exp_name",
          "type": "basic:string:",
          "label": "Expression name",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Normalization type",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Normalization type"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "choices": [
            {
              "label": "AFFY",
              "value": "AFFY"
            },
            {
              "label": "DICTYBASE",
              "value": "DICTYBASE"
            },
            {
              "label": "ENSEMBL",
              "value": "ENSEMBL"
            },
            {
              "label": "NCBI",
              "value": "NCBI"
            },
            {
              "label": "UCSC",
              "value": "UCSC"
            }
          ],
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "choices": [
            {
              "label": "Homo sapiens",
              "value": "Homo sapiens"
            },
            {
              "label": "Mus musculus",
              "value": "Mus musculus"
            },
            {
              "label": "Rattus norvegicus",
              "value": "Rattus norvegicus"
            },
            {
              "label": "Dictyostelium discoideum",
              "value": "Dictyostelium discoideum"
            }
          ],
          "disabled": False,
          "required": True,
          "description": "Species latin name.",
          "allow_custom_choice": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True,
          "description": "Genome build or annotation version."
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "choices": [
            {
              "label": "gene",
              "value": "gene"
            },
            {
              "label": "transcript",
              "value": "transcript"
            },
            {
              "label": "exon",
              "value": "exon"
            }
          ],
          "default": "gene",
          "disabled": False,
          "required": True,
          "allow_custom_choice": True
        }
      ],
      "name": "Expression data",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Normalized expression",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts",
          "hidden": False,
          "disabled": False,
          "required": False,
          "description": "Reads mapped to genomic features."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression type",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set",
          "type": "basic:file:",
          "label": "Expressions",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "exp_set_json",
          "type": "basic:json:",
          "label": "Expressions (json)",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID source",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build",
          "hidden": False,
          "disabled": False,
          "required": True
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type",
          "hidden": False,
          "disabled": False,
          "required": True
        }
      ],
      "persistence": "RAW",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0"
          }
        },
        "resources": {
          "cores": 1,
          "memory": 1024,
          "network": True
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "\"\"\"Upload Expressions.\"\"\"\nimport gzip\nimport io\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom resolwe.process import (\n    DataField,\n    FileField,\n    JsonField,\n    Persistence,\n    SchedulingClass,\n    StringField,\n)\n\nfrom resolwe_bio.process.runtime import ProcessBio\n\n\ndef parse_expression_file(exp_file, exp_type):\n    \"\"\"Parse expression file to a Pandas dataframe.\"\"\"\n    with gzip.open(exp_file) as exp:\n        df = pd.read_csv(exp, sep=\"\\t\", float_precision=\"round_trip\")\n\n        df.rename(\n            index=str,\n            columns={\n                \"Gene\": \"FEATURE_ID\",\n                \"Expression\": exp_type,\n            },\n            inplace=True,\n        )\n        # Cast FEATURE_ID column to string\n        df[\"FEATURE_ID\"] = df[\"FEATURE_ID\"].astype(\"str\")\n        # Remove any possible empty rows from the input file\n        df.dropna(inplace=True)\n\n    return df\n\n\ndef prepare_expression_set(exp, exp_type, feature_dict, outfile_name, rc=None):\n    \"\"\"Prepare expression set output data.\"\"\"\n    exp = parse_expression_file(exp_file=exp, exp_type=exp_type)\n    exp[\"GENE_SYMBOL\"] = exp[\"FEATURE_ID\"].map(feature_dict)\n    input_features = exp[\"FEATURE_ID\"].tolist()\n    # Check if all of the input feature IDs could be mapped to the gene symbols\n    if not all(f_id in feature_dict for f_id in input_features):\n        print(\n            f\"{sum(exp.isNone().values.ravel())} feature(s) \"\n            f\"could not be mapped to the associated feature symbols.\"\n        )\n    # Merge expression values and reorder columns\n    if rc:\n        rc = parse_expression_file(exp_file=rc, exp_type=\"RAW_COUNT\")\n        exp_set = exp.merge(rc, on=\"FEATURE_ID\")\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", \"RAW_COUNT\", exp_type]\n    else:\n        exp_set = exp\n        columns = [\"FEATURE_ID\", \"GENE_SYMBOL\", exp_type]\n    exp_set = exp_set[columns]\n    # Replace NaN values with empty string\n    exp_set.fillna(\"\", inplace=True)\n\n    # Write to file\n    exp_set.to_csv(\n        outfile_name + \".txt.gz\",\n        header=True,\n        index=False,\n        sep=\"\\t\",\n        compression=\"gzip\",\n    )\n\n    # Write to JSON\n    df_dict = exp_set.set_index(\"FEATURE_ID\").to_dict(orient=\"index\")\n    with open(outfile_name + \".json\", \"w\") as f:\n        json.dump({\"genes\": df_dict}, f, allow_nan=False)\n\n\ndef expression_to_storage(infile, outfile):\n    \"\"\"Convert expressions file to JSON format.\"\"\"\n\n    def isfloat(value):\n        \"\"\"Check if value is float.\"\"\"\n        try:\n            float(value)\n            return True\n        except ValueError:\n            return False\n\n    with io.TextIOWrapper(io.BufferedReader(gzip.open(infile))) as f:\n        # Split lines by tabs\n        # Ignore lines without a number in second column\n        # Build a dictionary of gene-expression pairs\n        exp = {\n            \"genes\": {\n                gene_exp[0]: float(gene_exp[1])\n                for gene_exp in (l.split(\"\\t\") for l in f)\n                if len(gene_exp) == 2 and isfloat(gene_exp[1])\n            }\n        }\n\n    with open(file=outfile, mode=\"wt\") as f:\n        json.dump(exp, f)\n\n    return outfile\n\n\ndef replace_extension(infile):\n    \"\"\"Replace extensions of file.\"\"\"\n    extensions = \"\".join(Path(str(infile)).suffixes[-2:])\n    new_ext = \".tab.gz\"\n    outfile = str(infile).replace(extensions, new_ext)\n    return outfile\n\n\nclass UploadExpression(ProcessBio):\n    \"\"\"Upload expression data.\n\n    Upload expression data by providing raw expression data (read counts)\n    and/or normalized expression data together with the associated data\n    normalization type.\n    \"\"\"\n\n    slug = \"upload-expression\"\n    name = \"Expression data\"\n    process_type = \"data:expression\"\n    version = \"2.6.0\"\n    category = \"Import\"\n    data_name = \"{{ exp_name }}\"\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields to process UploadExpression.\"\"\"\n\n        rc = FileField(\n            label=\"Read counts (raw expression)\",\n            description=\"Reads mapped to genomic features (raw count data). \"\n            \"Supported extensions: .txt.gz (preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression data. Supported extensions: .tab.gz \"\n            \"(preferred), .tab.*, .txt.* or .tsv.*\",\n            required=False,\n        )\n        exp_name = StringField(\n            label=\"Expression name\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            description=\"Normalization type\",\n            required=False,\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n            allow_custom_choice=True,\n            choices=[\n                (\"AFFY\", \"AFFY\"),\n                (\"DICTYBASE\", \"DICTYBASE\"),\n                (\"ENSEMBL\", \"ENSEMBL\"),\n                (\"NCBI\", \"NCBI\"),\n                (\"UCSC\", \"UCSC\"),\n            ],\n        )\n        species = StringField(\n            label=\"Species\",\n            description=\"Species latin name.\",\n            allow_custom_choice=True,\n            choices=[\n                (\"Homo sapiens\", \"Homo sapiens\"),\n                (\"Mus musculus\", \"Mus musculus\"),\n                (\"Rattus norvegicus\", \"Rattus norvegicus\"),\n                (\"Dictyostelium discoideum\", \"Dictyostelium discoideum\"),\n            ],\n        )\n        build = StringField(\n            label=\"Build\", description=\"Genome build or annotation version.\"\n        )\n        feature_type = StringField(\n            label=\"Feature type\",\n            allow_custom_choice=True,\n            default=\"gene\",\n            choices=[\n                (\"gene\", \"gene\"),\n                (\"transcript\", \"transcript\"),\n                (\"exon\", \"exon\"),\n            ],\n        )\n\n    class Output:\n        \"\"\"Output fields to process UploadExpression.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        rc = FileField(\n            label=\"Read counts\",\n            required=False,\n            description=\"Reads mapped to genomic features.\",\n        )\n        exp_json = JsonField(label=\"Expression (json)\")\n        exp_type = StringField(label=\"Expression type\")\n        exp_set = FileField(label=\"Expressions\")\n        exp_set_json = JsonField(label=\"Expressions (json)\")\n        source = StringField(label=\"Gene ID source\")\n        species = StringField(label=\"Species\")\n        build = StringField(label=\"Build\")\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        supported_extensions = (\".txt\", \".tab\", \".tsv\")\n\n        if not inputs.exp and not inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif not inputs.exp and inputs.exp_type and inputs.rc:\n            self.error(\"Please provide raw or/and normalized expression files.\")\n\n        elif inputs.rc and not inputs.exp and not inputs.exp_type:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.rc.import_file(imported_format=\"compressed\")\n            exp_type = \"RAW_COUNT\"\n            stem = Path(rc).stem\n\n        elif inputs.exp and inputs.exp_type and not inputs.rc:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            exp_type = inputs.exp_type\n\n        else:\n            rc = inputs.rc.import_file(imported_format=\"compressed\")\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(rc).stem\n            stem_exp = Path(exp).stem\n            if not stem_exp.endswith(supported_extensions):\n                self.error(\n                    f\"The imported file has unsupported file name extension. \"\n                    f\"The supported extensions are {supported_extensions}.\"\n                )\n            exp_type = inputs.exp_type\n\n        if not stem.endswith(supported_extensions):\n            self.error(\n                \"The imported file has unsupported file name extension. \"\n                f\"The supported extensions are {supported_extensions}.\"\n            )\n        name = stem[:-4]\n\n        # Save the abundance estimates to JSON storage\n        expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n        # Prepare the expression set outputs\n        feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n        feature_filters = {\n            \"source\": inputs.source,\n            \"species\": inputs.species,\n            \"feature_id__in\": feature_ids,\n        }\n\n        feature_ids_to_names = {\n            f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n        }\n\n        if inputs.rc and inputs.exp:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n                rc=rc,\n            )\n        else:\n            prepare_expression_set(\n                exp=exp,\n                exp_type=exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        # Change suffixes of exp file\n        exp_final = replace_extension(infile=exp)\n        Path(exp).rename(exp_final)\n        exp = Path(exp_final).name\n\n        if inputs.rc and inputs.exp:\n            # Change suffixes of rc file\n            rc_final = replace_extension(infile=rc)\n            Path(rc).rename(rc_final)\n            rc = Path(rc_final).name\n            outputs.rc = rc\n        elif inputs.rc and not inputs.exp:\n            rc = exp\n            outputs.rc = rc\n\n        outputs.exp_type = exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.source\n        outputs.species = inputs.species\n        outputs.build = inputs.build\n        outputs.feature_type = inputs.feature_type\n\n\nclass UploadExpressionCuffnorm(ProcessBio):\n    \"\"\"Upload expression data by providing Cuffnorm results.\"\"\"\n\n    slug = \"upload-expression-cuffnorm\"\n    name = \"Expression data (Cuffnorm)\"\n    process_type = \"data:expression\"\n    version = \"1.8.0\"\n    category = \"Import\"\n    data_name = '{{ exp.file|default(\"?\") }}'\n    scheduling_class = SchedulingClass.BATCH\n    persistence = Persistence.RAW\n    entity = {\n        \"type\": \"sample\",\n    }\n    requirements = {\n        \"expression-engine\": \"jinja\",\n        \"executor\": {\n            \"docker\": {\"image\": \"public.ecr.aws/genialis/resolwebio/rnaseq:6.0.0\"}\n        },\n        \"resources\": {\n            \"cores\": 1,\n            \"memory\": 1024,\n            \"network\": True,\n        },\n    }\n\n    class Input:\n        \"\"\"Input fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(label=\"Normalized expression\")\n        cxb = DataField(\n            \"cufflinks:cuffquant\",\n            label=\"Cuffquant analysis\",\n            description=\"Cuffquant analysis.\",\n        )\n        exp_type = StringField(\n            label=\"Normalization type\",\n            default=\"Cuffnorm\",\n        )\n\n    class Output:\n        \"\"\"Output fields for UploadExpressionCuffnorm.\"\"\"\n\n        exp = FileField(\n            label=\"Normalized expression\",\n            description=\"Normalized expression\",\n        )\n        exp_json = JsonField(\n            label=\"Expression (json)\",\n        )\n        exp_type = StringField(\n            label=\"Expression type\",\n        )\n        exp_set = FileField(\n            label=\"Expressions\",\n        )\n        exp_set_json = JsonField(\n            label=\"Expressions (json)\",\n        )\n        source = StringField(\n            label=\"Gene ID source\",\n        )\n        species = StringField(label=\"Species\")\n        build = StringField(\n            label=\"Build\",\n        )\n        feature_type = StringField(label=\"Feature type\")\n\n    def run(self, inputs, outputs):\n        \"\"\"Run analysis.\"\"\"\n\n        if inputs.exp and not inputs.exp_type:\n            self.error(\n                \"Please provide normalization type together with normalized expressions.\"\n            )\n\n        elif inputs.exp and inputs.exp_type and inputs.cxb:\n            exp = inputs.exp.import_file(imported_format=\"compressed\")\n            stem = Path(exp).stem\n            name = stem[:-4]\n\n            # Save the abundance estimates to JSON storage\n            expression_to_storage(infile=exp, outfile=\"json.txt\")\n\n            # Prepare the expression set outputs\n            feature_ids = pd.read_csv(exp, sep=\"\\t\", index_col=\"Gene\").index.tolist()\n\n            feature_filters = {\n                \"source\": inputs.cxb.output.source,\n                \"species\": inputs.cxb.output.species,\n                \"feature_id__in\": feature_ids,\n            }\n\n            feature_ids_to_names = {\n                f.feature_id: f.name for f in self.feature.filter(**feature_filters)\n            }\n\n            prepare_expression_set(\n                exp=exp,\n                exp_type=inputs.exp_type,\n                feature_dict=feature_ids_to_names,\n                outfile_name=f\"{name}_expressions\",\n            )\n\n        outputs.exp_type = inputs.exp_type\n        outputs.exp = exp\n        outputs.exp_json = \"json.txt\"\n        outputs.exp_set = f\"{name}_expressions.txt.gz\"\n        outputs.exp_set_json = f\"{name}_expressions.json\"\n        outputs.source = inputs.cxb.output.source\n        outputs.species = inputs.cxb.output.species\n        outputs.build = inputs.cxb.output.build\n        outputs.feature_type = \"gene\"\n",
        "language": "python"
      },
      "scheduling_class": "BA",
      "slug": "upload-expression",
      "type": "data:expression:",
      "version": "2.6.0"
    },
    "collection": {
      "created": "2022-05-17T11:25:49.867149+0000",
      "duplicated": None,
      "id": 2333,
      "modified": "2022-05-17T11:25:49.867169+0000",
      "data_count": 88,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "7.  Milestone",
      "name": "D. discoideum, AX4, AX4, Katoh-Kurasawa M et al., (HL5, Filter Development)",
      "settings": {

      },
      "slug": "5f7f8a7e6b133974f5cd3b34",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "entity_count": 88,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-05-17T11:25:52.367003+0000",
      "duplicated": None,
      "id": 72983,
      "modified": "2022-05-17T11:25:54.092750+0000",
      "data_count": 1,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "AX4_r1_hr00",
      "settings": {

      },
      "slug": "ax4_r1_hr00",
      "tags": [
        "community:bcm",
        "dictyExpress"
      ],
      "collection": 2333,
      "type": "sample"
    },
    "name": "AX4_r1_hr00",
    "slug": "ax4_r1_hr00",
    "tags": [
      "community:bcm",
      "dictyExpress"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "ebc3877020479ffa6173e550507cefa5cdc85dd15b7871aafcdfa92e5457728b",
    "created": "2022-04-01T09:40:13.143665+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-04-01T09:56:12.505799+0000",
    "id": 389280,
    "modified": "2022-04-01T09:40:13.583292+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 16384,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "dpAX1_on_Ka_24Hr_bio1_mapped_expression_rc_polya.tab.gz",
        "size": 47268,
        "total_size": 47268
      },
      "exp": {
        "file": "dpAX1_on_Ka_24Hr_bio1_mapped_expression_rpkum_polya.tab.gz",
        "size": 111843,
        "total_size": 111843
      },
      "rpkm": {
        "file": "dpAX1_on_Ka_24Hr_bio1_mapped_expression_rpkm.tab.gz",
        "size": 111122,
        "total_size": 111122
      },
      "build": "dp-10-16-2014",
      "rpkum": {
        "file": "dpAX1_on_Ka_24Hr_bio1_mapped_expression_rpkum.tab.gz",
        "size": 111837,
        "total_size": 111837
      },
      "rc_raw": {
        "file": "dpAX1_on_Ka_24Hr_bio1_mapped_expression_rc.tab.gz",
        "size": 47262,
        "total_size": 47262
      },
      "source": "DICTYBASE",
      "species": "Dictyostelium purpureum",
      "exp_json": 475997,
      "exp_type": "polyA",
      "rpkmpolya": {
        "file": "dpAX1_on_Ka_24Hr_bio1_mapped_expression_rpkm_polya.tab.gz",
        "size": 111128,
        "total_size": 111128
      },
      "feature_type": "gene"
    },
    "scheduled": "2022-04-01T09:40:14.004480+0000",
    "size": 16086617,
    "started": "2022-04-01T09:42:59.050598+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "gff": 387805,
      "mappable": 387889,
      "alignment": 387888
    },
    "process": {
      "created": "2021-02-24T02:23:18.320496+0000",
      "id": 2177,
      "modified": "2021-11-17T06:04:16.445726+0000",
      "is_active": True,
      "category": "Other:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ alignment.bam.file|basename|default('?') }}",
      "description": "Dictyostelium-specific pipeline. Developed by Bioinformatics Laboratory,\nFaculty of Computer and Information Science, University of Ljubljana,\nSlovenia and Shaulsky Lab, Department of Molecular and Human Genetics,\nBaylor College of Medicine, Houston, TX, USA.\n",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "alignment",
          "type": "data:alignment:bam:",
          "label": "Aligned sequence"
        },
        {
          "name": "gff",
          "type": "data:annotation:gff3:",
          "label": "Features (GFF3)"
        },
        {
          "name": "mappable",
          "type": "data:mappability:bcm:",
          "label": "Mappability"
        }
      ],
      "name": "Dictyostelium expressions",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Expression RPKUM (polyA)",
          "description": "mRNA reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkmpolya",
          "type": "basic:file:",
          "label": "Expression RPKM (polyA)",
          "description": "mRNA reads scaled by exon length."
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (polyA)",
          "description": "mRNA reads uniquely mapped to gene exons."
        },
        {
          "name": "rpkum",
          "type": "basic:file:",
          "label": "Expression RPKUM",
          "description": "Reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkm",
          "type": "basic:file:",
          "label": "Expression RPKM",
          "description": "Reads scaled by exon length."
        },
        {
          "name": "rc_raw",
          "type": "basic:file:",
          "label": "Read counts (raw)",
          "description": "Reads uniquely mapped to gene exons."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression RPKUM (polyA) (json)"
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression Type (default output)"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID database"
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species"
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build"
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type"
        }
      ],
      "persistence": "CAC",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/s4q6j6e8/resolwebio/biox:2.0.0"
          }
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "NAME=`basename {{ alignment.bam.file }} .bam`\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}}\nre-checkrc \"Calculation of expression values failed.\"\nre-progress 0.5\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}} --mrna\nre-checkrc \"Calculation of expression values failed.\"\nsamtools idxstats {{ alignment.bam.file }} | cut -f -2 | head -n -1 \u003E chrom.sizes\nre-checkrc \"Samtools idxstats command failed.\"\n\nmv expression_rc.tab.gz ${NAME}_expression_rc.tab.gz\nre-save-file rc_raw ${NAME}_expression_rc.tab.gz\n\nmv expression_rc_polya.tab.gz ${NAME}_expression_rc_polya.tab.gz\nre-save-file rc ${NAME}_expression_rc_polya.tab.gz\n\nmv expression_rpkm.tab.gz ${NAME}_expression_rpkm.tab.gz\nre-save-file rpkm ${NAME}_expression_rpkm.tab.gz\n\nmv expression_rpkm_polya.tab.gz ${NAME}_expression_rpkm_polya.tab.gz\nre-save-file rpkmpolya ${NAME}_expression_rpkm_polya.tab.gz\n\nmv expression_rpkum.tab.gz ${NAME}_expression_rpkum.tab.gz\nre-save-file rpkum ${NAME}_expression_rpkum.tab.gz\n\nmv expression_rpkum_polya.tab.gz ${NAME}_expression_rpkum_polya.tab.gz\nexpression2storage.py ${NAME}_expression_rpkum_polya.tab.gz --output json.txt\nre-checkrc\nre-save exp_json json.txt\nre-save-file exp ${NAME}_expression_rpkum_polya.tab.gz\n\nre-save source {{gff.source}}\nre-save species {{alignment.species}}\nre-save build {{alignment.build}}\nre-save feature_type gene\nre-save exp_type polyA\n",
        "runtime": "polyglot",
        "language": "bash"
      },
      "scheduling_class": "BA",
      "slug": "expression-dicty",
      "type": "data:expression:polya:",
      "version": "1.4.1"
    },
    "collection": {
      "created": "2022-03-22T10:48:54.505954+0000",
      "duplicated": None,
      "id": 2218,
      "modified": "2022-05-17T10:02:06.304553+0000",
      "data_count": 44,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "dictyExpress Parikh A et. al. dataset",
      "name": "D. purpureum, DpAX1, Parikh et al. 2015 (Growth: K. pneumoniae, Treatment: Filter Development)",
      "settings": {

      },
      "slug": "dictyexpress-purpureum-parikh-et-al",
      "tags": [
        "community:bcm"
      ],
      "entity_count": 14,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-03-23T13:43:01.134188+0000",
      "duplicated": None,
      "id": 66384,
      "modified": "2022-03-23T13:43:02.248230+0000",
      "data_count": 3,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "dpAX1_on_Ka_24Hr_bio1",
      "settings": {

      },
      "slug": "dpax1_on_ka_24hr_bio1fastqgz",
      "tags": [
        "community:bcm"
      ],
      "collection": 2218,
      "type": "sample"
    },
    "name": "dpAX1_on_Ka_24Hr_bio1_mapped.bam",
    "slug": "dpax1_on_ka_24hr_bio1_mappedbam",
    "tags": [
      "community:bcm"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "0e19e8bca256b102f1c9b5bf619bfaa35e72581d2cbf77b8395c82732f7ae6ec",
    "created": "2022-04-01T09:40:13.140154+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-04-01T09:56:20.210600+0000",
    "id": 389279,
    "modified": "2022-04-01T09:40:13.585561+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 16384,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "dpAX1_on_Ka_24Hr_bio2_mapped_expression_rc_polya.tab.gz",
        "size": 47772,
        "total_size": 47772
      },
      "exp": {
        "file": "dpAX1_on_Ka_24Hr_bio2_mapped_expression_rpkum_polya.tab.gz",
        "size": 113645,
        "total_size": 113645
      },
      "rpkm": {
        "file": "dpAX1_on_Ka_24Hr_bio2_mapped_expression_rpkm.tab.gz",
        "size": 112961,
        "total_size": 112961
      },
      "build": "dp-10-16-2014",
      "rpkum": {
        "file": "dpAX1_on_Ka_24Hr_bio2_mapped_expression_rpkum.tab.gz",
        "size": 113639,
        "total_size": 113639
      },
      "rc_raw": {
        "file": "dpAX1_on_Ka_24Hr_bio2_mapped_expression_rc.tab.gz",
        "size": 47766,
        "total_size": 47766
      },
      "source": "DICTYBASE",
      "species": "Dictyostelium purpureum",
      "exp_json": 475998,
      "exp_type": "polyA",
      "rpkmpolya": {
        "file": "dpAX1_on_Ka_24Hr_bio2_mapped_expression_rpkm_polya.tab.gz",
        "size": 112967,
        "total_size": 112967
      },
      "feature_type": "gene"
    },
    "scheduled": "2022-04-01T09:40:14.002822+0000",
    "size": 16097789,
    "started": "2022-04-01T09:40:28.775228+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "gff": 387805,
      "mappable": 387889,
      "alignment": 387887
    },
    "process": {
      "created": "2021-02-24T02:23:18.320496+0000",
      "id": 2177,
      "modified": "2021-11-17T06:04:16.445726+0000",
      "is_active": True,
      "category": "Other:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ alignment.bam.file|basename|default('?') }}",
      "description": "Dictyostelium-specific pipeline. Developed by Bioinformatics Laboratory,\nFaculty of Computer and Information Science, University of Ljubljana,\nSlovenia and Shaulsky Lab, Department of Molecular and Human Genetics,\nBaylor College of Medicine, Houston, TX, USA.\n",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "alignment",
          "type": "data:alignment:bam:",
          "label": "Aligned sequence"
        },
        {
          "name": "gff",
          "type": "data:annotation:gff3:",
          "label": "Features (GFF3)"
        },
        {
          "name": "mappable",
          "type": "data:mappability:bcm:",
          "label": "Mappability"
        }
      ],
      "name": "Dictyostelium expressions",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Expression RPKUM (polyA)",
          "description": "mRNA reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkmpolya",
          "type": "basic:file:",
          "label": "Expression RPKM (polyA)",
          "description": "mRNA reads scaled by exon length."
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (polyA)",
          "description": "mRNA reads uniquely mapped to gene exons."
        },
        {
          "name": "rpkum",
          "type": "basic:file:",
          "label": "Expression RPKUM",
          "description": "Reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkm",
          "type": "basic:file:",
          "label": "Expression RPKM",
          "description": "Reads scaled by exon length."
        },
        {
          "name": "rc_raw",
          "type": "basic:file:",
          "label": "Read counts (raw)",
          "description": "Reads uniquely mapped to gene exons."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression RPKUM (polyA) (json)"
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression Type (default output)"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID database"
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species"
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build"
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type"
        }
      ],
      "persistence": "CAC",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/s4q6j6e8/resolwebio/biox:2.0.0"
          }
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "NAME=`basename {{ alignment.bam.file }} .bam`\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}}\nre-checkrc \"Calculation of expression values failed.\"\nre-progress 0.5\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}} --mrna\nre-checkrc \"Calculation of expression values failed.\"\nsamtools idxstats {{ alignment.bam.file }} | cut -f -2 | head -n -1 \u003E chrom.sizes\nre-checkrc \"Samtools idxstats command failed.\"\n\nmv expression_rc.tab.gz ${NAME}_expression_rc.tab.gz\nre-save-file rc_raw ${NAME}_expression_rc.tab.gz\n\nmv expression_rc_polya.tab.gz ${NAME}_expression_rc_polya.tab.gz\nre-save-file rc ${NAME}_expression_rc_polya.tab.gz\n\nmv expression_rpkm.tab.gz ${NAME}_expression_rpkm.tab.gz\nre-save-file rpkm ${NAME}_expression_rpkm.tab.gz\n\nmv expression_rpkm_polya.tab.gz ${NAME}_expression_rpkm_polya.tab.gz\nre-save-file rpkmpolya ${NAME}_expression_rpkm_polya.tab.gz\n\nmv expression_rpkum.tab.gz ${NAME}_expression_rpkum.tab.gz\nre-save-file rpkum ${NAME}_expression_rpkum.tab.gz\n\nmv expression_rpkum_polya.tab.gz ${NAME}_expression_rpkum_polya.tab.gz\nexpression2storage.py ${NAME}_expression_rpkum_polya.tab.gz --output json.txt\nre-checkrc\nre-save exp_json json.txt\nre-save-file exp ${NAME}_expression_rpkum_polya.tab.gz\n\nre-save source {{gff.source}}\nre-save species {{alignment.species}}\nre-save build {{alignment.build}}\nre-save feature_type gene\nre-save exp_type polyA\n",
        "runtime": "polyglot",
        "language": "bash"
      },
      "scheduling_class": "BA",
      "slug": "expression-dicty",
      "type": "data:expression:polya:",
      "version": "1.4.1"
    },
    "collection": {
      "created": "2022-03-22T10:48:54.505954+0000",
      "duplicated": None,
      "id": 2218,
      "modified": "2022-05-17T10:02:06.304553+0000",
      "data_count": 44,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "dictyExpress Parikh A et. al. dataset",
      "name": "D. purpureum, DpAX1, Parikh et al. 2015 (Growth: K. pneumoniae, Treatment: Filter Development)",
      "settings": {

      },
      "slug": "dictyexpress-purpureum-parikh-et-al",
      "tags": [
        "community:bcm"
      ],
      "entity_count": 14,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-03-23T13:45:02.007909+0000",
      "duplicated": None,
      "id": 66385,
      "modified": "2022-03-23T13:45:03.354818+0000",
      "data_count": 3,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "dpAX1_on_Ka_24Hr_bio2",
      "settings": {

      },
      "slug": "dpax1_on_ka_24hr_bio2fastqgz",
      "tags": [
        "community:bcm"
      ],
      "collection": 2218,
      "type": "sample"
    },
    "name": "dpAX1_on_Ka_24Hr_bio2_mapped.bam",
    "slug": "dpax1_on_ka_24hr_bio2_mappedbam",
    "tags": [
      "community:bcm"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "353cf0ac53bf27d634795d6b9b27f9635a1f6c2de309eebdea3a2ff779effa7a",
    "created": "2022-04-01T09:40:12.082457+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-04-01T09:57:50.732101+0000",
    "id": 389278,
    "modified": "2022-04-01T09:40:12.607673+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 16384,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "dpAX1_on_Ka_16Hr_bio1_mapped_expression_rc_polya.tab.gz",
        "size": 47621,
        "total_size": 47621
      },
      "exp": {
        "file": "dpAX1_on_Ka_16Hr_bio1_mapped_expression_rpkum_polya.tab.gz",
        "size": 111583,
        "total_size": 111583
      },
      "rpkm": {
        "file": "dpAX1_on_Ka_16Hr_bio1_mapped_expression_rpkm.tab.gz",
        "size": 110835,
        "total_size": 110835
      },
      "build": "dp-10-16-2014",
      "rpkum": {
        "file": "dpAX1_on_Ka_16Hr_bio1_mapped_expression_rpkum.tab.gz",
        "size": 111577,
        "total_size": 111577
      },
      "rc_raw": {
        "file": "dpAX1_on_Ka_16Hr_bio1_mapped_expression_rc.tab.gz",
        "size": 47615,
        "total_size": 47615
      },
      "source": "DICTYBASE",
      "species": "Dictyostelium purpureum",
      "exp_json": 476007,
      "exp_type": "polyA",
      "rpkmpolya": {
        "file": "dpAX1_on_Ka_16Hr_bio1_mapped_expression_rpkm_polya.tab.gz",
        "size": 110841,
        "total_size": 110841
      },
      "feature_type": "gene"
    },
    "scheduled": "2022-04-01T09:40:13.019892+0000",
    "size": 16085066,
    "started": "2022-04-01T09:42:29.979977+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "gff": 387805,
      "mappable": 387889,
      "alignment": 387886
    },
    "process": {
      "created": "2021-02-24T02:23:18.320496+0000",
      "id": 2177,
      "modified": "2021-11-17T06:04:16.445726+0000",
      "is_active": True,
      "category": "Other:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ alignment.bam.file|basename|default('?') }}",
      "description": "Dictyostelium-specific pipeline. Developed by Bioinformatics Laboratory,\nFaculty of Computer and Information Science, University of Ljubljana,\nSlovenia and Shaulsky Lab, Department of Molecular and Human Genetics,\nBaylor College of Medicine, Houston, TX, USA.\n",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "alignment",
          "type": "data:alignment:bam:",
          "label": "Aligned sequence"
        },
        {
          "name": "gff",
          "type": "data:annotation:gff3:",
          "label": "Features (GFF3)"
        },
        {
          "name": "mappable",
          "type": "data:mappability:bcm:",
          "label": "Mappability"
        }
      ],
      "name": "Dictyostelium expressions",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Expression RPKUM (polyA)",
          "description": "mRNA reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkmpolya",
          "type": "basic:file:",
          "label": "Expression RPKM (polyA)",
          "description": "mRNA reads scaled by exon length."
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (polyA)",
          "description": "mRNA reads uniquely mapped to gene exons."
        },
        {
          "name": "rpkum",
          "type": "basic:file:",
          "label": "Expression RPKUM",
          "description": "Reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkm",
          "type": "basic:file:",
          "label": "Expression RPKM",
          "description": "Reads scaled by exon length."
        },
        {
          "name": "rc_raw",
          "type": "basic:file:",
          "label": "Read counts (raw)",
          "description": "Reads uniquely mapped to gene exons."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression RPKUM (polyA) (json)"
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression Type (default output)"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID database"
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species"
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build"
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type"
        }
      ],
      "persistence": "CAC",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/s4q6j6e8/resolwebio/biox:2.0.0"
          }
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "NAME=`basename {{ alignment.bam.file }} .bam`\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}}\nre-checkrc \"Calculation of expression values failed.\"\nre-progress 0.5\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}} --mrna\nre-checkrc \"Calculation of expression values failed.\"\nsamtools idxstats {{ alignment.bam.file }} | cut -f -2 | head -n -1 \u003E chrom.sizes\nre-checkrc \"Samtools idxstats command failed.\"\n\nmv expression_rc.tab.gz ${NAME}_expression_rc.tab.gz\nre-save-file rc_raw ${NAME}_expression_rc.tab.gz\n\nmv expression_rc_polya.tab.gz ${NAME}_expression_rc_polya.tab.gz\nre-save-file rc ${NAME}_expression_rc_polya.tab.gz\n\nmv expression_rpkm.tab.gz ${NAME}_expression_rpkm.tab.gz\nre-save-file rpkm ${NAME}_expression_rpkm.tab.gz\n\nmv expression_rpkm_polya.tab.gz ${NAME}_expression_rpkm_polya.tab.gz\nre-save-file rpkmpolya ${NAME}_expression_rpkm_polya.tab.gz\n\nmv expression_rpkum.tab.gz ${NAME}_expression_rpkum.tab.gz\nre-save-file rpkum ${NAME}_expression_rpkum.tab.gz\n\nmv expression_rpkum_polya.tab.gz ${NAME}_expression_rpkum_polya.tab.gz\nexpression2storage.py ${NAME}_expression_rpkum_polya.tab.gz --output json.txt\nre-checkrc\nre-save exp_json json.txt\nre-save-file exp ${NAME}_expression_rpkum_polya.tab.gz\n\nre-save source {{gff.source}}\nre-save species {{alignment.species}}\nre-save build {{alignment.build}}\nre-save feature_type gene\nre-save exp_type polyA\n",
        "runtime": "polyglot",
        "language": "bash"
      },
      "scheduling_class": "BA",
      "slug": "expression-dicty",
      "type": "data:expression:polya:",
      "version": "1.4.1"
    },
    "collection": {
      "created": "2022-03-22T10:48:54.505954+0000",
      "duplicated": None,
      "id": 2218,
      "modified": "2022-05-17T10:02:06.304553+0000",
      "data_count": 44,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "dictyExpress Parikh A et. al. dataset",
      "name": "D. purpureum, DpAX1, Parikh et al. 2015 (Growth: K. pneumoniae, Treatment: Filter Development)",
      "settings": {

      },
      "slug": "dictyexpress-purpureum-parikh-et-al",
      "tags": [
        "community:bcm"
      ],
      "entity_count": 14,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-03-23T13:37:04.890803+0000",
      "duplicated": None,
      "id": 66380,
      "modified": "2022-03-23T13:37:06.091122+0000",
      "data_count": 3,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "dpAX1_on_Ka_16Hr_bio1",
      "settings": {

      },
      "slug": "dpax1_on_ka_16hr_bio1fastqgz",
      "tags": [
        "community:bcm"
      ],
      "collection": 2218,
      "type": "sample"
    },
    "name": "dpAX1_on_Ka_16Hr_bio1_mapped.bam",
    "slug": "dpax1_on_ka_16hr_bio1_mappedbam",
    "tags": [
      "community:bcm"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "873d0c6303730376a3f7908087d2fab03520fffe309e27955be01b57ae60601e",
    "created": "2022-04-01T09:40:11.413770+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-04-01T09:57:41.953461+0000",
    "id": 389277,
    "modified": "2022-04-01T09:40:12.132240+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 16384,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "dpAX1_on_Ka_20Hr_bio2_mapped_expression_rc_polya.tab.gz",
        "size": 47833,
        "total_size": 47833
      },
      "exp": {
        "file": "dpAX1_on_Ka_20Hr_bio2_mapped_expression_rpkum_polya.tab.gz",
        "size": 112751,
        "total_size": 112751
      },
      "rpkm": {
        "file": "dpAX1_on_Ka_20Hr_bio2_mapped_expression_rpkm.tab.gz",
        "size": 111850,
        "total_size": 111850
      },
      "build": "dp-10-16-2014",
      "rpkum": {
        "file": "dpAX1_on_Ka_20Hr_bio2_mapped_expression_rpkum.tab.gz",
        "size": 112745,
        "total_size": 112745
      },
      "rc_raw": {
        "file": "dpAX1_on_Ka_20Hr_bio2_mapped_expression_rc.tab.gz",
        "size": 47827,
        "total_size": 47827
      },
      "source": "DICTYBASE",
      "species": "Dictyostelium purpureum",
      "exp_json": 476006,
      "exp_type": "polyA",
      "rpkmpolya": {
        "file": "dpAX1_on_Ka_20Hr_bio2_mapped_expression_rpkm_polya.tab.gz",
        "size": 111856,
        "total_size": 111856
      },
      "feature_type": "gene"
    },
    "scheduled": "2022-04-01T09:40:12.611154+0000",
    "size": 16092302,
    "started": "2022-04-01T09:42:26.440163+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "gff": 387805,
      "mappable": 387889,
      "alignment": 387883
    },
    "process": {
      "created": "2021-02-24T02:23:18.320496+0000",
      "id": 2177,
      "modified": "2021-11-17T06:04:16.445726+0000",
      "is_active": True,
      "category": "Other:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ alignment.bam.file|basename|default('?') }}",
      "description": "Dictyostelium-specific pipeline. Developed by Bioinformatics Laboratory,\nFaculty of Computer and Information Science, University of Ljubljana,\nSlovenia and Shaulsky Lab, Department of Molecular and Human Genetics,\nBaylor College of Medicine, Houston, TX, USA.\n",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "alignment",
          "type": "data:alignment:bam:",
          "label": "Aligned sequence"
        },
        {
          "name": "gff",
          "type": "data:annotation:gff3:",
          "label": "Features (GFF3)"
        },
        {
          "name": "mappable",
          "type": "data:mappability:bcm:",
          "label": "Mappability"
        }
      ],
      "name": "Dictyostelium expressions",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Expression RPKUM (polyA)",
          "description": "mRNA reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkmpolya",
          "type": "basic:file:",
          "label": "Expression RPKM (polyA)",
          "description": "mRNA reads scaled by exon length."
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (polyA)",
          "description": "mRNA reads uniquely mapped to gene exons."
        },
        {
          "name": "rpkum",
          "type": "basic:file:",
          "label": "Expression RPKUM",
          "description": "Reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkm",
          "type": "basic:file:",
          "label": "Expression RPKM",
          "description": "Reads scaled by exon length."
        },
        {
          "name": "rc_raw",
          "type": "basic:file:",
          "label": "Read counts (raw)",
          "description": "Reads uniquely mapped to gene exons."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression RPKUM (polyA) (json)"
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression Type (default output)"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID database"
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species"
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build"
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type"
        }
      ],
      "persistence": "CAC",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/s4q6j6e8/resolwebio/biox:2.0.0"
          }
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "NAME=`basename {{ alignment.bam.file }} .bam`\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}}\nre-checkrc \"Calculation of expression values failed.\"\nre-progress 0.5\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}} --mrna\nre-checkrc \"Calculation of expression values failed.\"\nsamtools idxstats {{ alignment.bam.file }} | cut -f -2 | head -n -1 \u003E chrom.sizes\nre-checkrc \"Samtools idxstats command failed.\"\n\nmv expression_rc.tab.gz ${NAME}_expression_rc.tab.gz\nre-save-file rc_raw ${NAME}_expression_rc.tab.gz\n\nmv expression_rc_polya.tab.gz ${NAME}_expression_rc_polya.tab.gz\nre-save-file rc ${NAME}_expression_rc_polya.tab.gz\n\nmv expression_rpkm.tab.gz ${NAME}_expression_rpkm.tab.gz\nre-save-file rpkm ${NAME}_expression_rpkm.tab.gz\n\nmv expression_rpkm_polya.tab.gz ${NAME}_expression_rpkm_polya.tab.gz\nre-save-file rpkmpolya ${NAME}_expression_rpkm_polya.tab.gz\n\nmv expression_rpkum.tab.gz ${NAME}_expression_rpkum.tab.gz\nre-save-file rpkum ${NAME}_expression_rpkum.tab.gz\n\nmv expression_rpkum_polya.tab.gz ${NAME}_expression_rpkum_polya.tab.gz\nexpression2storage.py ${NAME}_expression_rpkum_polya.tab.gz --output json.txt\nre-checkrc\nre-save exp_json json.txt\nre-save-file exp ${NAME}_expression_rpkum_polya.tab.gz\n\nre-save source {{gff.source}}\nre-save species {{alignment.species}}\nre-save build {{alignment.build}}\nre-save feature_type gene\nre-save exp_type polyA\n",
        "runtime": "polyglot",
        "language": "bash"
      },
      "scheduling_class": "BA",
      "slug": "expression-dicty",
      "type": "data:expression:polya:",
      "version": "1.4.1"
    },
    "collection": {
      "created": "2022-03-22T10:48:54.505954+0000",
      "duplicated": None,
      "id": 2218,
      "modified": "2022-05-17T10:02:06.304553+0000",
      "data_count": 44,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "dictyExpress Parikh A et. al. dataset",
      "name": "D. purpureum, DpAX1, Parikh et al. 2015 (Growth: K. pneumoniae, Treatment: Filter Development)",
      "settings": {

      },
      "slug": "dictyexpress-purpureum-parikh-et-al",
      "tags": [
        "community:bcm"
      ],
      "entity_count": 14,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-03-23T13:41:18.433487+0000",
      "duplicated": None,
      "id": 66383,
      "modified": "2022-03-23T13:41:19.620953+0000",
      "data_count": 3,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "dpAX1_on_Ka_20Hr_bio2",
      "settings": {

      },
      "slug": "dpax1_on_ka_20hr_bio2fastqgz",
      "tags": [
        "community:bcm"
      ],
      "collection": 2218,
      "type": "sample"
    },
    "name": "dpAX1_on_Ka_20Hr_bio2_mapped.bam",
    "slug": "dpax1_on_ka_20hr_bio2_mappedbam",
    "tags": [
      "community:bcm"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "45044fa786c177230be5ac49b0520bc278dcd0f56ec576917de1e5c0d0e9ca36",
    "created": "2022-04-01T09:40:11.388297+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-04-01T09:57:36.840780+0000",
    "id": 389276,
    "modified": "2022-04-01T09:40:11.878403+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 16384,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "dpAX1_on_Ka_20Hr_bio1_mapped_expression_rc_polya.tab.gz",
        "size": 46716,
        "total_size": 46716
      },
      "exp": {
        "file": "dpAX1_on_Ka_20Hr_bio1_mapped_expression_rpkum_polya.tab.gz",
        "size": 110603,
        "total_size": 110603
      },
      "rpkm": {
        "file": "dpAX1_on_Ka_20Hr_bio1_mapped_expression_rpkm.tab.gz",
        "size": 109848,
        "total_size": 109848
      },
      "build": "dp-10-16-2014",
      "rpkum": {
        "file": "dpAX1_on_Ka_20Hr_bio1_mapped_expression_rpkum.tab.gz",
        "size": 110597,
        "total_size": 110597
      },
      "rc_raw": {
        "file": "dpAX1_on_Ka_20Hr_bio1_mapped_expression_rc.tab.gz",
        "size": 46710,
        "total_size": 46710
      },
      "source": "DICTYBASE",
      "species": "Dictyostelium purpureum",
      "exp_json": 476004,
      "exp_type": "polyA",
      "rpkmpolya": {
        "file": "dpAX1_on_Ka_20Hr_bio1_mapped_expression_rpkm_polya.tab.gz",
        "size": 109854,
        "total_size": 109854
      },
      "feature_type": "gene"
    },
    "scheduled": "2022-04-01T09:40:12.239989+0000",
    "size": 16078516,
    "started": "2022-04-01T09:42:50.916300+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "gff": 387805,
      "mappable": 387889,
      "alignment": 387884
    },
    "process": {
      "created": "2021-02-24T02:23:18.320496+0000",
      "id": 2177,
      "modified": "2021-11-17T06:04:16.445726+0000",
      "is_active": True,
      "category": "Other:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ alignment.bam.file|basename|default('?') }}",
      "description": "Dictyostelium-specific pipeline. Developed by Bioinformatics Laboratory,\nFaculty of Computer and Information Science, University of Ljubljana,\nSlovenia and Shaulsky Lab, Department of Molecular and Human Genetics,\nBaylor College of Medicine, Houston, TX, USA.\n",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "alignment",
          "type": "data:alignment:bam:",
          "label": "Aligned sequence"
        },
        {
          "name": "gff",
          "type": "data:annotation:gff3:",
          "label": "Features (GFF3)"
        },
        {
          "name": "mappable",
          "type": "data:mappability:bcm:",
          "label": "Mappability"
        }
      ],
      "name": "Dictyostelium expressions",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Expression RPKUM (polyA)",
          "description": "mRNA reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkmpolya",
          "type": "basic:file:",
          "label": "Expression RPKM (polyA)",
          "description": "mRNA reads scaled by exon length."
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (polyA)",
          "description": "mRNA reads uniquely mapped to gene exons."
        },
        {
          "name": "rpkum",
          "type": "basic:file:",
          "label": "Expression RPKUM",
          "description": "Reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkm",
          "type": "basic:file:",
          "label": "Expression RPKM",
          "description": "Reads scaled by exon length."
        },
        {
          "name": "rc_raw",
          "type": "basic:file:",
          "label": "Read counts (raw)",
          "description": "Reads uniquely mapped to gene exons."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression RPKUM (polyA) (json)"
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression Type (default output)"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID database"
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species"
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build"
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type"
        }
      ],
      "persistence": "CAC",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/s4q6j6e8/resolwebio/biox:2.0.0"
          }
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "NAME=`basename {{ alignment.bam.file }} .bam`\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}}\nre-checkrc \"Calculation of expression values failed.\"\nre-progress 0.5\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}} --mrna\nre-checkrc \"Calculation of expression values failed.\"\nsamtools idxstats {{ alignment.bam.file }} | cut -f -2 | head -n -1 \u003E chrom.sizes\nre-checkrc \"Samtools idxstats command failed.\"\n\nmv expression_rc.tab.gz ${NAME}_expression_rc.tab.gz\nre-save-file rc_raw ${NAME}_expression_rc.tab.gz\n\nmv expression_rc_polya.tab.gz ${NAME}_expression_rc_polya.tab.gz\nre-save-file rc ${NAME}_expression_rc_polya.tab.gz\n\nmv expression_rpkm.tab.gz ${NAME}_expression_rpkm.tab.gz\nre-save-file rpkm ${NAME}_expression_rpkm.tab.gz\n\nmv expression_rpkm_polya.tab.gz ${NAME}_expression_rpkm_polya.tab.gz\nre-save-file rpkmpolya ${NAME}_expression_rpkm_polya.tab.gz\n\nmv expression_rpkum.tab.gz ${NAME}_expression_rpkum.tab.gz\nre-save-file rpkum ${NAME}_expression_rpkum.tab.gz\n\nmv expression_rpkum_polya.tab.gz ${NAME}_expression_rpkum_polya.tab.gz\nexpression2storage.py ${NAME}_expression_rpkum_polya.tab.gz --output json.txt\nre-checkrc\nre-save exp_json json.txt\nre-save-file exp ${NAME}_expression_rpkum_polya.tab.gz\n\nre-save source {{gff.source}}\nre-save species {{alignment.species}}\nre-save build {{alignment.build}}\nre-save feature_type gene\nre-save exp_type polyA\n",
        "runtime": "polyglot",
        "language": "bash"
      },
      "scheduling_class": "BA",
      "slug": "expression-dicty",
      "type": "data:expression:polya:",
      "version": "1.4.1"
    },
    "collection": {
      "created": "2022-03-22T10:48:54.505954+0000",
      "duplicated": None,
      "id": 2218,
      "modified": "2022-05-17T10:02:06.304553+0000",
      "data_count": 44,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "dictyExpress Parikh A et. al. dataset",
      "name": "D. purpureum, DpAX1, Parikh et al. 2015 (Growth: K. pneumoniae, Treatment: Filter Development)",
      "settings": {

      },
      "slug": "dictyexpress-purpureum-parikh-et-al",
      "tags": [
        "community:bcm"
      ],
      "entity_count": 14,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-03-23T13:39:42.269988+0000",
      "duplicated": None,
      "id": 66382,
      "modified": "2022-03-23T13:39:43.476886+0000",
      "data_count": 3,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "dpAX1_on_Ka_20Hr_bio1",
      "settings": {

      },
      "slug": "dpax1_on_ka_20hr_bio1fastqgz",
      "tags": [
        "community:bcm"
      ],
      "collection": 2218,
      "type": "sample"
    },
    "name": "dpAX1_on_Ka_20Hr_bio1_mapped.bam",
    "slug": "dpax1_on_ka_20hr_bio1_mappedbam",
    "tags": [
      "community:bcm"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "87ef11d831ab859cff81ea16dbc5320dc92d4e770ed394a967af3040b0b1f7bd",
    "created": "2022-04-01T09:40:11.383103+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-04-01T09:57:39.661916+0000",
    "id": 389275,
    "modified": "2022-04-01T09:40:12.192050+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 16384,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "dpAX1_on_Ka_16Hr_bio2_mapped_expression_rc_polya.tab.gz",
        "size": 47761,
        "total_size": 47761
      },
      "exp": {
        "file": "dpAX1_on_Ka_16Hr_bio2_mapped_expression_rpkum_polya.tab.gz",
        "size": 111655,
        "total_size": 111655
      },
      "rpkm": {
        "file": "dpAX1_on_Ka_16Hr_bio2_mapped_expression_rpkm.tab.gz",
        "size": 110988,
        "total_size": 110988
      },
      "build": "dp-10-16-2014",
      "rpkum": {
        "file": "dpAX1_on_Ka_16Hr_bio2_mapped_expression_rpkum.tab.gz",
        "size": 111649,
        "total_size": 111649
      },
      "rc_raw": {
        "file": "dpAX1_on_Ka_16Hr_bio2_mapped_expression_rc.tab.gz",
        "size": 47755,
        "total_size": 47755
      },
      "source": "DICTYBASE",
      "species": "Dictyostelium purpureum",
      "exp_json": 476005,
      "exp_type": "polyA",
      "rpkmpolya": {
        "file": "dpAX1_on_Ka_16Hr_bio2_mapped_expression_rpkm_polya.tab.gz",
        "size": 110994,
        "total_size": 110994
      },
      "feature_type": "gene"
    },
    "scheduled": "2022-04-01T09:40:12.638415+0000",
    "size": 16086648,
    "started": "2022-04-01T09:42:30.859526+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "gff": 387805,
      "mappable": 387889,
      "alignment": 387885
    },
    "process": {
      "created": "2021-02-24T02:23:18.320496+0000",
      "id": 2177,
      "modified": "2021-11-17T06:04:16.445726+0000",
      "is_active": True,
      "category": "Other:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ alignment.bam.file|basename|default('?') }}",
      "description": "Dictyostelium-specific pipeline. Developed by Bioinformatics Laboratory,\nFaculty of Computer and Information Science, University of Ljubljana,\nSlovenia and Shaulsky Lab, Department of Molecular and Human Genetics,\nBaylor College of Medicine, Houston, TX, USA.\n",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "alignment",
          "type": "data:alignment:bam:",
          "label": "Aligned sequence"
        },
        {
          "name": "gff",
          "type": "data:annotation:gff3:",
          "label": "Features (GFF3)"
        },
        {
          "name": "mappable",
          "type": "data:mappability:bcm:",
          "label": "Mappability"
        }
      ],
      "name": "Dictyostelium expressions",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Expression RPKUM (polyA)",
          "description": "mRNA reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkmpolya",
          "type": "basic:file:",
          "label": "Expression RPKM (polyA)",
          "description": "mRNA reads scaled by exon length."
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (polyA)",
          "description": "mRNA reads uniquely mapped to gene exons."
        },
        {
          "name": "rpkum",
          "type": "basic:file:",
          "label": "Expression RPKUM",
          "description": "Reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkm",
          "type": "basic:file:",
          "label": "Expression RPKM",
          "description": "Reads scaled by exon length."
        },
        {
          "name": "rc_raw",
          "type": "basic:file:",
          "label": "Read counts (raw)",
          "description": "Reads uniquely mapped to gene exons."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression RPKUM (polyA) (json)"
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression Type (default output)"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID database"
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species"
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build"
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type"
        }
      ],
      "persistence": "CAC",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/s4q6j6e8/resolwebio/biox:2.0.0"
          }
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "NAME=`basename {{ alignment.bam.file }} .bam`\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}}\nre-checkrc \"Calculation of expression values failed.\"\nre-progress 0.5\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}} --mrna\nre-checkrc \"Calculation of expression values failed.\"\nsamtools idxstats {{ alignment.bam.file }} | cut -f -2 | head -n -1 \u003E chrom.sizes\nre-checkrc \"Samtools idxstats command failed.\"\n\nmv expression_rc.tab.gz ${NAME}_expression_rc.tab.gz\nre-save-file rc_raw ${NAME}_expression_rc.tab.gz\n\nmv expression_rc_polya.tab.gz ${NAME}_expression_rc_polya.tab.gz\nre-save-file rc ${NAME}_expression_rc_polya.tab.gz\n\nmv expression_rpkm.tab.gz ${NAME}_expression_rpkm.tab.gz\nre-save-file rpkm ${NAME}_expression_rpkm.tab.gz\n\nmv expression_rpkm_polya.tab.gz ${NAME}_expression_rpkm_polya.tab.gz\nre-save-file rpkmpolya ${NAME}_expression_rpkm_polya.tab.gz\n\nmv expression_rpkum.tab.gz ${NAME}_expression_rpkum.tab.gz\nre-save-file rpkum ${NAME}_expression_rpkum.tab.gz\n\nmv expression_rpkum_polya.tab.gz ${NAME}_expression_rpkum_polya.tab.gz\nexpression2storage.py ${NAME}_expression_rpkum_polya.tab.gz --output json.txt\nre-checkrc\nre-save exp_json json.txt\nre-save-file exp ${NAME}_expression_rpkum_polya.tab.gz\n\nre-save source {{gff.source}}\nre-save species {{alignment.species}}\nre-save build {{alignment.build}}\nre-save feature_type gene\nre-save exp_type polyA\n",
        "runtime": "polyglot",
        "language": "bash"
      },
      "scheduling_class": "BA",
      "slug": "expression-dicty",
      "type": "data:expression:polya:",
      "version": "1.4.1"
    },
    "collection": {
      "created": "2022-03-22T10:48:54.505954+0000",
      "duplicated": None,
      "id": 2218,
      "modified": "2022-05-17T10:02:06.304553+0000",
      "data_count": 44,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "dictyExpress Parikh A et. al. dataset",
      "name": "D. purpureum, DpAX1, Parikh et al. 2015 (Growth: K. pneumoniae, Treatment: Filter Development)",
      "settings": {

      },
      "slug": "dictyexpress-purpureum-parikh-et-al",
      "tags": [
        "community:bcm"
      ],
      "entity_count": 14,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-03-23T13:38:29.166305+0000",
      "duplicated": None,
      "id": 66381,
      "modified": "2022-03-23T13:38:30.320601+0000",
      "data_count": 3,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "dpAX1_on_Ka_16Hr_bio2",
      "settings": {

      },
      "slug": "dpax1_on_ka_16hr_bio2fastqgz",
      "tags": [
        "community:bcm"
      ],
      "collection": 2218,
      "type": "sample"
    },
    "name": "dpAX1_on_Ka_16Hr_bio2_mapped.bam",
    "slug": "dpax1_on_ka_16hr_bio2_mappedbam",
    "tags": [
      "community:bcm"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "46373f0b1f2308ba9b8d80dfbdcc39016f9361141aa948b6cd89679749250dd4",
    "created": "2022-04-01T09:40:10.116424+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-04-01T09:58:09.066669+0000",
    "id": 389274,
    "modified": "2022-04-01T09:40:10.700189+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 16384,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "dpAX1_on_Ka_12Hr_bio2_mapped_expression_rc_polya.tab.gz",
        "size": 48340,
        "total_size": 48340
      },
      "exp": {
        "file": "dpAX1_on_Ka_12Hr_bio2_mapped_expression_rpkum_polya.tab.gz",
        "size": 112206,
        "total_size": 112206
      },
      "rpkm": {
        "file": "dpAX1_on_Ka_12Hr_bio2_mapped_expression_rpkm.tab.gz",
        "size": 111431,
        "total_size": 111431
      },
      "build": "dp-10-16-2014",
      "rpkum": {
        "file": "dpAX1_on_Ka_12Hr_bio2_mapped_expression_rpkum.tab.gz",
        "size": 112200,
        "total_size": 112200
      },
      "rc_raw": {
        "file": "dpAX1_on_Ka_12Hr_bio2_mapped_expression_rc.tab.gz",
        "size": 48334,
        "total_size": 48334
      },
      "source": "DICTYBASE",
      "species": "Dictyostelium purpureum",
      "exp_json": 476008,
      "exp_type": "polyA",
      "rpkmpolya": {
        "file": "dpAX1_on_Ka_12Hr_bio2_mapped_expression_rpkm_polya.tab.gz",
        "size": 111437,
        "total_size": 111437
      },
      "feature_type": "gene"
    },
    "scheduled": "2022-04-01T09:40:11.178307+0000",
    "size": 16090226,
    "started": "2022-04-01T09:42:28.901631+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "gff": 387805,
      "mappable": 387889,
      "alignment": 387882
    },
    "process": {
      "created": "2021-02-24T02:23:18.320496+0000",
      "id": 2177,
      "modified": "2021-11-17T06:04:16.445726+0000",
      "is_active": True,
      "category": "Other:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ alignment.bam.file|basename|default('?') }}",
      "description": "Dictyostelium-specific pipeline. Developed by Bioinformatics Laboratory,\nFaculty of Computer and Information Science, University of Ljubljana,\nSlovenia and Shaulsky Lab, Department of Molecular and Human Genetics,\nBaylor College of Medicine, Houston, TX, USA.\n",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "alignment",
          "type": "data:alignment:bam:",
          "label": "Aligned sequence"
        },
        {
          "name": "gff",
          "type": "data:annotation:gff3:",
          "label": "Features (GFF3)"
        },
        {
          "name": "mappable",
          "type": "data:mappability:bcm:",
          "label": "Mappability"
        }
      ],
      "name": "Dictyostelium expressions",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Expression RPKUM (polyA)",
          "description": "mRNA reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkmpolya",
          "type": "basic:file:",
          "label": "Expression RPKM (polyA)",
          "description": "mRNA reads scaled by exon length."
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (polyA)",
          "description": "mRNA reads uniquely mapped to gene exons."
        },
        {
          "name": "rpkum",
          "type": "basic:file:",
          "label": "Expression RPKUM",
          "description": "Reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkm",
          "type": "basic:file:",
          "label": "Expression RPKM",
          "description": "Reads scaled by exon length."
        },
        {
          "name": "rc_raw",
          "type": "basic:file:",
          "label": "Read counts (raw)",
          "description": "Reads uniquely mapped to gene exons."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression RPKUM (polyA) (json)"
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression Type (default output)"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID database"
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species"
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build"
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type"
        }
      ],
      "persistence": "CAC",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/s4q6j6e8/resolwebio/biox:2.0.0"
          }
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "NAME=`basename {{ alignment.bam.file }} .bam`\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}}\nre-checkrc \"Calculation of expression values failed.\"\nre-progress 0.5\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}} --mrna\nre-checkrc \"Calculation of expression values failed.\"\nsamtools idxstats {{ alignment.bam.file }} | cut -f -2 | head -n -1 \u003E chrom.sizes\nre-checkrc \"Samtools idxstats command failed.\"\n\nmv expression_rc.tab.gz ${NAME}_expression_rc.tab.gz\nre-save-file rc_raw ${NAME}_expression_rc.tab.gz\n\nmv expression_rc_polya.tab.gz ${NAME}_expression_rc_polya.tab.gz\nre-save-file rc ${NAME}_expression_rc_polya.tab.gz\n\nmv expression_rpkm.tab.gz ${NAME}_expression_rpkm.tab.gz\nre-save-file rpkm ${NAME}_expression_rpkm.tab.gz\n\nmv expression_rpkm_polya.tab.gz ${NAME}_expression_rpkm_polya.tab.gz\nre-save-file rpkmpolya ${NAME}_expression_rpkm_polya.tab.gz\n\nmv expression_rpkum.tab.gz ${NAME}_expression_rpkum.tab.gz\nre-save-file rpkum ${NAME}_expression_rpkum.tab.gz\n\nmv expression_rpkum_polya.tab.gz ${NAME}_expression_rpkum_polya.tab.gz\nexpression2storage.py ${NAME}_expression_rpkum_polya.tab.gz --output json.txt\nre-checkrc\nre-save exp_json json.txt\nre-save-file exp ${NAME}_expression_rpkum_polya.tab.gz\n\nre-save source {{gff.source}}\nre-save species {{alignment.species}}\nre-save build {{alignment.build}}\nre-save feature_type gene\nre-save exp_type polyA\n",
        "runtime": "polyglot",
        "language": "bash"
      },
      "scheduling_class": "BA",
      "slug": "expression-dicty",
      "type": "data:expression:polya:",
      "version": "1.4.1"
    },
    "collection": {
      "created": "2022-03-22T10:48:54.505954+0000",
      "duplicated": None,
      "id": 2218,
      "modified": "2022-05-17T10:02:06.304553+0000",
      "data_count": 44,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "dictyExpress Parikh A et. al. dataset",
      "name": "D. purpureum, DpAX1, Parikh et al. 2015 (Growth: K. pneumoniae, Treatment: Filter Development)",
      "settings": {

      },
      "slug": "dictyexpress-purpureum-parikh-et-al",
      "tags": [
        "community:bcm"
      ],
      "entity_count": 14,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-03-23T13:35:40.952850+0000",
      "duplicated": None,
      "id": 66379,
      "modified": "2022-03-23T13:35:42.134323+0000",
      "data_count": 3,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "dpAX1_on_Ka_12Hr_bio2",
      "settings": {

      },
      "slug": "dpax1_on_ka_12hr_bio2fastqgz",
      "tags": [
        "community:bcm"
      ],
      "collection": 2218,
      "type": "sample"
    },
    "name": "dpAX1_on_Ka_12Hr_bio2_mapped.bam",
    "slug": "dpax1_on_ka_12hr_bio2_mappedbam",
    "tags": [
      "community:bcm"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "1248b2ab13c7cf4ebab6efbb9f75cf6ada2b03d003741223a7195fbd4ef7a93c",
    "created": "2022-04-01T09:40:10.107990+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-04-01T09:57:28.148415+0000",
    "id": 389273,
    "modified": "2022-04-01T09:40:10.676858+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 16384,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "dpAX1_on_Ka_12Hr_bio1_mapped_expression_rc_polya.tab.gz",
        "size": 47373,
        "total_size": 47373
      },
      "exp": {
        "file": "dpAX1_on_Ka_12Hr_bio1_mapped_expression_rpkum_polya.tab.gz",
        "size": 110695,
        "total_size": 110695
      },
      "rpkm": {
        "file": "dpAX1_on_Ka_12Hr_bio1_mapped_expression_rpkm.tab.gz",
        "size": 110125,
        "total_size": 110125
      },
      "build": "dp-10-16-2014",
      "rpkum": {
        "file": "dpAX1_on_Ka_12Hr_bio1_mapped_expression_rpkum.tab.gz",
        "size": 110689,
        "total_size": 110689
      },
      "rc_raw": {
        "file": "dpAX1_on_Ka_12Hr_bio1_mapped_expression_rc.tab.gz",
        "size": 47367,
        "total_size": 47367
      },
      "source": "DICTYBASE",
      "species": "Dictyostelium purpureum",
      "exp_json": 476003,
      "exp_type": "polyA",
      "rpkmpolya": {
        "file": "dpAX1_on_Ka_12Hr_bio1_mapped_expression_rpkm_polya.tab.gz",
        "size": 110131,
        "total_size": 110131
      },
      "feature_type": "gene"
    },
    "scheduled": "2022-04-01T09:40:11.155480+0000",
    "size": 16080207,
    "started": "2022-04-01T09:42:26.436110+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "gff": 387805,
      "mappable": 387889,
      "alignment": 387881
    },
    "process": {
      "created": "2021-02-24T02:23:18.320496+0000",
      "id": 2177,
      "modified": "2021-11-17T06:04:16.445726+0000",
      "is_active": True,
      "category": "Other:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ alignment.bam.file|basename|default('?') }}",
      "description": "Dictyostelium-specific pipeline. Developed by Bioinformatics Laboratory,\nFaculty of Computer and Information Science, University of Ljubljana,\nSlovenia and Shaulsky Lab, Department of Molecular and Human Genetics,\nBaylor College of Medicine, Houston, TX, USA.\n",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "alignment",
          "type": "data:alignment:bam:",
          "label": "Aligned sequence"
        },
        {
          "name": "gff",
          "type": "data:annotation:gff3:",
          "label": "Features (GFF3)"
        },
        {
          "name": "mappable",
          "type": "data:mappability:bcm:",
          "label": "Mappability"
        }
      ],
      "name": "Dictyostelium expressions",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Expression RPKUM (polyA)",
          "description": "mRNA reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkmpolya",
          "type": "basic:file:",
          "label": "Expression RPKM (polyA)",
          "description": "mRNA reads scaled by exon length."
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (polyA)",
          "description": "mRNA reads uniquely mapped to gene exons."
        },
        {
          "name": "rpkum",
          "type": "basic:file:",
          "label": "Expression RPKUM",
          "description": "Reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkm",
          "type": "basic:file:",
          "label": "Expression RPKM",
          "description": "Reads scaled by exon length."
        },
        {
          "name": "rc_raw",
          "type": "basic:file:",
          "label": "Read counts (raw)",
          "description": "Reads uniquely mapped to gene exons."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression RPKUM (polyA) (json)"
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression Type (default output)"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID database"
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species"
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build"
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type"
        }
      ],
      "persistence": "CAC",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/s4q6j6e8/resolwebio/biox:2.0.0"
          }
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "NAME=`basename {{ alignment.bam.file }} .bam`\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}}\nre-checkrc \"Calculation of expression values failed.\"\nre-progress 0.5\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}} --mrna\nre-checkrc \"Calculation of expression values failed.\"\nsamtools idxstats {{ alignment.bam.file }} | cut -f -2 | head -n -1 \u003E chrom.sizes\nre-checkrc \"Samtools idxstats command failed.\"\n\nmv expression_rc.tab.gz ${NAME}_expression_rc.tab.gz\nre-save-file rc_raw ${NAME}_expression_rc.tab.gz\n\nmv expression_rc_polya.tab.gz ${NAME}_expression_rc_polya.tab.gz\nre-save-file rc ${NAME}_expression_rc_polya.tab.gz\n\nmv expression_rpkm.tab.gz ${NAME}_expression_rpkm.tab.gz\nre-save-file rpkm ${NAME}_expression_rpkm.tab.gz\n\nmv expression_rpkm_polya.tab.gz ${NAME}_expression_rpkm_polya.tab.gz\nre-save-file rpkmpolya ${NAME}_expression_rpkm_polya.tab.gz\n\nmv expression_rpkum.tab.gz ${NAME}_expression_rpkum.tab.gz\nre-save-file rpkum ${NAME}_expression_rpkum.tab.gz\n\nmv expression_rpkum_polya.tab.gz ${NAME}_expression_rpkum_polya.tab.gz\nexpression2storage.py ${NAME}_expression_rpkum_polya.tab.gz --output json.txt\nre-checkrc\nre-save exp_json json.txt\nre-save-file exp ${NAME}_expression_rpkum_polya.tab.gz\n\nre-save source {{gff.source}}\nre-save species {{alignment.species}}\nre-save build {{alignment.build}}\nre-save feature_type gene\nre-save exp_type polyA\n",
        "runtime": "polyglot",
        "language": "bash"
      },
      "scheduling_class": "BA",
      "slug": "expression-dicty",
      "type": "data:expression:polya:",
      "version": "1.4.1"
    },
    "collection": {
      "created": "2022-03-22T10:48:54.505954+0000",
      "duplicated": None,
      "id": 2218,
      "modified": "2022-05-17T10:02:06.304553+0000",
      "data_count": 44,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "dictyExpress Parikh A et. al. dataset",
      "name": "D. purpureum, DpAX1, Parikh et al. 2015 (Growth: K. pneumoniae, Treatment: Filter Development)",
      "settings": {

      },
      "slug": "dictyexpress-purpureum-parikh-et-al",
      "tags": [
        "community:bcm"
      ],
      "entity_count": 14,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-03-23T13:33:41.007341+0000",
      "duplicated": None,
      "id": 66378,
      "modified": "2022-03-23T13:33:42.209671+0000",
      "data_count": 3,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "dpAX1_on_Ka_12Hr_bio1",
      "settings": {

      },
      "slug": "dpax1_on_ka_12hr_bio1fastqgz",
      "tags": [
        "community:bcm"
      ],
      "collection": 2218,
      "type": "sample"
    },
    "name": "dpAX1_on_Ka_12Hr_bio1_mapped.bam",
    "slug": "dpax1_on_ka_12hr_bio1_mappedbam",
    "tags": [
      "community:bcm"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "003a17083aac7fa7ff69064b94a0afe6ae8d6683a9b3cc23a080c571f9710aec",
    "created": "2022-04-01T09:40:10.103495+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-04-01T09:57:24.750872+0000",
    "id": 389272,
    "modified": "2022-04-01T09:40:10.626059+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 16384,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "dpAX1_on_Ka_08Hr_bio1_mapped_expression_rc_polya.tab.gz",
        "size": 47374,
        "total_size": 47374
      },
      "exp": {
        "file": "dpAX1_on_Ka_08Hr_bio1_mapped_expression_rpkum_polya.tab.gz",
        "size": 111053,
        "total_size": 111053
      },
      "rpkm": {
        "file": "dpAX1_on_Ka_08Hr_bio1_mapped_expression_rpkm.tab.gz",
        "size": 110518,
        "total_size": 110518
      },
      "build": "dp-10-16-2014",
      "rpkum": {
        "file": "dpAX1_on_Ka_08Hr_bio1_mapped_expression_rpkum.tab.gz",
        "size": 111047,
        "total_size": 111047
      },
      "rc_raw": {
        "file": "dpAX1_on_Ka_08Hr_bio1_mapped_expression_rc.tab.gz",
        "size": 47368,
        "total_size": 47368
      },
      "source": "DICTYBASE",
      "species": "Dictyostelium purpureum",
      "exp_json": 476002,
      "exp_type": "polyA",
      "rpkmpolya": {
        "file": "dpAX1_on_Ka_08Hr_bio1_mapped_expression_rpkm_polya.tab.gz",
        "size": 110524,
        "total_size": 110524
      },
      "feature_type": "gene"
    },
    "scheduled": "2022-04-01T09:40:11.095448+0000",
    "size": 16082394,
    "started": "2022-04-01T09:42:26.443265+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "gff": 387805,
      "mappable": 387889,
      "alignment": 387879
    },
    "process": {
      "created": "2021-02-24T02:23:18.320496+0000",
      "id": 2177,
      "modified": "2021-11-17T06:04:16.445726+0000",
      "is_active": True,
      "category": "Other:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ alignment.bam.file|basename|default('?') }}",
      "description": "Dictyostelium-specific pipeline. Developed by Bioinformatics Laboratory,\nFaculty of Computer and Information Science, University of Ljubljana,\nSlovenia and Shaulsky Lab, Department of Molecular and Human Genetics,\nBaylor College of Medicine, Houston, TX, USA.\n",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "alignment",
          "type": "data:alignment:bam:",
          "label": "Aligned sequence"
        },
        {
          "name": "gff",
          "type": "data:annotation:gff3:",
          "label": "Features (GFF3)"
        },
        {
          "name": "mappable",
          "type": "data:mappability:bcm:",
          "label": "Mappability"
        }
      ],
      "name": "Dictyostelium expressions",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Expression RPKUM (polyA)",
          "description": "mRNA reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkmpolya",
          "type": "basic:file:",
          "label": "Expression RPKM (polyA)",
          "description": "mRNA reads scaled by exon length."
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (polyA)",
          "description": "mRNA reads uniquely mapped to gene exons."
        },
        {
          "name": "rpkum",
          "type": "basic:file:",
          "label": "Expression RPKUM",
          "description": "Reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkm",
          "type": "basic:file:",
          "label": "Expression RPKM",
          "description": "Reads scaled by exon length."
        },
        {
          "name": "rc_raw",
          "type": "basic:file:",
          "label": "Read counts (raw)",
          "description": "Reads uniquely mapped to gene exons."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression RPKUM (polyA) (json)"
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression Type (default output)"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID database"
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species"
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build"
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type"
        }
      ],
      "persistence": "CAC",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/s4q6j6e8/resolwebio/biox:2.0.0"
          }
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "NAME=`basename {{ alignment.bam.file }} .bam`\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}}\nre-checkrc \"Calculation of expression values failed.\"\nre-progress 0.5\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}} --mrna\nre-checkrc \"Calculation of expression values failed.\"\nsamtools idxstats {{ alignment.bam.file }} | cut -f -2 | head -n -1 \u003E chrom.sizes\nre-checkrc \"Samtools idxstats command failed.\"\n\nmv expression_rc.tab.gz ${NAME}_expression_rc.tab.gz\nre-save-file rc_raw ${NAME}_expression_rc.tab.gz\n\nmv expression_rc_polya.tab.gz ${NAME}_expression_rc_polya.tab.gz\nre-save-file rc ${NAME}_expression_rc_polya.tab.gz\n\nmv expression_rpkm.tab.gz ${NAME}_expression_rpkm.tab.gz\nre-save-file rpkm ${NAME}_expression_rpkm.tab.gz\n\nmv expression_rpkm_polya.tab.gz ${NAME}_expression_rpkm_polya.tab.gz\nre-save-file rpkmpolya ${NAME}_expression_rpkm_polya.tab.gz\n\nmv expression_rpkum.tab.gz ${NAME}_expression_rpkum.tab.gz\nre-save-file rpkum ${NAME}_expression_rpkum.tab.gz\n\nmv expression_rpkum_polya.tab.gz ${NAME}_expression_rpkum_polya.tab.gz\nexpression2storage.py ${NAME}_expression_rpkum_polya.tab.gz --output json.txt\nre-checkrc\nre-save exp_json json.txt\nre-save-file exp ${NAME}_expression_rpkum_polya.tab.gz\n\nre-save source {{gff.source}}\nre-save species {{alignment.species}}\nre-save build {{alignment.build}}\nre-save feature_type gene\nre-save exp_type polyA\n",
        "runtime": "polyglot",
        "language": "bash"
      },
      "scheduling_class": "BA",
      "slug": "expression-dicty",
      "type": "data:expression:polya:",
      "version": "1.4.1"
    },
    "collection": {
      "created": "2022-03-22T10:48:54.505954+0000",
      "duplicated": None,
      "id": 2218,
      "modified": "2022-05-17T10:02:06.304553+0000",
      "data_count": 44,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "dictyExpress Parikh A et. al. dataset",
      "name": "D. purpureum, DpAX1, Parikh et al. 2015 (Growth: K. pneumoniae, Treatment: Filter Development)",
      "settings": {

      },
      "slug": "dictyexpress-purpureum-parikh-et-al",
      "tags": [
        "community:bcm"
      ],
      "entity_count": 14,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-03-23T13:29:51.845517+0000",
      "duplicated": None,
      "id": 66376,
      "modified": "2022-03-23T13:29:53.019543+0000",
      "data_count": 3,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "dpAX1_on_Ka_08Hr_bio1",
      "settings": {

      },
      "slug": "dpax1_on_ka_08hr_bio1fastqgz",
      "tags": [
        "community:bcm"
      ],
      "collection": 2218,
      "type": "sample"
    },
    "name": "dpAX1_on_Ka_08Hr_bio1_mapped.bam",
    "slug": "dpax1_on_ka_08hr_bio1_mappedbam",
    "tags": [
      "community:bcm"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "0896c58de980811272a055c465daf296ce4350663ca10efd14e8eaede1ad2496",
    "created": "2022-04-01T09:40:10.098261+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-04-01T09:56:41.609032+0000",
    "id": 389271,
    "modified": "2022-04-01T09:40:10.620046+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 16384,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "dpAX1_on_Ka_08Hr_bio2_mapped_expression_rc_polya.tab.gz",
        "size": 48825,
        "total_size": 48825
      },
      "exp": {
        "file": "dpAX1_on_Ka_08Hr_bio2_mapped_expression_rpkum_polya.tab.gz",
        "size": 113355,
        "total_size": 113355
      },
      "rpkm": {
        "file": "dpAX1_on_Ka_08Hr_bio2_mapped_expression_rpkm.tab.gz",
        "size": 112593,
        "total_size": 112593
      },
      "build": "dp-10-16-2014",
      "rpkum": {
        "file": "dpAX1_on_Ka_08Hr_bio2_mapped_expression_rpkum.tab.gz",
        "size": 113349,
        "total_size": 113349
      },
      "rc_raw": {
        "file": "dpAX1_on_Ka_08Hr_bio2_mapped_expression_rc.tab.gz",
        "size": 48819,
        "total_size": 48819
      },
      "source": "DICTYBASE",
      "species": "Dictyostelium purpureum",
      "exp_json": 476000,
      "exp_type": "polyA",
      "rpkmpolya": {
        "file": "dpAX1_on_Ka_08Hr_bio2_mapped_expression_rpkm_polya.tab.gz",
        "size": 112599,
        "total_size": 112599
      },
      "feature_type": "gene"
    },
    "scheduled": "2022-04-01T09:40:11.081642+0000",
    "size": 16097353,
    "started": "2022-04-01T09:42:55.482986+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "gff": 387805,
      "mappable": 387889,
      "alignment": 387880
    },
    "process": {
      "created": "2021-02-24T02:23:18.320496+0000",
      "id": 2177,
      "modified": "2021-11-17T06:04:16.445726+0000",
      "is_active": True,
      "category": "Other:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ alignment.bam.file|basename|default('?') }}",
      "description": "Dictyostelium-specific pipeline. Developed by Bioinformatics Laboratory,\nFaculty of Computer and Information Science, University of Ljubljana,\nSlovenia and Shaulsky Lab, Department of Molecular and Human Genetics,\nBaylor College of Medicine, Houston, TX, USA.\n",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "alignment",
          "type": "data:alignment:bam:",
          "label": "Aligned sequence"
        },
        {
          "name": "gff",
          "type": "data:annotation:gff3:",
          "label": "Features (GFF3)"
        },
        {
          "name": "mappable",
          "type": "data:mappability:bcm:",
          "label": "Mappability"
        }
      ],
      "name": "Dictyostelium expressions",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Expression RPKUM (polyA)",
          "description": "mRNA reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkmpolya",
          "type": "basic:file:",
          "label": "Expression RPKM (polyA)",
          "description": "mRNA reads scaled by exon length."
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (polyA)",
          "description": "mRNA reads uniquely mapped to gene exons."
        },
        {
          "name": "rpkum",
          "type": "basic:file:",
          "label": "Expression RPKUM",
          "description": "Reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkm",
          "type": "basic:file:",
          "label": "Expression RPKM",
          "description": "Reads scaled by exon length."
        },
        {
          "name": "rc_raw",
          "type": "basic:file:",
          "label": "Read counts (raw)",
          "description": "Reads uniquely mapped to gene exons."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression RPKUM (polyA) (json)"
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression Type (default output)"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID database"
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species"
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build"
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type"
        }
      ],
      "persistence": "CAC",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/s4q6j6e8/resolwebio/biox:2.0.0"
          }
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "NAME=`basename {{ alignment.bam.file }} .bam`\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}}\nre-checkrc \"Calculation of expression values failed.\"\nre-progress 0.5\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}} --mrna\nre-checkrc \"Calculation of expression values failed.\"\nsamtools idxstats {{ alignment.bam.file }} | cut -f -2 | head -n -1 \u003E chrom.sizes\nre-checkrc \"Samtools idxstats command failed.\"\n\nmv expression_rc.tab.gz ${NAME}_expression_rc.tab.gz\nre-save-file rc_raw ${NAME}_expression_rc.tab.gz\n\nmv expression_rc_polya.tab.gz ${NAME}_expression_rc_polya.tab.gz\nre-save-file rc ${NAME}_expression_rc_polya.tab.gz\n\nmv expression_rpkm.tab.gz ${NAME}_expression_rpkm.tab.gz\nre-save-file rpkm ${NAME}_expression_rpkm.tab.gz\n\nmv expression_rpkm_polya.tab.gz ${NAME}_expression_rpkm_polya.tab.gz\nre-save-file rpkmpolya ${NAME}_expression_rpkm_polya.tab.gz\n\nmv expression_rpkum.tab.gz ${NAME}_expression_rpkum.tab.gz\nre-save-file rpkum ${NAME}_expression_rpkum.tab.gz\n\nmv expression_rpkum_polya.tab.gz ${NAME}_expression_rpkum_polya.tab.gz\nexpression2storage.py ${NAME}_expression_rpkum_polya.tab.gz --output json.txt\nre-checkrc\nre-save exp_json json.txt\nre-save-file exp ${NAME}_expression_rpkum_polya.tab.gz\n\nre-save source {{gff.source}}\nre-save species {{alignment.species}}\nre-save build {{alignment.build}}\nre-save feature_type gene\nre-save exp_type polyA\n",
        "runtime": "polyglot",
        "language": "bash"
      },
      "scheduling_class": "BA",
      "slug": "expression-dicty",
      "type": "data:expression:polya:",
      "version": "1.4.1"
    },
    "collection": {
      "created": "2022-03-22T10:48:54.505954+0000",
      "duplicated": None,
      "id": 2218,
      "modified": "2022-05-17T10:02:06.304553+0000",
      "data_count": 44,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "dictyExpress Parikh A et. al. dataset",
      "name": "D. purpureum, DpAX1, Parikh et al. 2015 (Growth: K. pneumoniae, Treatment: Filter Development)",
      "settings": {

      },
      "slug": "dictyexpress-purpureum-parikh-et-al",
      "tags": [
        "community:bcm"
      ],
      "entity_count": 14,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-03-23T13:32:27.692564+0000",
      "duplicated": None,
      "id": 66377,
      "modified": "2022-03-23T13:32:28.863024+0000",
      "data_count": 3,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "dpAX1_on_Ka_08Hr_bio2",
      "settings": {

      },
      "slug": "dpax1_on_ka_08hr_bio2fastqgz",
      "tags": [
        "community:bcm"
      ],
      "collection": 2218,
      "type": "sample"
    },
    "name": "dpAX1_on_Ka_08Hr_bio2_mapped.bam",
    "slug": "dpax1_on_ka_08hr_bio2_mappedbam",
    "tags": [
      "community:bcm"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "d6d97d6e90fab54ec7d8b7901758ddaf7ea8e6ca924f504d0dd80417eac73095",
    "created": "2022-04-01T09:40:09.229292+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-04-01T09:58:10.116428+0000",
    "id": 389270,
    "modified": "2022-04-01T09:40:09.672147+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 16384,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "dpAX1_on_Ka_04Hr_bio2_mapped_expression_rc_polya.tab.gz",
        "size": 48505,
        "total_size": 48505
      },
      "exp": {
        "file": "dpAX1_on_Ka_04Hr_bio2_mapped_expression_rpkum_polya.tab.gz",
        "size": 112794,
        "total_size": 112794
      },
      "rpkm": {
        "file": "dpAX1_on_Ka_04Hr_bio2_mapped_expression_rpkm.tab.gz",
        "size": 112052,
        "total_size": 112052
      },
      "build": "dp-10-16-2014",
      "rpkum": {
        "file": "dpAX1_on_Ka_04Hr_bio2_mapped_expression_rpkum.tab.gz",
        "size": 112788,
        "total_size": 112788
      },
      "rc_raw": {
        "file": "dpAX1_on_Ka_04Hr_bio2_mapped_expression_rc.tab.gz",
        "size": 48499,
        "total_size": 48499
      },
      "source": "DICTYBASE",
      "species": "Dictyostelium purpureum",
      "exp_json": 476009,
      "exp_type": "polyA",
      "rpkmpolya": {
        "file": "dpAX1_on_Ka_04Hr_bio2_mapped_expression_rpkm_polya.tab.gz",
        "size": 112058,
        "total_size": 112058
      },
      "feature_type": "gene"
    },
    "scheduled": "2022-04-01T09:40:10.000599+0000",
    "size": 16093419,
    "started": "2022-04-01T09:42:31.350454+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "gff": 387805,
      "mappable": 387889,
      "alignment": 387878
    },
    "process": {
      "created": "2021-02-24T02:23:18.320496+0000",
      "id": 2177,
      "modified": "2021-11-17T06:04:16.445726+0000",
      "is_active": True,
      "category": "Other:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ alignment.bam.file|basename|default('?') }}",
      "description": "Dictyostelium-specific pipeline. Developed by Bioinformatics Laboratory,\nFaculty of Computer and Information Science, University of Ljubljana,\nSlovenia and Shaulsky Lab, Department of Molecular and Human Genetics,\nBaylor College of Medicine, Houston, TX, USA.\n",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "alignment",
          "type": "data:alignment:bam:",
          "label": "Aligned sequence"
        },
        {
          "name": "gff",
          "type": "data:annotation:gff3:",
          "label": "Features (GFF3)"
        },
        {
          "name": "mappable",
          "type": "data:mappability:bcm:",
          "label": "Mappability"
        }
      ],
      "name": "Dictyostelium expressions",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Expression RPKUM (polyA)",
          "description": "mRNA reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkmpolya",
          "type": "basic:file:",
          "label": "Expression RPKM (polyA)",
          "description": "mRNA reads scaled by exon length."
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (polyA)",
          "description": "mRNA reads uniquely mapped to gene exons."
        },
        {
          "name": "rpkum",
          "type": "basic:file:",
          "label": "Expression RPKUM",
          "description": "Reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkm",
          "type": "basic:file:",
          "label": "Expression RPKM",
          "description": "Reads scaled by exon length."
        },
        {
          "name": "rc_raw",
          "type": "basic:file:",
          "label": "Read counts (raw)",
          "description": "Reads uniquely mapped to gene exons."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression RPKUM (polyA) (json)"
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression Type (default output)"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID database"
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species"
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build"
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type"
        }
      ],
      "persistence": "CAC",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/s4q6j6e8/resolwebio/biox:2.0.0"
          }
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "NAME=`basename {{ alignment.bam.file }} .bam`\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}}\nre-checkrc \"Calculation of expression values failed.\"\nre-progress 0.5\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}} --mrna\nre-checkrc \"Calculation of expression values failed.\"\nsamtools idxstats {{ alignment.bam.file }} | cut -f -2 | head -n -1 \u003E chrom.sizes\nre-checkrc \"Samtools idxstats command failed.\"\n\nmv expression_rc.tab.gz ${NAME}_expression_rc.tab.gz\nre-save-file rc_raw ${NAME}_expression_rc.tab.gz\n\nmv expression_rc_polya.tab.gz ${NAME}_expression_rc_polya.tab.gz\nre-save-file rc ${NAME}_expression_rc_polya.tab.gz\n\nmv expression_rpkm.tab.gz ${NAME}_expression_rpkm.tab.gz\nre-save-file rpkm ${NAME}_expression_rpkm.tab.gz\n\nmv expression_rpkm_polya.tab.gz ${NAME}_expression_rpkm_polya.tab.gz\nre-save-file rpkmpolya ${NAME}_expression_rpkm_polya.tab.gz\n\nmv expression_rpkum.tab.gz ${NAME}_expression_rpkum.tab.gz\nre-save-file rpkum ${NAME}_expression_rpkum.tab.gz\n\nmv expression_rpkum_polya.tab.gz ${NAME}_expression_rpkum_polya.tab.gz\nexpression2storage.py ${NAME}_expression_rpkum_polya.tab.gz --output json.txt\nre-checkrc\nre-save exp_json json.txt\nre-save-file exp ${NAME}_expression_rpkum_polya.tab.gz\n\nre-save source {{gff.source}}\nre-save species {{alignment.species}}\nre-save build {{alignment.build}}\nre-save feature_type gene\nre-save exp_type polyA\n",
        "runtime": "polyglot",
        "language": "bash"
      },
      "scheduling_class": "BA",
      "slug": "expression-dicty",
      "type": "data:expression:polya:",
      "version": "1.4.1"
    },
    "collection": {
      "created": "2022-03-22T10:48:54.505954+0000",
      "duplicated": None,
      "id": 2218,
      "modified": "2022-05-17T10:02:06.304553+0000",
      "data_count": 44,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "dictyExpress Parikh A et. al. dataset",
      "name": "D. purpureum, DpAX1, Parikh et al. 2015 (Growth: K. pneumoniae, Treatment: Filter Development)",
      "settings": {

      },
      "slug": "dictyexpress-purpureum-parikh-et-al",
      "tags": [
        "community:bcm"
      ],
      "entity_count": 14,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-03-23T13:28:20.476354+0000",
      "duplicated": None,
      "id": 66375,
      "modified": "2022-03-23T13:28:21.579066+0000",
      "data_count": 3,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "dpAX1_on_Ka_04Hr_bio2",
      "settings": {

      },
      "slug": "dpax1_on_ka_04hr_bio2fastqgz",
      "tags": [
        "community:bcm"
      ],
      "collection": 2218,
      "type": "sample"
    },
    "name": "dpAX1_on_Ka_04Hr_bio2_mapped.bam",
    "slug": "dpax1_on_ka_04hr_bio2_mappedbam",
    "tags": [
      "community:bcm"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "7c0576836f39105293aa6c48a7dcc63588f0299e968cf51d6c4e537b3d9aef63",
    "created": "2022-04-01T09:40:08.462061+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-04-01T09:56:03.253413+0000",
    "id": 389269,
    "modified": "2022-04-01T09:40:09.015598+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 16384,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "dpAX1_on_Ka_00Hr_bio1_mapped_expression_rc_polya.tab.gz",
        "size": 45803,
        "total_size": 45803
      },
      "exp": {
        "file": "dpAX1_on_Ka_00Hr_bio1_mapped_expression_rpkum_polya.tab.gz",
        "size": 107326,
        "total_size": 107326
      },
      "rpkm": {
        "file": "dpAX1_on_Ka_00Hr_bio1_mapped_expression_rpkm.tab.gz",
        "size": 106248,
        "total_size": 106248
      },
      "build": "dp-10-16-2014",
      "rpkum": {
        "file": "dpAX1_on_Ka_00Hr_bio1_mapped_expression_rpkum.tab.gz",
        "size": 107320,
        "total_size": 107320
      },
      "rc_raw": {
        "file": "dpAX1_on_Ka_00Hr_bio1_mapped_expression_rc.tab.gz",
        "size": 45797,
        "total_size": 45797
      },
      "source": "DICTYBASE",
      "species": "Dictyostelium purpureum",
      "exp_json": 475995,
      "exp_type": "polyA",
      "rpkmpolya": {
        "file": "dpAX1_on_Ka_00Hr_bio1_mapped_expression_rpkm_polya.tab.gz",
        "size": 106254,
        "total_size": 106254
      },
      "feature_type": "gene"
    },
    "scheduled": "2022-04-01T09:40:09.476534+0000",
    "size": 16057010,
    "started": "2022-04-01T09:40:31.006519+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "gff": 387805,
      "mappable": 387889,
      "alignment": 387876
    },
    "process": {
      "created": "2021-02-24T02:23:18.320496+0000",
      "id": 2177,
      "modified": "2021-11-17T06:04:16.445726+0000",
      "is_active": True,
      "category": "Other:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ alignment.bam.file|basename|default('?') }}",
      "description": "Dictyostelium-specific pipeline. Developed by Bioinformatics Laboratory,\nFaculty of Computer and Information Science, University of Ljubljana,\nSlovenia and Shaulsky Lab, Department of Molecular and Human Genetics,\nBaylor College of Medicine, Houston, TX, USA.\n",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "alignment",
          "type": "data:alignment:bam:",
          "label": "Aligned sequence"
        },
        {
          "name": "gff",
          "type": "data:annotation:gff3:",
          "label": "Features (GFF3)"
        },
        {
          "name": "mappable",
          "type": "data:mappability:bcm:",
          "label": "Mappability"
        }
      ],
      "name": "Dictyostelium expressions",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Expression RPKUM (polyA)",
          "description": "mRNA reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkmpolya",
          "type": "basic:file:",
          "label": "Expression RPKM (polyA)",
          "description": "mRNA reads scaled by exon length."
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (polyA)",
          "description": "mRNA reads uniquely mapped to gene exons."
        },
        {
          "name": "rpkum",
          "type": "basic:file:",
          "label": "Expression RPKUM",
          "description": "Reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkm",
          "type": "basic:file:",
          "label": "Expression RPKM",
          "description": "Reads scaled by exon length."
        },
        {
          "name": "rc_raw",
          "type": "basic:file:",
          "label": "Read counts (raw)",
          "description": "Reads uniquely mapped to gene exons."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression RPKUM (polyA) (json)"
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression Type (default output)"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID database"
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species"
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build"
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type"
        }
      ],
      "persistence": "CAC",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/s4q6j6e8/resolwebio/biox:2.0.0"
          }
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "NAME=`basename {{ alignment.bam.file }} .bam`\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}}\nre-checkrc \"Calculation of expression values failed.\"\nre-progress 0.5\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}} --mrna\nre-checkrc \"Calculation of expression values failed.\"\nsamtools idxstats {{ alignment.bam.file }} | cut -f -2 | head -n -1 \u003E chrom.sizes\nre-checkrc \"Samtools idxstats command failed.\"\n\nmv expression_rc.tab.gz ${NAME}_expression_rc.tab.gz\nre-save-file rc_raw ${NAME}_expression_rc.tab.gz\n\nmv expression_rc_polya.tab.gz ${NAME}_expression_rc_polya.tab.gz\nre-save-file rc ${NAME}_expression_rc_polya.tab.gz\n\nmv expression_rpkm.tab.gz ${NAME}_expression_rpkm.tab.gz\nre-save-file rpkm ${NAME}_expression_rpkm.tab.gz\n\nmv expression_rpkm_polya.tab.gz ${NAME}_expression_rpkm_polya.tab.gz\nre-save-file rpkmpolya ${NAME}_expression_rpkm_polya.tab.gz\n\nmv expression_rpkum.tab.gz ${NAME}_expression_rpkum.tab.gz\nre-save-file rpkum ${NAME}_expression_rpkum.tab.gz\n\nmv expression_rpkum_polya.tab.gz ${NAME}_expression_rpkum_polya.tab.gz\nexpression2storage.py ${NAME}_expression_rpkum_polya.tab.gz --output json.txt\nre-checkrc\nre-save exp_json json.txt\nre-save-file exp ${NAME}_expression_rpkum_polya.tab.gz\n\nre-save source {{gff.source}}\nre-save species {{alignment.species}}\nre-save build {{alignment.build}}\nre-save feature_type gene\nre-save exp_type polyA\n",
        "runtime": "polyglot",
        "language": "bash"
      },
      "scheduling_class": "BA",
      "slug": "expression-dicty",
      "type": "data:expression:polya:",
      "version": "1.4.1"
    },
    "collection": {
      "created": "2022-03-22T10:48:54.505954+0000",
      "duplicated": None,
      "id": 2218,
      "modified": "2022-05-17T10:02:06.304553+0000",
      "data_count": 44,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "dictyExpress Parikh A et. al. dataset",
      "name": "D. purpureum, DpAX1, Parikh et al. 2015 (Growth: K. pneumoniae, Treatment: Filter Development)",
      "settings": {

      },
      "slug": "dictyexpress-purpureum-parikh-et-al",
      "tags": [
        "community:bcm"
      ],
      "entity_count": 14,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-03-23T13:21:58.172644+0000",
      "duplicated": None,
      "id": 66372,
      "modified": "2022-03-23T13:21:59.460306+0000",
      "data_count": 3,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "dpAX1_on_Ka_00Hr_bio1",
      "settings": {

      },
      "slug": "dpax1_on_ka_00hr_bio1fastqgz",
      "tags": [
        "community:bcm"
      ],
      "collection": 2218,
      "type": "sample"
    },
    "name": "dpAX1_on_Ka_00Hr_bio1_mapped.bam",
    "slug": "dpax1_on_ka_00hr_bio1_mappedbam",
    "tags": [
      "community:bcm"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "d6f8dcdceda3809453e7b9eaa693b951c02f2e29542a56ba786251754aaad05a",
    "created": "2022-04-01T09:40:08.410018+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-04-01T09:56:04.343080+0000",
    "id": 389267,
    "modified": "2022-04-01T09:40:08.922483+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 16384,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "dpAX1_on_Ka_04Hr_bio1_mapped_expression_rc_polya.tab.gz",
        "size": 47133,
        "total_size": 47133
      },
      "exp": {
        "file": "dpAX1_on_Ka_04Hr_bio1_mapped_expression_rpkum_polya.tab.gz",
        "size": 110171,
        "total_size": 110171
      },
      "rpkm": {
        "file": "dpAX1_on_Ka_04Hr_bio1_mapped_expression_rpkm.tab.gz",
        "size": 109443,
        "total_size": 109443
      },
      "build": "dp-10-16-2014",
      "rpkum": {
        "file": "dpAX1_on_Ka_04Hr_bio1_mapped_expression_rpkum.tab.gz",
        "size": 110165,
        "total_size": 110165
      },
      "rc_raw": {
        "file": "dpAX1_on_Ka_04Hr_bio1_mapped_expression_rc.tab.gz",
        "size": 47127,
        "total_size": 47127
      },
      "source": "DICTYBASE",
      "species": "Dictyostelium purpureum",
      "exp_json": 475996,
      "exp_type": "polyA",
      "rpkmpolya": {
        "file": "dpAX1_on_Ka_04Hr_bio1_mapped_expression_rpkm_polya.tab.gz",
        "size": 109449,
        "total_size": 109449
      },
      "feature_type": "gene"
    },
    "scheduled": "2022-04-01T09:40:09.392779+0000",
    "size": 16076395,
    "started": "2022-04-01T09:40:29.269441+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "gff": 387805,
      "mappable": 387889,
      "alignment": 387877
    },
    "process": {
      "created": "2021-02-24T02:23:18.320496+0000",
      "id": 2177,
      "modified": "2021-11-17T06:04:16.445726+0000",
      "is_active": True,
      "category": "Other:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ alignment.bam.file|basename|default('?') }}",
      "description": "Dictyostelium-specific pipeline. Developed by Bioinformatics Laboratory,\nFaculty of Computer and Information Science, University of Ljubljana,\nSlovenia and Shaulsky Lab, Department of Molecular and Human Genetics,\nBaylor College of Medicine, Houston, TX, USA.\n",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "alignment",
          "type": "data:alignment:bam:",
          "label": "Aligned sequence"
        },
        {
          "name": "gff",
          "type": "data:annotation:gff3:",
          "label": "Features (GFF3)"
        },
        {
          "name": "mappable",
          "type": "data:mappability:bcm:",
          "label": "Mappability"
        }
      ],
      "name": "Dictyostelium expressions",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Expression RPKUM (polyA)",
          "description": "mRNA reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkmpolya",
          "type": "basic:file:",
          "label": "Expression RPKM (polyA)",
          "description": "mRNA reads scaled by exon length."
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (polyA)",
          "description": "mRNA reads uniquely mapped to gene exons."
        },
        {
          "name": "rpkum",
          "type": "basic:file:",
          "label": "Expression RPKUM",
          "description": "Reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkm",
          "type": "basic:file:",
          "label": "Expression RPKM",
          "description": "Reads scaled by exon length."
        },
        {
          "name": "rc_raw",
          "type": "basic:file:",
          "label": "Read counts (raw)",
          "description": "Reads uniquely mapped to gene exons."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression RPKUM (polyA) (json)"
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression Type (default output)"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID database"
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species"
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build"
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type"
        }
      ],
      "persistence": "CAC",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/s4q6j6e8/resolwebio/biox:2.0.0"
          }
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "NAME=`basename {{ alignment.bam.file }} .bam`\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}}\nre-checkrc \"Calculation of expression values failed.\"\nre-progress 0.5\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}} --mrna\nre-checkrc \"Calculation of expression values failed.\"\nsamtools idxstats {{ alignment.bam.file }} | cut -f -2 | head -n -1 \u003E chrom.sizes\nre-checkrc \"Samtools idxstats command failed.\"\n\nmv expression_rc.tab.gz ${NAME}_expression_rc.tab.gz\nre-save-file rc_raw ${NAME}_expression_rc.tab.gz\n\nmv expression_rc_polya.tab.gz ${NAME}_expression_rc_polya.tab.gz\nre-save-file rc ${NAME}_expression_rc_polya.tab.gz\n\nmv expression_rpkm.tab.gz ${NAME}_expression_rpkm.tab.gz\nre-save-file rpkm ${NAME}_expression_rpkm.tab.gz\n\nmv expression_rpkm_polya.tab.gz ${NAME}_expression_rpkm_polya.tab.gz\nre-save-file rpkmpolya ${NAME}_expression_rpkm_polya.tab.gz\n\nmv expression_rpkum.tab.gz ${NAME}_expression_rpkum.tab.gz\nre-save-file rpkum ${NAME}_expression_rpkum.tab.gz\n\nmv expression_rpkum_polya.tab.gz ${NAME}_expression_rpkum_polya.tab.gz\nexpression2storage.py ${NAME}_expression_rpkum_polya.tab.gz --output json.txt\nre-checkrc\nre-save exp_json json.txt\nre-save-file exp ${NAME}_expression_rpkum_polya.tab.gz\n\nre-save source {{gff.source}}\nre-save species {{alignment.species}}\nre-save build {{alignment.build}}\nre-save feature_type gene\nre-save exp_type polyA\n",
        "runtime": "polyglot",
        "language": "bash"
      },
      "scheduling_class": "BA",
      "slug": "expression-dicty",
      "type": "data:expression:polya:",
      "version": "1.4.1"
    },
    "collection": {
      "created": "2022-03-22T10:48:54.505954+0000",
      "duplicated": None,
      "id": 2218,
      "modified": "2022-05-17T10:02:06.304553+0000",
      "data_count": 44,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "dictyExpress Parikh A et. al. dataset",
      "name": "D. purpureum, DpAX1, Parikh et al. 2015 (Growth: K. pneumoniae, Treatment: Filter Development)",
      "settings": {

      },
      "slug": "dictyexpress-purpureum-parikh-et-al",
      "tags": [
        "community:bcm"
      ],
      "entity_count": 14,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-03-23T13:25:54.484765+0000",
      "duplicated": None,
      "id": 66374,
      "modified": "2022-03-23T13:25:55.641830+0000",
      "data_count": 3,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "dpAX1_on_Ka_04Hr_bio1",
      "settings": {

      },
      "slug": "dpax1_on_ka_04hr_bio1fastqgz",
      "tags": [
        "community:bcm"
      ],
      "collection": 2218,
      "type": "sample"
    },
    "name": "dpAX1_on_Ka_04Hr_bio1_mapped.bam",
    "slug": "dpax1_on_ka_04hr_bio1_mappedbam",
    "tags": [
      "community:bcm"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "56ce8411156f592bdb7250b14545f91b663d5fcde6b3cb28c0cd18e3626bf0ef",
    "created": "2022-04-01T09:40:08.410016+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-04-01T09:56:21.567304+0000",
    "id": 389268,
    "modified": "2022-04-01T09:40:08.848624+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 16384,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "dpAX1_on_Ka_00Hr_bio2_mapped_expression_rc_polya.tab.gz",
        "size": 47434,
        "total_size": 47434
      },
      "exp": {
        "file": "dpAX1_on_Ka_00Hr_bio2_mapped_expression_rpkum_polya.tab.gz",
        "size": 110226,
        "total_size": 110226
      },
      "rpkm": {
        "file": "dpAX1_on_Ka_00Hr_bio2_mapped_expression_rpkm.tab.gz",
        "size": 109454,
        "total_size": 109454
      },
      "build": "dp-10-16-2014",
      "rpkum": {
        "file": "dpAX1_on_Ka_00Hr_bio2_mapped_expression_rpkum.tab.gz",
        "size": 110220,
        "total_size": 110220
      },
      "rc_raw": {
        "file": "dpAX1_on_Ka_00Hr_bio2_mapped_expression_rc.tab.gz",
        "size": 47428,
        "total_size": 47428
      },
      "source": "DICTYBASE",
      "species": "Dictyostelium purpureum",
      "exp_json": 475999,
      "exp_type": "polyA",
      "rpkmpolya": {
        "file": "dpAX1_on_Ka_00Hr_bio2_mapped_expression_rpkm_polya.tab.gz",
        "size": 109460,
        "total_size": 109460
      },
      "feature_type": "gene"
    },
    "scheduled": "2022-04-01T09:40:09.268757+0000",
    "size": 16076910,
    "started": "2022-04-01T09:40:30.235402+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "gff": 387805,
      "mappable": 387889,
      "alignment": 387875
    },
    "process": {
      "created": "2021-02-24T02:23:18.320496+0000",
      "id": 2177,
      "modified": "2021-11-17T06:04:16.445726+0000",
      "is_active": True,
      "category": "Other:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ alignment.bam.file|basename|default('?') }}",
      "description": "Dictyostelium-specific pipeline. Developed by Bioinformatics Laboratory,\nFaculty of Computer and Information Science, University of Ljubljana,\nSlovenia and Shaulsky Lab, Department of Molecular and Human Genetics,\nBaylor College of Medicine, Houston, TX, USA.\n",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "alignment",
          "type": "data:alignment:bam:",
          "label": "Aligned sequence"
        },
        {
          "name": "gff",
          "type": "data:annotation:gff3:",
          "label": "Features (GFF3)"
        },
        {
          "name": "mappable",
          "type": "data:mappability:bcm:",
          "label": "Mappability"
        }
      ],
      "name": "Dictyostelium expressions",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Expression RPKUM (polyA)",
          "description": "mRNA reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkmpolya",
          "type": "basic:file:",
          "label": "Expression RPKM (polyA)",
          "description": "mRNA reads scaled by exon length."
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (polyA)",
          "description": "mRNA reads uniquely mapped to gene exons."
        },
        {
          "name": "rpkum",
          "type": "basic:file:",
          "label": "Expression RPKUM",
          "description": "Reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkm",
          "type": "basic:file:",
          "label": "Expression RPKM",
          "description": "Reads scaled by exon length."
        },
        {
          "name": "rc_raw",
          "type": "basic:file:",
          "label": "Read counts (raw)",
          "description": "Reads uniquely mapped to gene exons."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression RPKUM (polyA) (json)"
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression Type (default output)"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID database"
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species"
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build"
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type"
        }
      ],
      "persistence": "CAC",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/s4q6j6e8/resolwebio/biox:2.0.0"
          }
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "NAME=`basename {{ alignment.bam.file }} .bam`\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}}\nre-checkrc \"Calculation of expression values failed.\"\nre-progress 0.5\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}} --mrna\nre-checkrc \"Calculation of expression values failed.\"\nsamtools idxstats {{ alignment.bam.file }} | cut -f -2 | head -n -1 \u003E chrom.sizes\nre-checkrc \"Samtools idxstats command failed.\"\n\nmv expression_rc.tab.gz ${NAME}_expression_rc.tab.gz\nre-save-file rc_raw ${NAME}_expression_rc.tab.gz\n\nmv expression_rc_polya.tab.gz ${NAME}_expression_rc_polya.tab.gz\nre-save-file rc ${NAME}_expression_rc_polya.tab.gz\n\nmv expression_rpkm.tab.gz ${NAME}_expression_rpkm.tab.gz\nre-save-file rpkm ${NAME}_expression_rpkm.tab.gz\n\nmv expression_rpkm_polya.tab.gz ${NAME}_expression_rpkm_polya.tab.gz\nre-save-file rpkmpolya ${NAME}_expression_rpkm_polya.tab.gz\n\nmv expression_rpkum.tab.gz ${NAME}_expression_rpkum.tab.gz\nre-save-file rpkum ${NAME}_expression_rpkum.tab.gz\n\nmv expression_rpkum_polya.tab.gz ${NAME}_expression_rpkum_polya.tab.gz\nexpression2storage.py ${NAME}_expression_rpkum_polya.tab.gz --output json.txt\nre-checkrc\nre-save exp_json json.txt\nre-save-file exp ${NAME}_expression_rpkum_polya.tab.gz\n\nre-save source {{gff.source}}\nre-save species {{alignment.species}}\nre-save build {{alignment.build}}\nre-save feature_type gene\nre-save exp_type polyA\n",
        "runtime": "polyglot",
        "language": "bash"
      },
      "scheduling_class": "BA",
      "slug": "expression-dicty",
      "type": "data:expression:polya:",
      "version": "1.4.1"
    },
    "collection": {
      "created": "2022-03-22T10:48:54.505954+0000",
      "duplicated": None,
      "id": 2218,
      "modified": "2022-05-17T10:02:06.304553+0000",
      "data_count": 44,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "dictyExpress Parikh A et. al. dataset",
      "name": "D. purpureum, DpAX1, Parikh et al. 2015 (Growth: K. pneumoniae, Treatment: Filter Development)",
      "settings": {

      },
      "slug": "dictyexpress-purpureum-parikh-et-al",
      "tags": [
        "community:bcm"
      ],
      "entity_count": 14,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-03-23T13:24:27.456064+0000",
      "duplicated": None,
      "id": 66373,
      "modified": "2022-03-23T13:24:28.706222+0000",
      "data_count": 3,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "dpAX1_on_Ka_00Hr_bio2",
      "settings": {

      },
      "slug": "dpax1_on_ka_00hr_bio2fastqgz",
      "tags": [
        "community:bcm"
      ],
      "collection": 2218,
      "type": "sample"
    },
    "name": "dpAX1_on_Ka_00Hr_bio2_mapped.bam",
    "slug": "dpax1_on_ka_00hr_bio2_mappedbam",
    "tags": [
      "community:bcm"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "8bc83cd3870acaa64144994ef3691fb4af48cd1d19a5f38df994aa9b16e9b9e2",
    "created": "2022-03-24T12:03:17.430274+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-03-24T13:38:23.167725+0000",
    "id": 387874,
    "modified": "2022-03-24T13:25:37.584195+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 16384,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "dd_AX4_on_Ka_24Hr_bio1_mapped_expression_rc_polya.tab.gz",
        "size": 49159,
        "total_size": 49159
      },
      "exp": {
        "file": "dd_AX4_on_Ka_24Hr_bio1_mapped_expression_rpkum_polya.tab.gz",
        "size": 116417,
        "total_size": 116417
      },
      "rpkm": {
        "file": "dd_AX4_on_Ka_24Hr_bio1_mapped_expression_rpkm.tab.gz",
        "size": 115015,
        "total_size": 115015
      },
      "build": "dd-05-13-2009",
      "rpkum": {
        "file": "dd_AX4_on_Ka_24Hr_bio1_mapped_expression_rpkum.tab.gz",
        "size": 116292,
        "total_size": 116292
      },
      "rc_raw": {
        "file": "dd_AX4_on_Ka_24Hr_bio1_mapped_expression_rc.tab.gz",
        "size": 49222,
        "total_size": 49222
      },
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_json": 475627,
      "exp_type": "polyA",
      "rpkmpolya": {
        "file": "dd_AX4_on_Ka_24Hr_bio1_mapped_expression_rpkm_polya.tab.gz",
        "size": 115113,
        "total_size": 115113
      },
      "feature_type": "gene"
    },
    "scheduled": "2022-03-24T13:25:37.923533+0000",
    "size": 957342,
    "started": "2022-03-24T13:25:52.910806+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "gff": 387800,
      "mappable": 387852,
      "alignment": 387821
    },
    "process": {
      "created": "2021-02-24T02:23:18.320496+0000",
      "id": 2177,
      "modified": "2021-11-17T06:04:16.445726+0000",
      "is_active": True,
      "category": "Other:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ alignment.bam.file|basename|default('?') }}",
      "description": "Dictyostelium-specific pipeline. Developed by Bioinformatics Laboratory,\nFaculty of Computer and Information Science, University of Ljubljana,\nSlovenia and Shaulsky Lab, Department of Molecular and Human Genetics,\nBaylor College of Medicine, Houston, TX, USA.\n",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "alignment",
          "type": "data:alignment:bam:",
          "label": "Aligned sequence"
        },
        {
          "name": "gff",
          "type": "data:annotation:gff3:",
          "label": "Features (GFF3)"
        },
        {
          "name": "mappable",
          "type": "data:mappability:bcm:",
          "label": "Mappability"
        }
      ],
      "name": "Dictyostelium expressions",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Expression RPKUM (polyA)",
          "description": "mRNA reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkmpolya",
          "type": "basic:file:",
          "label": "Expression RPKM (polyA)",
          "description": "mRNA reads scaled by exon length."
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (polyA)",
          "description": "mRNA reads uniquely mapped to gene exons."
        },
        {
          "name": "rpkum",
          "type": "basic:file:",
          "label": "Expression RPKUM",
          "description": "Reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkm",
          "type": "basic:file:",
          "label": "Expression RPKM",
          "description": "Reads scaled by exon length."
        },
        {
          "name": "rc_raw",
          "type": "basic:file:",
          "label": "Read counts (raw)",
          "description": "Reads uniquely mapped to gene exons."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression RPKUM (polyA) (json)"
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression Type (default output)"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID database"
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species"
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build"
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type"
        }
      ],
      "persistence": "CAC",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/s4q6j6e8/resolwebio/biox:2.0.0"
          }
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "NAME=`basename {{ alignment.bam.file }} .bam`\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}}\nre-checkrc \"Calculation of expression values failed.\"\nre-progress 0.5\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}} --mrna\nre-checkrc \"Calculation of expression values failed.\"\nsamtools idxstats {{ alignment.bam.file }} | cut -f -2 | head -n -1 \u003E chrom.sizes\nre-checkrc \"Samtools idxstats command failed.\"\n\nmv expression_rc.tab.gz ${NAME}_expression_rc.tab.gz\nre-save-file rc_raw ${NAME}_expression_rc.tab.gz\n\nmv expression_rc_polya.tab.gz ${NAME}_expression_rc_polya.tab.gz\nre-save-file rc ${NAME}_expression_rc_polya.tab.gz\n\nmv expression_rpkm.tab.gz ${NAME}_expression_rpkm.tab.gz\nre-save-file rpkm ${NAME}_expression_rpkm.tab.gz\n\nmv expression_rpkm_polya.tab.gz ${NAME}_expression_rpkm_polya.tab.gz\nre-save-file rpkmpolya ${NAME}_expression_rpkm_polya.tab.gz\n\nmv expression_rpkum.tab.gz ${NAME}_expression_rpkum.tab.gz\nre-save-file rpkum ${NAME}_expression_rpkum.tab.gz\n\nmv expression_rpkum_polya.tab.gz ${NAME}_expression_rpkum_polya.tab.gz\nexpression2storage.py ${NAME}_expression_rpkum_polya.tab.gz --output json.txt\nre-checkrc\nre-save exp_json json.txt\nre-save-file exp ${NAME}_expression_rpkum_polya.tab.gz\n\nre-save source {{gff.source}}\nre-save species {{alignment.species}}\nre-save build {{alignment.build}}\nre-save feature_type gene\nre-save exp_type polyA\n",
        "runtime": "polyglot",
        "language": "bash"
      },
      "scheduling_class": "BA",
      "slug": "expression-dicty",
      "type": "data:expression:polya:",
      "version": "1.4.1"
    },
    "collection": {
      "created": "2022-03-22T10:47:57.116905+0000",
      "duplicated": None,
      "id": 2217,
      "modified": "2022-05-17T10:01:35.314628+0000",
      "data_count": 46,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "dictyExpress Parikh A et. al. dataset",
      "name": "D. discoideum, AX4, Parikh et al. 2015 (Growth: K. pneumoniae, Treatment: Filter Development)",
      "settings": {

      },
      "slug": "dictyexpress-discoideum-parikh-et-al",
      "tags": [
        "community:bcm"
      ],
      "entity_count": 14,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-03-23T14:12:38.339366+0000",
      "duplicated": None,
      "id": 66398,
      "modified": "2022-03-23T14:12:39.579694+0000",
      "data_count": 3,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "dd_AX4_on_Ka_24Hr_bio1",
      "settings": {

      },
      "slug": "dd_ax4_on_ka_24hr_bio1fastqgz",
      "tags": [
        "community:bcm"
      ],
      "collection": 2217,
      "type": "sample"
    },
    "name": "?",
    "slug": "data-279",
    "tags": [
      "community:bcm"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "780e5d80db67bf69c27ca13bd60f1dea9ee50bacc29da28afe5b9735aa28a546",
    "created": "2022-03-24T12:03:17.429957+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-03-24T12:19:34.031882+0000",
    "id": 387873,
    "modified": "2022-03-24T12:03:17.877372+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 16384,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "dd_AX4_on_Ka_24Hr_bio2_mapped_expression_rc_polya.tab.gz",
        "size": 50822,
        "total_size": 50822
      },
      "exp": {
        "file": "dd_AX4_on_Ka_24Hr_bio2_mapped_expression_rpkum_polya.tab.gz",
        "size": 116674,
        "total_size": 116674
      },
      "rpkm": {
        "file": "dd_AX4_on_Ka_24Hr_bio2_mapped_expression_rpkm.tab.gz",
        "size": 115715,
        "total_size": 115715
      },
      "build": "dd-05-13-2009",
      "rpkum": {
        "file": "dd_AX4_on_Ka_24Hr_bio2_mapped_expression_rpkum.tab.gz",
        "size": 116725,
        "total_size": 116725
      },
      "rc_raw": {
        "file": "dd_AX4_on_Ka_24Hr_bio2_mapped_expression_rc.tab.gz",
        "size": 50885,
        "total_size": 50885
      },
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_json": 475606,
      "exp_type": "polyA",
      "rpkmpolya": {
        "file": "dd_AX4_on_Ka_24Hr_bio2_mapped_expression_rpkm_polya.tab.gz",
        "size": 115806,
        "total_size": 115806
      },
      "feature_type": "gene"
    },
    "scheduled": "2022-03-24T12:03:18.201801+0000",
    "size": 15423317,
    "started": "2022-03-24T12:03:44.845735+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "gff": 387800,
      "mappable": 387852,
      "alignment": 387820
    },
    "process": {
      "created": "2021-02-24T02:23:18.320496+0000",
      "id": 2177,
      "modified": "2021-11-17T06:04:16.445726+0000",
      "is_active": True,
      "category": "Other:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ alignment.bam.file|basename|default('?') }}",
      "description": "Dictyostelium-specific pipeline. Developed by Bioinformatics Laboratory,\nFaculty of Computer and Information Science, University of Ljubljana,\nSlovenia and Shaulsky Lab, Department of Molecular and Human Genetics,\nBaylor College of Medicine, Houston, TX, USA.\n",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "alignment",
          "type": "data:alignment:bam:",
          "label": "Aligned sequence"
        },
        {
          "name": "gff",
          "type": "data:annotation:gff3:",
          "label": "Features (GFF3)"
        },
        {
          "name": "mappable",
          "type": "data:mappability:bcm:",
          "label": "Mappability"
        }
      ],
      "name": "Dictyostelium expressions",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Expression RPKUM (polyA)",
          "description": "mRNA reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkmpolya",
          "type": "basic:file:",
          "label": "Expression RPKM (polyA)",
          "description": "mRNA reads scaled by exon length."
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (polyA)",
          "description": "mRNA reads uniquely mapped to gene exons."
        },
        {
          "name": "rpkum",
          "type": "basic:file:",
          "label": "Expression RPKUM",
          "description": "Reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkm",
          "type": "basic:file:",
          "label": "Expression RPKM",
          "description": "Reads scaled by exon length."
        },
        {
          "name": "rc_raw",
          "type": "basic:file:",
          "label": "Read counts (raw)",
          "description": "Reads uniquely mapped to gene exons."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression RPKUM (polyA) (json)"
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression Type (default output)"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID database"
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species"
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build"
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type"
        }
      ],
      "persistence": "CAC",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/s4q6j6e8/resolwebio/biox:2.0.0"
          }
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "NAME=`basename {{ alignment.bam.file }} .bam`\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}}\nre-checkrc \"Calculation of expression values failed.\"\nre-progress 0.5\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}} --mrna\nre-checkrc \"Calculation of expression values failed.\"\nsamtools idxstats {{ alignment.bam.file }} | cut -f -2 | head -n -1 \u003E chrom.sizes\nre-checkrc \"Samtools idxstats command failed.\"\n\nmv expression_rc.tab.gz ${NAME}_expression_rc.tab.gz\nre-save-file rc_raw ${NAME}_expression_rc.tab.gz\n\nmv expression_rc_polya.tab.gz ${NAME}_expression_rc_polya.tab.gz\nre-save-file rc ${NAME}_expression_rc_polya.tab.gz\n\nmv expression_rpkm.tab.gz ${NAME}_expression_rpkm.tab.gz\nre-save-file rpkm ${NAME}_expression_rpkm.tab.gz\n\nmv expression_rpkm_polya.tab.gz ${NAME}_expression_rpkm_polya.tab.gz\nre-save-file rpkmpolya ${NAME}_expression_rpkm_polya.tab.gz\n\nmv expression_rpkum.tab.gz ${NAME}_expression_rpkum.tab.gz\nre-save-file rpkum ${NAME}_expression_rpkum.tab.gz\n\nmv expression_rpkum_polya.tab.gz ${NAME}_expression_rpkum_polya.tab.gz\nexpression2storage.py ${NAME}_expression_rpkum_polya.tab.gz --output json.txt\nre-checkrc\nre-save exp_json json.txt\nre-save-file exp ${NAME}_expression_rpkum_polya.tab.gz\n\nre-save source {{gff.source}}\nre-save species {{alignment.species}}\nre-save build {{alignment.build}}\nre-save feature_type gene\nre-save exp_type polyA\n",
        "runtime": "polyglot",
        "language": "bash"
      },
      "scheduling_class": "BA",
      "slug": "expression-dicty",
      "type": "data:expression:polya:",
      "version": "1.4.1"
    },
    "collection": {
      "created": "2022-03-22T10:47:57.116905+0000",
      "duplicated": None,
      "id": 2217,
      "modified": "2022-05-17T10:01:35.314628+0000",
      "data_count": 46,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "dictyExpress Parikh A et. al. dataset",
      "name": "D. discoideum, AX4, Parikh et al. 2015 (Growth: K. pneumoniae, Treatment: Filter Development)",
      "settings": {

      },
      "slug": "dictyexpress-discoideum-parikh-et-al",
      "tags": [
        "community:bcm"
      ],
      "entity_count": 14,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-03-23T14:14:35.890797+0000",
      "duplicated": None,
      "id": 66399,
      "modified": "2022-03-23T14:14:37.436353+0000",
      "data_count": 3,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "dd_AX4_on_Ka_24Hr_bio2",
      "settings": {

      },
      "slug": "dd_ax4_on_ka_24hr_bio2fastqgz-2",
      "tags": [
        "community:bcm"
      ],
      "collection": 2217,
      "type": "sample"
    },
    "name": "dd_AX4_on_Ka_24Hr_bio2_mapped.bam",
    "slug": "dd_ax4_on_ka_24hr_bio2_mappedbam",
    "tags": [
      "community:bcm"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "0f83c9746ba0d83062b727fb06d477bfd52c6c20f013136048e1fa3f3979ca24",
    "created": "2022-03-24T12:03:16.639273+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-03-24T14:12:35.562296+0000",
    "id": 387872,
    "modified": "2022-03-24T14:00:10.508045+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 16384,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "dd_AX4_on_Ka_20Hr_bio1_mapped_expression_rc_polya.tab.gz",
        "size": 48543,
        "total_size": 48543
      },
      "exp": {
        "file": "dd_AX4_on_Ka_20Hr_bio1_mapped_expression_rpkum_polya.tab.gz",
        "size": 116267,
        "total_size": 116267
      },
      "rpkm": {
        "file": "dd_AX4_on_Ka_20Hr_bio1_mapped_expression_rpkm.tab.gz",
        "size": 115002,
        "total_size": 115002
      },
      "build": "dd-05-13-2009",
      "rpkum": {
        "file": "dd_AX4_on_Ka_20Hr_bio1_mapped_expression_rpkum.tab.gz",
        "size": 116294,
        "total_size": 116294
      },
      "rc_raw": {
        "file": "dd_AX4_on_Ka_20Hr_bio1_mapped_expression_rc.tab.gz",
        "size": 48608,
        "total_size": 48608
      },
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_json": 475634,
      "exp_type": "polyA",
      "rpkmpolya": {
        "file": "dd_AX4_on_Ka_20Hr_bio1_mapped_expression_rpkm_polya.tab.gz",
        "size": 114833,
        "total_size": 114833
      },
      "feature_type": "gene"
    },
    "scheduled": "2022-03-24T14:00:10.861787+0000",
    "size": 956116,
    "started": "2022-03-24T14:00:25.524883+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "gff": 387800,
      "mappable": 387852,
      "alignment": 387819
    },
    "process": {
      "created": "2021-02-24T02:23:18.320496+0000",
      "id": 2177,
      "modified": "2021-11-17T06:04:16.445726+0000",
      "is_active": True,
      "category": "Other:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ alignment.bam.file|basename|default('?') }}",
      "description": "Dictyostelium-specific pipeline. Developed by Bioinformatics Laboratory,\nFaculty of Computer and Information Science, University of Ljubljana,\nSlovenia and Shaulsky Lab, Department of Molecular and Human Genetics,\nBaylor College of Medicine, Houston, TX, USA.\n",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "alignment",
          "type": "data:alignment:bam:",
          "label": "Aligned sequence"
        },
        {
          "name": "gff",
          "type": "data:annotation:gff3:",
          "label": "Features (GFF3)"
        },
        {
          "name": "mappable",
          "type": "data:mappability:bcm:",
          "label": "Mappability"
        }
      ],
      "name": "Dictyostelium expressions",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Expression RPKUM (polyA)",
          "description": "mRNA reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkmpolya",
          "type": "basic:file:",
          "label": "Expression RPKM (polyA)",
          "description": "mRNA reads scaled by exon length."
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (polyA)",
          "description": "mRNA reads uniquely mapped to gene exons."
        },
        {
          "name": "rpkum",
          "type": "basic:file:",
          "label": "Expression RPKUM",
          "description": "Reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkm",
          "type": "basic:file:",
          "label": "Expression RPKM",
          "description": "Reads scaled by exon length."
        },
        {
          "name": "rc_raw",
          "type": "basic:file:",
          "label": "Read counts (raw)",
          "description": "Reads uniquely mapped to gene exons."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression RPKUM (polyA) (json)"
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression Type (default output)"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID database"
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species"
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build"
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type"
        }
      ],
      "persistence": "CAC",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/s4q6j6e8/resolwebio/biox:2.0.0"
          }
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "NAME=`basename {{ alignment.bam.file }} .bam`\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}}\nre-checkrc \"Calculation of expression values failed.\"\nre-progress 0.5\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}} --mrna\nre-checkrc \"Calculation of expression values failed.\"\nsamtools idxstats {{ alignment.bam.file }} | cut -f -2 | head -n -1 \u003E chrom.sizes\nre-checkrc \"Samtools idxstats command failed.\"\n\nmv expression_rc.tab.gz ${NAME}_expression_rc.tab.gz\nre-save-file rc_raw ${NAME}_expression_rc.tab.gz\n\nmv expression_rc_polya.tab.gz ${NAME}_expression_rc_polya.tab.gz\nre-save-file rc ${NAME}_expression_rc_polya.tab.gz\n\nmv expression_rpkm.tab.gz ${NAME}_expression_rpkm.tab.gz\nre-save-file rpkm ${NAME}_expression_rpkm.tab.gz\n\nmv expression_rpkm_polya.tab.gz ${NAME}_expression_rpkm_polya.tab.gz\nre-save-file rpkmpolya ${NAME}_expression_rpkm_polya.tab.gz\n\nmv expression_rpkum.tab.gz ${NAME}_expression_rpkum.tab.gz\nre-save-file rpkum ${NAME}_expression_rpkum.tab.gz\n\nmv expression_rpkum_polya.tab.gz ${NAME}_expression_rpkum_polya.tab.gz\nexpression2storage.py ${NAME}_expression_rpkum_polya.tab.gz --output json.txt\nre-checkrc\nre-save exp_json json.txt\nre-save-file exp ${NAME}_expression_rpkum_polya.tab.gz\n\nre-save source {{gff.source}}\nre-save species {{alignment.species}}\nre-save build {{alignment.build}}\nre-save feature_type gene\nre-save exp_type polyA\n",
        "runtime": "polyglot",
        "language": "bash"
      },
      "scheduling_class": "BA",
      "slug": "expression-dicty",
      "type": "data:expression:polya:",
      "version": "1.4.1"
    },
    "collection": {
      "created": "2022-03-22T10:47:57.116905+0000",
      "duplicated": None,
      "id": 2217,
      "modified": "2022-05-17T10:01:35.314628+0000",
      "data_count": 46,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "dictyExpress Parikh A et. al. dataset",
      "name": "D. discoideum, AX4, Parikh et al. 2015 (Growth: K. pneumoniae, Treatment: Filter Development)",
      "settings": {

      },
      "slug": "dictyexpress-discoideum-parikh-et-al",
      "tags": [
        "community:bcm"
      ],
      "entity_count": 14,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-03-23T14:07:46.851512+0000",
      "duplicated": None,
      "id": 66396,
      "modified": "2022-03-23T14:07:48.034595+0000",
      "data_count": 3,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "dd_AX4_on_Ka_20Hr_bio1",
      "settings": {

      },
      "slug": "dd_ax4_on_ka_20hr_bio1fastqgz",
      "tags": [
        "community:bcm"
      ],
      "collection": 2217,
      "type": "sample"
    },
    "name": "?",
    "slug": "data-278",
    "tags": [
      "community:bcm"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "7c2bdb0bf22805840e02c79976c93c7361b76dac12f729b414b4b4e12226af61",
    "created": "2022-03-24T12:03:16.322227+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-03-24T12:19:44.054609+0000",
    "id": 387870,
    "modified": "2022-03-24T12:04:40.401928+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 16384,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "dd_AX4_on_Ka_16Hr_bio2_mapped_expression_rc_polya.tab.gz",
        "size": 50428,
        "total_size": 50428
      },
      "exp": {
        "file": "dd_AX4_on_Ka_16Hr_bio2_mapped_expression_rpkum_polya.tab.gz",
        "size": 116008,
        "total_size": 116008
      },
      "rpkm": {
        "file": "dd_AX4_on_Ka_16Hr_bio2_mapped_expression_rpkm.tab.gz",
        "size": 114911,
        "total_size": 114911
      },
      "build": "dd-05-13-2009",
      "rpkum": {
        "file": "dd_AX4_on_Ka_16Hr_bio2_mapped_expression_rpkum.tab.gz",
        "size": 116018,
        "total_size": 116018
      },
      "rc_raw": {
        "file": "dd_AX4_on_Ka_16Hr_bio2_mapped_expression_rc.tab.gz",
        "size": 50493,
        "total_size": 50493
      },
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_json": 475607,
      "exp_type": "polyA",
      "rpkmpolya": {
        "file": "dd_AX4_on_Ka_16Hr_bio2_mapped_expression_rpkm_polya.tab.gz",
        "size": 114882,
        "total_size": 114882
      },
      "feature_type": "gene"
    },
    "scheduled": "2022-03-24T12:04:40.729846+0000",
    "size": 15418241,
    "started": "2022-03-24T12:04:59.521801+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "gff": 387800,
      "mappable": 387852,
      "alignment": 387816
    },
    "process": {
      "created": "2021-02-24T02:23:18.320496+0000",
      "id": 2177,
      "modified": "2021-11-17T06:04:16.445726+0000",
      "is_active": True,
      "category": "Other:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ alignment.bam.file|basename|default('?') }}",
      "description": "Dictyostelium-specific pipeline. Developed by Bioinformatics Laboratory,\nFaculty of Computer and Information Science, University of Ljubljana,\nSlovenia and Shaulsky Lab, Department of Molecular and Human Genetics,\nBaylor College of Medicine, Houston, TX, USA.\n",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "alignment",
          "type": "data:alignment:bam:",
          "label": "Aligned sequence"
        },
        {
          "name": "gff",
          "type": "data:annotation:gff3:",
          "label": "Features (GFF3)"
        },
        {
          "name": "mappable",
          "type": "data:mappability:bcm:",
          "label": "Mappability"
        }
      ],
      "name": "Dictyostelium expressions",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Expression RPKUM (polyA)",
          "description": "mRNA reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkmpolya",
          "type": "basic:file:",
          "label": "Expression RPKM (polyA)",
          "description": "mRNA reads scaled by exon length."
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (polyA)",
          "description": "mRNA reads uniquely mapped to gene exons."
        },
        {
          "name": "rpkum",
          "type": "basic:file:",
          "label": "Expression RPKUM",
          "description": "Reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkm",
          "type": "basic:file:",
          "label": "Expression RPKM",
          "description": "Reads scaled by exon length."
        },
        {
          "name": "rc_raw",
          "type": "basic:file:",
          "label": "Read counts (raw)",
          "description": "Reads uniquely mapped to gene exons."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression RPKUM (polyA) (json)"
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression Type (default output)"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID database"
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species"
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build"
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type"
        }
      ],
      "persistence": "CAC",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/s4q6j6e8/resolwebio/biox:2.0.0"
          }
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "NAME=`basename {{ alignment.bam.file }} .bam`\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}}\nre-checkrc \"Calculation of expression values failed.\"\nre-progress 0.5\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}} --mrna\nre-checkrc \"Calculation of expression values failed.\"\nsamtools idxstats {{ alignment.bam.file }} | cut -f -2 | head -n -1 \u003E chrom.sizes\nre-checkrc \"Samtools idxstats command failed.\"\n\nmv expression_rc.tab.gz ${NAME}_expression_rc.tab.gz\nre-save-file rc_raw ${NAME}_expression_rc.tab.gz\n\nmv expression_rc_polya.tab.gz ${NAME}_expression_rc_polya.tab.gz\nre-save-file rc ${NAME}_expression_rc_polya.tab.gz\n\nmv expression_rpkm.tab.gz ${NAME}_expression_rpkm.tab.gz\nre-save-file rpkm ${NAME}_expression_rpkm.tab.gz\n\nmv expression_rpkm_polya.tab.gz ${NAME}_expression_rpkm_polya.tab.gz\nre-save-file rpkmpolya ${NAME}_expression_rpkm_polya.tab.gz\n\nmv expression_rpkum.tab.gz ${NAME}_expression_rpkum.tab.gz\nre-save-file rpkum ${NAME}_expression_rpkum.tab.gz\n\nmv expression_rpkum_polya.tab.gz ${NAME}_expression_rpkum_polya.tab.gz\nexpression2storage.py ${NAME}_expression_rpkum_polya.tab.gz --output json.txt\nre-checkrc\nre-save exp_json json.txt\nre-save-file exp ${NAME}_expression_rpkum_polya.tab.gz\n\nre-save source {{gff.source}}\nre-save species {{alignment.species}}\nre-save build {{alignment.build}}\nre-save feature_type gene\nre-save exp_type polyA\n",
        "runtime": "polyglot",
        "language": "bash"
      },
      "scheduling_class": "BA",
      "slug": "expression-dicty",
      "type": "data:expression:polya:",
      "version": "1.4.1"
    },
    "collection": {
      "created": "2022-03-22T10:47:57.116905+0000",
      "duplicated": None,
      "id": 2217,
      "modified": "2022-05-17T10:01:35.314628+0000",
      "data_count": 46,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "dictyExpress Parikh A et. al. dataset",
      "name": "D. discoideum, AX4, Parikh et al. 2015 (Growth: K. pneumoniae, Treatment: Filter Development)",
      "settings": {

      },
      "slug": "dictyexpress-discoideum-parikh-et-al",
      "tags": [
        "community:bcm"
      ],
      "entity_count": 14,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-03-23T14:05:03.735939+0000",
      "duplicated": None,
      "id": 66395,
      "modified": "2022-03-23T14:05:05.346649+0000",
      "data_count": 3,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "dd_AX4_on_Ka_16Hr_bio2",
      "settings": {

      },
      "slug": "dd_ax4_on_ka_16hr_bio2fastqgz",
      "tags": [
        "community:bcm"
      ],
      "collection": 2217,
      "type": "sample"
    },
    "name": "?",
    "slug": "data-277",
    "tags": [
      "community:bcm"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "8b5a18991704a6a3a03e00de38b448dce1bd76ba871e8d048e8e97e898db32f3",
    "created": "2022-03-24T12:03:16.006482+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-03-24T14:00:13.723701+0000",
    "id": 387867,
    "modified": "2022-03-24T13:46:42.309640+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 16384,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "dd_AX4_on_Ka_16Hr_bio1_mapped_expression_rc_polya.tab.gz",
        "size": 49523,
        "total_size": 49523
      },
      "exp": {
        "file": "dd_AX4_on_Ka_16Hr_bio1_mapped_expression_rpkum_polya.tab.gz",
        "size": 117209,
        "total_size": 117209
      },
      "rpkm": {
        "file": "dd_AX4_on_Ka_16Hr_bio1_mapped_expression_rpkm.tab.gz",
        "size": 116025,
        "total_size": 116025
      },
      "build": "dd-05-13-2009",
      "rpkum": {
        "file": "dd_AX4_on_Ka_16Hr_bio1_mapped_expression_rpkum.tab.gz",
        "size": 117252,
        "total_size": 117252
      },
      "rc_raw": {
        "file": "dd_AX4_on_Ka_16Hr_bio1_mapped_expression_rc.tab.gz",
        "size": 49589,
        "total_size": 49589
      },
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_json": 475629,
      "exp_type": "polyA",
      "rpkmpolya": {
        "file": "dd_AX4_on_Ka_16Hr_bio1_mapped_expression_rpkm_polya.tab.gz",
        "size": 116149,
        "total_size": 116149
      },
      "feature_type": "gene"
    },
    "scheduled": "2022-03-24T13:46:42.659735+0000",
    "size": 15423989,
    "started": "2022-03-24T13:47:09.488737+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "gff": 387800,
      "mappable": 387852,
      "alignment": 387817
    },
    "process": {
      "created": "2021-02-24T02:23:18.320496+0000",
      "id": 2177,
      "modified": "2021-11-17T06:04:16.445726+0000",
      "is_active": True,
      "category": "Other:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ alignment.bam.file|basename|default('?') }}",
      "description": "Dictyostelium-specific pipeline. Developed by Bioinformatics Laboratory,\nFaculty of Computer and Information Science, University of Ljubljana,\nSlovenia and Shaulsky Lab, Department of Molecular and Human Genetics,\nBaylor College of Medicine, Houston, TX, USA.\n",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "alignment",
          "type": "data:alignment:bam:",
          "label": "Aligned sequence"
        },
        {
          "name": "gff",
          "type": "data:annotation:gff3:",
          "label": "Features (GFF3)"
        },
        {
          "name": "mappable",
          "type": "data:mappability:bcm:",
          "label": "Mappability"
        }
      ],
      "name": "Dictyostelium expressions",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Expression RPKUM (polyA)",
          "description": "mRNA reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkmpolya",
          "type": "basic:file:",
          "label": "Expression RPKM (polyA)",
          "description": "mRNA reads scaled by exon length."
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (polyA)",
          "description": "mRNA reads uniquely mapped to gene exons."
        },
        {
          "name": "rpkum",
          "type": "basic:file:",
          "label": "Expression RPKUM",
          "description": "Reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkm",
          "type": "basic:file:",
          "label": "Expression RPKM",
          "description": "Reads scaled by exon length."
        },
        {
          "name": "rc_raw",
          "type": "basic:file:",
          "label": "Read counts (raw)",
          "description": "Reads uniquely mapped to gene exons."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression RPKUM (polyA) (json)"
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression Type (default output)"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID database"
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species"
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build"
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type"
        }
      ],
      "persistence": "CAC",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/s4q6j6e8/resolwebio/biox:2.0.0"
          }
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "NAME=`basename {{ alignment.bam.file }} .bam`\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}}\nre-checkrc \"Calculation of expression values failed.\"\nre-progress 0.5\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}} --mrna\nre-checkrc \"Calculation of expression values failed.\"\nsamtools idxstats {{ alignment.bam.file }} | cut -f -2 | head -n -1 \u003E chrom.sizes\nre-checkrc \"Samtools idxstats command failed.\"\n\nmv expression_rc.tab.gz ${NAME}_expression_rc.tab.gz\nre-save-file rc_raw ${NAME}_expression_rc.tab.gz\n\nmv expression_rc_polya.tab.gz ${NAME}_expression_rc_polya.tab.gz\nre-save-file rc ${NAME}_expression_rc_polya.tab.gz\n\nmv expression_rpkm.tab.gz ${NAME}_expression_rpkm.tab.gz\nre-save-file rpkm ${NAME}_expression_rpkm.tab.gz\n\nmv expression_rpkm_polya.tab.gz ${NAME}_expression_rpkm_polya.tab.gz\nre-save-file rpkmpolya ${NAME}_expression_rpkm_polya.tab.gz\n\nmv expression_rpkum.tab.gz ${NAME}_expression_rpkum.tab.gz\nre-save-file rpkum ${NAME}_expression_rpkum.tab.gz\n\nmv expression_rpkum_polya.tab.gz ${NAME}_expression_rpkum_polya.tab.gz\nexpression2storage.py ${NAME}_expression_rpkum_polya.tab.gz --output json.txt\nre-checkrc\nre-save exp_json json.txt\nre-save-file exp ${NAME}_expression_rpkum_polya.tab.gz\n\nre-save source {{gff.source}}\nre-save species {{alignment.species}}\nre-save build {{alignment.build}}\nre-save feature_type gene\nre-save exp_type polyA\n",
        "runtime": "polyglot",
        "language": "bash"
      },
      "scheduling_class": "BA",
      "slug": "expression-dicty",
      "type": "data:expression:polya:",
      "version": "1.4.1"
    },
    "collection": {
      "created": "2022-03-22T10:47:57.116905+0000",
      "duplicated": None,
      "id": 2217,
      "modified": "2022-05-17T10:01:35.314628+0000",
      "data_count": 46,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "dictyExpress Parikh A et. al. dataset",
      "name": "D. discoideum, AX4, Parikh et al. 2015 (Growth: K. pneumoniae, Treatment: Filter Development)",
      "settings": {

      },
      "slug": "dictyexpress-discoideum-parikh-et-al",
      "tags": [
        "community:bcm"
      ],
      "entity_count": 14,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-03-23T14:03:00.555141+0000",
      "duplicated": None,
      "id": 66394,
      "modified": "2022-03-23T14:03:01.777533+0000",
      "data_count": 3,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "dd_AX4_on_Ka_16Hr_bio1",
      "settings": {

      },
      "slug": "dd_ax4_on_ka_16hr_bio1fastqgz",
      "tags": [
        "community:bcm"
      ],
      "collection": 2217,
      "type": "sample"
    },
    "name": "?",
    "slug": "data-276",
    "tags": [
      "community:bcm"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "4b3e266112cc0379c97887a02309470a8c015d48789efe1e63c8178c8f8fc984",
    "created": "2022-03-24T12:03:15.691592+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-03-24T12:46:54.741615+0000",
    "id": 387864,
    "modified": "2022-03-24T12:33:37.362780+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 16384,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "dd_AX4_on_Ka_20Hr_bio2_mapped_expression_rc_polya.tab.gz",
        "size": 50705,
        "total_size": 50705
      },
      "exp": {
        "file": "dd_AX4_on_Ka_20Hr_bio2_mapped_expression_rpkum_polya.tab.gz",
        "size": 116907,
        "total_size": 116907
      },
      "rpkm": {
        "file": "dd_AX4_on_Ka_20Hr_bio2_mapped_expression_rpkm.tab.gz",
        "size": 115842,
        "total_size": 115842
      },
      "build": "dd-05-13-2009",
      "rpkum": {
        "file": "dd_AX4_on_Ka_20Hr_bio2_mapped_expression_rpkum.tab.gz",
        "size": 117004,
        "total_size": 117004
      },
      "rc_raw": {
        "file": "dd_AX4_on_Ka_20Hr_bio2_mapped_expression_rc.tab.gz",
        "size": 50769,
        "total_size": 50769
      },
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_json": 475609,
      "exp_type": "polyA",
      "rpkmpolya": {
        "file": "dd_AX4_on_Ka_20Hr_bio2_mapped_expression_rpkm_polya.tab.gz",
        "size": 115821,
        "total_size": 115821
      },
      "feature_type": "gene"
    },
    "scheduled": "2022-03-24T12:33:37.721829+0000",
    "size": 15424244,
    "started": "2022-03-24T12:33:56.360136+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "gff": 387800,
      "mappable": 387852,
      "alignment": 387818
    },
    "process": {
      "created": "2021-02-24T02:23:18.320496+0000",
      "id": 2177,
      "modified": "2021-11-17T06:04:16.445726+0000",
      "is_active": True,
      "category": "Other:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ alignment.bam.file|basename|default('?') }}",
      "description": "Dictyostelium-specific pipeline. Developed by Bioinformatics Laboratory,\nFaculty of Computer and Information Science, University of Ljubljana,\nSlovenia and Shaulsky Lab, Department of Molecular and Human Genetics,\nBaylor College of Medicine, Houston, TX, USA.\n",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "alignment",
          "type": "data:alignment:bam:",
          "label": "Aligned sequence"
        },
        {
          "name": "gff",
          "type": "data:annotation:gff3:",
          "label": "Features (GFF3)"
        },
        {
          "name": "mappable",
          "type": "data:mappability:bcm:",
          "label": "Mappability"
        }
      ],
      "name": "Dictyostelium expressions",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Expression RPKUM (polyA)",
          "description": "mRNA reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkmpolya",
          "type": "basic:file:",
          "label": "Expression RPKM (polyA)",
          "description": "mRNA reads scaled by exon length."
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (polyA)",
          "description": "mRNA reads uniquely mapped to gene exons."
        },
        {
          "name": "rpkum",
          "type": "basic:file:",
          "label": "Expression RPKUM",
          "description": "Reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkm",
          "type": "basic:file:",
          "label": "Expression RPKM",
          "description": "Reads scaled by exon length."
        },
        {
          "name": "rc_raw",
          "type": "basic:file:",
          "label": "Read counts (raw)",
          "description": "Reads uniquely mapped to gene exons."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression RPKUM (polyA) (json)"
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression Type (default output)"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID database"
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species"
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build"
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type"
        }
      ],
      "persistence": "CAC",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/s4q6j6e8/resolwebio/biox:2.0.0"
          }
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "NAME=`basename {{ alignment.bam.file }} .bam`\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}}\nre-checkrc \"Calculation of expression values failed.\"\nre-progress 0.5\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}} --mrna\nre-checkrc \"Calculation of expression values failed.\"\nsamtools idxstats {{ alignment.bam.file }} | cut -f -2 | head -n -1 \u003E chrom.sizes\nre-checkrc \"Samtools idxstats command failed.\"\n\nmv expression_rc.tab.gz ${NAME}_expression_rc.tab.gz\nre-save-file rc_raw ${NAME}_expression_rc.tab.gz\n\nmv expression_rc_polya.tab.gz ${NAME}_expression_rc_polya.tab.gz\nre-save-file rc ${NAME}_expression_rc_polya.tab.gz\n\nmv expression_rpkm.tab.gz ${NAME}_expression_rpkm.tab.gz\nre-save-file rpkm ${NAME}_expression_rpkm.tab.gz\n\nmv expression_rpkm_polya.tab.gz ${NAME}_expression_rpkm_polya.tab.gz\nre-save-file rpkmpolya ${NAME}_expression_rpkm_polya.tab.gz\n\nmv expression_rpkum.tab.gz ${NAME}_expression_rpkum.tab.gz\nre-save-file rpkum ${NAME}_expression_rpkum.tab.gz\n\nmv expression_rpkum_polya.tab.gz ${NAME}_expression_rpkum_polya.tab.gz\nexpression2storage.py ${NAME}_expression_rpkum_polya.tab.gz --output json.txt\nre-checkrc\nre-save exp_json json.txt\nre-save-file exp ${NAME}_expression_rpkum_polya.tab.gz\n\nre-save source {{gff.source}}\nre-save species {{alignment.species}}\nre-save build {{alignment.build}}\nre-save feature_type gene\nre-save exp_type polyA\n",
        "runtime": "polyglot",
        "language": "bash"
      },
      "scheduling_class": "BA",
      "slug": "expression-dicty",
      "type": "data:expression:polya:",
      "version": "1.4.1"
    },
    "collection": {
      "created": "2022-03-22T10:47:57.116905+0000",
      "duplicated": None,
      "id": 2217,
      "modified": "2022-05-17T10:01:35.314628+0000",
      "data_count": 46,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "dictyExpress Parikh A et. al. dataset",
      "name": "D. discoideum, AX4, Parikh et al. 2015 (Growth: K. pneumoniae, Treatment: Filter Development)",
      "settings": {

      },
      "slug": "dictyexpress-discoideum-parikh-et-al",
      "tags": [
        "community:bcm"
      ],
      "entity_count": 14,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-03-23T14:10:04.273620+0000",
      "duplicated": None,
      "id": 66397,
      "modified": "2022-03-23T14:10:05.369365+0000",
      "data_count": 3,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "dd_AX4_on_Ka_20Hr_bio2",
      "settings": {

      },
      "slug": "dd_ax4_on_ka_20hr_bio2fastqgz",
      "tags": [
        "community:bcm"
      ],
      "collection": 2217,
      "type": "sample"
    },
    "name": "?",
    "slug": "data-275",
    "tags": [
      "community:bcm"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "a12be5c1b97b3af0fe51c4720c41d579ea06968e4a10ee534c06376be3717f84",
    "created": "2022-03-24T12:03:14.856439+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-03-24T12:45:56.388421+0000",
    "id": 387863,
    "modified": "2022-03-24T12:32:42.547596+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 16384,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "dd_AX4_on_Ka_12Hr_bio1_mapped_expression_rc_polya.tab.gz",
        "size": 50583,
        "total_size": 50583
      },
      "exp": {
        "file": "dd_AX4_on_Ka_12Hr_bio1_mapped_expression_rpkum_polya.tab.gz",
        "size": 116114,
        "total_size": 116114
      },
      "rpkm": {
        "file": "dd_AX4_on_Ka_12Hr_bio1_mapped_expression_rpkm.tab.gz",
        "size": 115147,
        "total_size": 115147
      },
      "build": "dd-05-13-2009",
      "rpkum": {
        "file": "dd_AX4_on_Ka_12Hr_bio1_mapped_expression_rpkum.tab.gz",
        "size": 116037,
        "total_size": 116037
      },
      "rc_raw": {
        "file": "dd_AX4_on_Ka_12Hr_bio1_mapped_expression_rc.tab.gz",
        "size": 50647,
        "total_size": 50647
      },
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_json": 475608,
      "exp_type": "polyA",
      "rpkmpolya": {
        "file": "dd_AX4_on_Ka_12Hr_bio1_mapped_expression_rpkm_polya.tab.gz",
        "size": 115267,
        "total_size": 115267
      },
      "feature_type": "gene"
    },
    "scheduled": "2022-03-24T12:32:42.867942+0000",
    "size": 15419147,
    "started": "2022-03-24T12:33:09.342632+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "gff": 387800,
      "mappable": 387852,
      "alignment": 387815
    },
    "process": {
      "created": "2021-02-24T02:23:18.320496+0000",
      "id": 2177,
      "modified": "2021-11-17T06:04:16.445726+0000",
      "is_active": True,
      "category": "Other:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ alignment.bam.file|basename|default('?') }}",
      "description": "Dictyostelium-specific pipeline. Developed by Bioinformatics Laboratory,\nFaculty of Computer and Information Science, University of Ljubljana,\nSlovenia and Shaulsky Lab, Department of Molecular and Human Genetics,\nBaylor College of Medicine, Houston, TX, USA.\n",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "alignment",
          "type": "data:alignment:bam:",
          "label": "Aligned sequence"
        },
        {
          "name": "gff",
          "type": "data:annotation:gff3:",
          "label": "Features (GFF3)"
        },
        {
          "name": "mappable",
          "type": "data:mappability:bcm:",
          "label": "Mappability"
        }
      ],
      "name": "Dictyostelium expressions",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Expression RPKUM (polyA)",
          "description": "mRNA reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkmpolya",
          "type": "basic:file:",
          "label": "Expression RPKM (polyA)",
          "description": "mRNA reads scaled by exon length."
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (polyA)",
          "description": "mRNA reads uniquely mapped to gene exons."
        },
        {
          "name": "rpkum",
          "type": "basic:file:",
          "label": "Expression RPKUM",
          "description": "Reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkm",
          "type": "basic:file:",
          "label": "Expression RPKM",
          "description": "Reads scaled by exon length."
        },
        {
          "name": "rc_raw",
          "type": "basic:file:",
          "label": "Read counts (raw)",
          "description": "Reads uniquely mapped to gene exons."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression RPKUM (polyA) (json)"
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression Type (default output)"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID database"
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species"
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build"
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type"
        }
      ],
      "persistence": "CAC",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/s4q6j6e8/resolwebio/biox:2.0.0"
          }
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "NAME=`basename {{ alignment.bam.file }} .bam`\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}}\nre-checkrc \"Calculation of expression values failed.\"\nre-progress 0.5\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}} --mrna\nre-checkrc \"Calculation of expression values failed.\"\nsamtools idxstats {{ alignment.bam.file }} | cut -f -2 | head -n -1 \u003E chrom.sizes\nre-checkrc \"Samtools idxstats command failed.\"\n\nmv expression_rc.tab.gz ${NAME}_expression_rc.tab.gz\nre-save-file rc_raw ${NAME}_expression_rc.tab.gz\n\nmv expression_rc_polya.tab.gz ${NAME}_expression_rc_polya.tab.gz\nre-save-file rc ${NAME}_expression_rc_polya.tab.gz\n\nmv expression_rpkm.tab.gz ${NAME}_expression_rpkm.tab.gz\nre-save-file rpkm ${NAME}_expression_rpkm.tab.gz\n\nmv expression_rpkm_polya.tab.gz ${NAME}_expression_rpkm_polya.tab.gz\nre-save-file rpkmpolya ${NAME}_expression_rpkm_polya.tab.gz\n\nmv expression_rpkum.tab.gz ${NAME}_expression_rpkum.tab.gz\nre-save-file rpkum ${NAME}_expression_rpkum.tab.gz\n\nmv expression_rpkum_polya.tab.gz ${NAME}_expression_rpkum_polya.tab.gz\nexpression2storage.py ${NAME}_expression_rpkum_polya.tab.gz --output json.txt\nre-checkrc\nre-save exp_json json.txt\nre-save-file exp ${NAME}_expression_rpkum_polya.tab.gz\n\nre-save source {{gff.source}}\nre-save species {{alignment.species}}\nre-save build {{alignment.build}}\nre-save feature_type gene\nre-save exp_type polyA\n",
        "runtime": "polyglot",
        "language": "bash"
      },
      "scheduling_class": "BA",
      "slug": "expression-dicty",
      "type": "data:expression:polya:",
      "version": "1.4.1"
    },
    "collection": {
      "created": "2022-03-22T10:47:57.116905+0000",
      "duplicated": None,
      "id": 2217,
      "modified": "2022-05-17T10:01:35.314628+0000",
      "data_count": 46,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "dictyExpress Parikh A et. al. dataset",
      "name": "D. discoideum, AX4, Parikh et al. 2015 (Growth: K. pneumoniae, Treatment: Filter Development)",
      "settings": {

      },
      "slug": "dictyexpress-discoideum-parikh-et-al",
      "tags": [
        "community:bcm"
      ],
      "entity_count": 14,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-03-23T13:57:52.323061+0000",
      "duplicated": None,
      "id": 66392,
      "modified": "2022-03-23T13:57:53.498492+0000",
      "data_count": 3,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "dd_AX4_on_Ka_12Hr_bio1",
      "settings": {

      },
      "slug": "dd_ax4_on_ka_12hr_bio1fastqgz",
      "tags": [
        "community:bcm"
      ],
      "collection": 2217,
      "type": "sample"
    },
    "name": "?",
    "slug": "data-274",
    "tags": [
      "community:bcm"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "5facfd917203959546e55961533e35ba7577b8f64a2b3039bf3eee8d15eb25b3",
    "created": "2022-03-24T12:03:14.387522+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-03-24T13:32:36.694974+0000",
    "id": 387861,
    "modified": "2022-03-24T13:20:08.503715+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 16384,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "dd_AX4_on_Ka_12Hr_bio2_mapped_expression_rc_polya.tab.gz",
        "size": 50965,
        "total_size": 50965
      },
      "exp": {
        "file": "dd_AX4_on_Ka_12Hr_bio2_mapped_expression_rpkum_polya.tab.gz",
        "size": 117382,
        "total_size": 117382
      },
      "rpkm": {
        "file": "dd_AX4_on_Ka_12Hr_bio2_mapped_expression_rpkm.tab.gz",
        "size": 116483,
        "total_size": 116483
      },
      "build": "dd-05-13-2009",
      "rpkum": {
        "file": "dd_AX4_on_Ka_12Hr_bio2_mapped_expression_rpkum.tab.gz",
        "size": 117362,
        "total_size": 117362
      },
      "rc_raw": {
        "file": "dd_AX4_on_Ka_12Hr_bio2_mapped_expression_rc.tab.gz",
        "size": 51021,
        "total_size": 51021
      },
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_json": 475624,
      "exp_type": "polyA",
      "rpkmpolya": {
        "file": "dd_AX4_on_Ka_12Hr_bio2_mapped_expression_rpkm_polya.tab.gz",
        "size": 116458,
        "total_size": 116458
      },
      "feature_type": "gene"
    },
    "scheduled": "2022-03-24T13:20:08.924172+0000",
    "size": 15427541,
    "started": "2022-03-24T13:20:23.499949+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "gff": 387800,
      "mappable": 387852,
      "alignment": 387814
    },
    "process": {
      "created": "2021-02-24T02:23:18.320496+0000",
      "id": 2177,
      "modified": "2021-11-17T06:04:16.445726+0000",
      "is_active": True,
      "category": "Other:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ alignment.bam.file|basename|default('?') }}",
      "description": "Dictyostelium-specific pipeline. Developed by Bioinformatics Laboratory,\nFaculty of Computer and Information Science, University of Ljubljana,\nSlovenia and Shaulsky Lab, Department of Molecular and Human Genetics,\nBaylor College of Medicine, Houston, TX, USA.\n",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "alignment",
          "type": "data:alignment:bam:",
          "label": "Aligned sequence"
        },
        {
          "name": "gff",
          "type": "data:annotation:gff3:",
          "label": "Features (GFF3)"
        },
        {
          "name": "mappable",
          "type": "data:mappability:bcm:",
          "label": "Mappability"
        }
      ],
      "name": "Dictyostelium expressions",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Expression RPKUM (polyA)",
          "description": "mRNA reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkmpolya",
          "type": "basic:file:",
          "label": "Expression RPKM (polyA)",
          "description": "mRNA reads scaled by exon length."
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (polyA)",
          "description": "mRNA reads uniquely mapped to gene exons."
        },
        {
          "name": "rpkum",
          "type": "basic:file:",
          "label": "Expression RPKUM",
          "description": "Reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkm",
          "type": "basic:file:",
          "label": "Expression RPKM",
          "description": "Reads scaled by exon length."
        },
        {
          "name": "rc_raw",
          "type": "basic:file:",
          "label": "Read counts (raw)",
          "description": "Reads uniquely mapped to gene exons."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression RPKUM (polyA) (json)"
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression Type (default output)"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID database"
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species"
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build"
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type"
        }
      ],
      "persistence": "CAC",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/s4q6j6e8/resolwebio/biox:2.0.0"
          }
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "NAME=`basename {{ alignment.bam.file }} .bam`\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}}\nre-checkrc \"Calculation of expression values failed.\"\nre-progress 0.5\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}} --mrna\nre-checkrc \"Calculation of expression values failed.\"\nsamtools idxstats {{ alignment.bam.file }} | cut -f -2 | head -n -1 \u003E chrom.sizes\nre-checkrc \"Samtools idxstats command failed.\"\n\nmv expression_rc.tab.gz ${NAME}_expression_rc.tab.gz\nre-save-file rc_raw ${NAME}_expression_rc.tab.gz\n\nmv expression_rc_polya.tab.gz ${NAME}_expression_rc_polya.tab.gz\nre-save-file rc ${NAME}_expression_rc_polya.tab.gz\n\nmv expression_rpkm.tab.gz ${NAME}_expression_rpkm.tab.gz\nre-save-file rpkm ${NAME}_expression_rpkm.tab.gz\n\nmv expression_rpkm_polya.tab.gz ${NAME}_expression_rpkm_polya.tab.gz\nre-save-file rpkmpolya ${NAME}_expression_rpkm_polya.tab.gz\n\nmv expression_rpkum.tab.gz ${NAME}_expression_rpkum.tab.gz\nre-save-file rpkum ${NAME}_expression_rpkum.tab.gz\n\nmv expression_rpkum_polya.tab.gz ${NAME}_expression_rpkum_polya.tab.gz\nexpression2storage.py ${NAME}_expression_rpkum_polya.tab.gz --output json.txt\nre-checkrc\nre-save exp_json json.txt\nre-save-file exp ${NAME}_expression_rpkum_polya.tab.gz\n\nre-save source {{gff.source}}\nre-save species {{alignment.species}}\nre-save build {{alignment.build}}\nre-save feature_type gene\nre-save exp_type polyA\n",
        "runtime": "polyglot",
        "language": "bash"
      },
      "scheduling_class": "BA",
      "slug": "expression-dicty",
      "type": "data:expression:polya:",
      "version": "1.4.1"
    },
    "collection": {
      "created": "2022-03-22T10:47:57.116905+0000",
      "duplicated": None,
      "id": 2217,
      "modified": "2022-05-17T10:01:35.314628+0000",
      "data_count": 46,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "dictyExpress Parikh A et. al. dataset",
      "name": "D. discoideum, AX4, Parikh et al. 2015 (Growth: K. pneumoniae, Treatment: Filter Development)",
      "settings": {

      },
      "slug": "dictyexpress-discoideum-parikh-et-al",
      "tags": [
        "community:bcm"
      ],
      "entity_count": 14,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-03-23T14:00:21.171841+0000",
      "duplicated": None,
      "id": 66393,
      "modified": "2022-03-23T14:00:22.347416+0000",
      "data_count": 3,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "dd_AX4_on_Ka_12Hr_bio2",
      "settings": {

      },
      "slug": "dd_ax4_on_ka_12hr_bio2fastqgz",
      "tags": [
        "community:bcm"
      ],
      "collection": 2217,
      "type": "sample"
    },
    "name": "?",
    "slug": "data-273",
    "tags": [
      "community:bcm"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "3d69d03db7630979f591c9665267143cb6ed9c7e21c7b83bcf1fb21448d651da",
    "created": "2022-03-24T12:03:13.719668+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-03-24T13:37:58.245056+0000",
    "id": 387859,
    "modified": "2022-03-24T13:25:25.303851+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 16384,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "dd_AX4_on_Ka_08Hr_bio1_mapped_expression_rc_polya.tab.gz",
        "size": 48704,
        "total_size": 48704
      },
      "exp": {
        "file": "dd_AX4_on_Ka_08Hr_bio1_mapped_expression_rpkum_polya.tab.gz",
        "size": 115175,
        "total_size": 115175
      },
      "rpkm": {
        "file": "dd_AX4_on_Ka_08Hr_bio1_mapped_expression_rpkm.tab.gz",
        "size": 113884,
        "total_size": 113884
      },
      "build": "dd-05-13-2009",
      "rpkum": {
        "file": "dd_AX4_on_Ka_08Hr_bio1_mapped_expression_rpkum.tab.gz",
        "size": 115317,
        "total_size": 115317
      },
      "rc_raw": {
        "file": "dd_AX4_on_Ka_08Hr_bio1_mapped_expression_rc.tab.gz",
        "size": 48765,
        "total_size": 48765
      },
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_json": 475626,
      "exp_type": "polyA",
      "rpkmpolya": {
        "file": "dd_AX4_on_Ka_08Hr_bio1_mapped_expression_rpkm_polya.tab.gz",
        "size": 113974,
        "total_size": 113974
      },
      "feature_type": "gene"
    },
    "scheduled": "2022-03-24T13:25:25.637514+0000",
    "size": 15411806,
    "started": "2022-03-24T13:25:40.424611+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "gff": 387800,
      "mappable": 387852,
      "alignment": 387812
    },
    "process": {
      "created": "2021-02-24T02:23:18.320496+0000",
      "id": 2177,
      "modified": "2021-11-17T06:04:16.445726+0000",
      "is_active": True,
      "category": "Other:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ alignment.bam.file|basename|default('?') }}",
      "description": "Dictyostelium-specific pipeline. Developed by Bioinformatics Laboratory,\nFaculty of Computer and Information Science, University of Ljubljana,\nSlovenia and Shaulsky Lab, Department of Molecular and Human Genetics,\nBaylor College of Medicine, Houston, TX, USA.\n",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "alignment",
          "type": "data:alignment:bam:",
          "label": "Aligned sequence"
        },
        {
          "name": "gff",
          "type": "data:annotation:gff3:",
          "label": "Features (GFF3)"
        },
        {
          "name": "mappable",
          "type": "data:mappability:bcm:",
          "label": "Mappability"
        }
      ],
      "name": "Dictyostelium expressions",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Expression RPKUM (polyA)",
          "description": "mRNA reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkmpolya",
          "type": "basic:file:",
          "label": "Expression RPKM (polyA)",
          "description": "mRNA reads scaled by exon length."
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (polyA)",
          "description": "mRNA reads uniquely mapped to gene exons."
        },
        {
          "name": "rpkum",
          "type": "basic:file:",
          "label": "Expression RPKUM",
          "description": "Reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkm",
          "type": "basic:file:",
          "label": "Expression RPKM",
          "description": "Reads scaled by exon length."
        },
        {
          "name": "rc_raw",
          "type": "basic:file:",
          "label": "Read counts (raw)",
          "description": "Reads uniquely mapped to gene exons."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression RPKUM (polyA) (json)"
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression Type (default output)"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID database"
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species"
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build"
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type"
        }
      ],
      "persistence": "CAC",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/s4q6j6e8/resolwebio/biox:2.0.0"
          }
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "NAME=`basename {{ alignment.bam.file }} .bam`\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}}\nre-checkrc \"Calculation of expression values failed.\"\nre-progress 0.5\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}} --mrna\nre-checkrc \"Calculation of expression values failed.\"\nsamtools idxstats {{ alignment.bam.file }} | cut -f -2 | head -n -1 \u003E chrom.sizes\nre-checkrc \"Samtools idxstats command failed.\"\n\nmv expression_rc.tab.gz ${NAME}_expression_rc.tab.gz\nre-save-file rc_raw ${NAME}_expression_rc.tab.gz\n\nmv expression_rc_polya.tab.gz ${NAME}_expression_rc_polya.tab.gz\nre-save-file rc ${NAME}_expression_rc_polya.tab.gz\n\nmv expression_rpkm.tab.gz ${NAME}_expression_rpkm.tab.gz\nre-save-file rpkm ${NAME}_expression_rpkm.tab.gz\n\nmv expression_rpkm_polya.tab.gz ${NAME}_expression_rpkm_polya.tab.gz\nre-save-file rpkmpolya ${NAME}_expression_rpkm_polya.tab.gz\n\nmv expression_rpkum.tab.gz ${NAME}_expression_rpkum.tab.gz\nre-save-file rpkum ${NAME}_expression_rpkum.tab.gz\n\nmv expression_rpkum_polya.tab.gz ${NAME}_expression_rpkum_polya.tab.gz\nexpression2storage.py ${NAME}_expression_rpkum_polya.tab.gz --output json.txt\nre-checkrc\nre-save exp_json json.txt\nre-save-file exp ${NAME}_expression_rpkum_polya.tab.gz\n\nre-save source {{gff.source}}\nre-save species {{alignment.species}}\nre-save build {{alignment.build}}\nre-save feature_type gene\nre-save exp_type polyA\n",
        "runtime": "polyglot",
        "language": "bash"
      },
      "scheduling_class": "BA",
      "slug": "expression-dicty",
      "type": "data:expression:polya:",
      "version": "1.4.1"
    },
    "collection": {
      "created": "2022-03-22T10:47:57.116905+0000",
      "duplicated": None,
      "id": 2217,
      "modified": "2022-05-17T10:01:35.314628+0000",
      "data_count": 46,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "dictyExpress Parikh A et. al. dataset",
      "name": "D. discoideum, AX4, Parikh et al. 2015 (Growth: K. pneumoniae, Treatment: Filter Development)",
      "settings": {

      },
      "slug": "dictyexpress-discoideum-parikh-et-al",
      "tags": [
        "community:bcm"
      ],
      "entity_count": 14,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-03-23T13:54:19.945740+0000",
      "duplicated": None,
      "id": 66390,
      "modified": "2022-03-23T13:54:21.152696+0000",
      "data_count": 3,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "dd_AX4_on_Ka_08Hr_bio1",
      "settings": {

      },
      "slug": "dd_ax4_on_ka_08hr_bio1fastqgz",
      "tags": [
        "community:bcm"
      ],
      "collection": 2217,
      "type": "sample"
    },
    "name": "?",
    "slug": "data-272",
    "tags": [
      "community:bcm"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "b2247f43d30abfe3fa3f14cfc1119b9d09d9025107155f537e4a0326e518b812",
    "created": "2022-03-24T12:03:13.717193+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-03-24T12:16:13.900136+0000",
    "id": 387857,
    "modified": "2022-03-24T12:03:14.731468+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 16384,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "dd_AX4_on_Ka_08Hr_bio2_mapped_expression_rc_polya.tab.gz",
        "size": 48852,
        "total_size": 48852
      },
      "exp": {
        "file": "dd_AX4_on_Ka_08Hr_bio2_mapped_expression_rpkum_polya.tab.gz",
        "size": 112384,
        "total_size": 112384
      },
      "rpkm": {
        "file": "dd_AX4_on_Ka_08Hr_bio2_mapped_expression_rpkm.tab.gz",
        "size": 111164,
        "total_size": 111164
      },
      "build": "dd-05-13-2009",
      "rpkum": {
        "file": "dd_AX4_on_Ka_08Hr_bio2_mapped_expression_rpkum.tab.gz",
        "size": 112372,
        "total_size": 112372
      },
      "rc_raw": {
        "file": "dd_AX4_on_Ka_08Hr_bio2_mapped_expression_rc.tab.gz",
        "size": 48906,
        "total_size": 48906
      },
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_json": 475602,
      "exp_type": "polyA",
      "rpkmpolya": {
        "file": "dd_AX4_on_Ka_08Hr_bio2_mapped_expression_rpkm_polya.tab.gz",
        "size": 111280,
        "total_size": 111280
      },
      "feature_type": "gene"
    },
    "scheduled": "2022-03-24T12:03:15.163009+0000",
    "size": 15394750,
    "started": "2022-03-24T12:03:41.866452+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "gff": 387800,
      "mappable": 387852,
      "alignment": 387813
    },
    "process": {
      "created": "2021-02-24T02:23:18.320496+0000",
      "id": 2177,
      "modified": "2021-11-17T06:04:16.445726+0000",
      "is_active": True,
      "category": "Other:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ alignment.bam.file|basename|default('?') }}",
      "description": "Dictyostelium-specific pipeline. Developed by Bioinformatics Laboratory,\nFaculty of Computer and Information Science, University of Ljubljana,\nSlovenia and Shaulsky Lab, Department of Molecular and Human Genetics,\nBaylor College of Medicine, Houston, TX, USA.\n",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "alignment",
          "type": "data:alignment:bam:",
          "label": "Aligned sequence"
        },
        {
          "name": "gff",
          "type": "data:annotation:gff3:",
          "label": "Features (GFF3)"
        },
        {
          "name": "mappable",
          "type": "data:mappability:bcm:",
          "label": "Mappability"
        }
      ],
      "name": "Dictyostelium expressions",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Expression RPKUM (polyA)",
          "description": "mRNA reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkmpolya",
          "type": "basic:file:",
          "label": "Expression RPKM (polyA)",
          "description": "mRNA reads scaled by exon length."
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (polyA)",
          "description": "mRNA reads uniquely mapped to gene exons."
        },
        {
          "name": "rpkum",
          "type": "basic:file:",
          "label": "Expression RPKUM",
          "description": "Reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkm",
          "type": "basic:file:",
          "label": "Expression RPKM",
          "description": "Reads scaled by exon length."
        },
        {
          "name": "rc_raw",
          "type": "basic:file:",
          "label": "Read counts (raw)",
          "description": "Reads uniquely mapped to gene exons."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression RPKUM (polyA) (json)"
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression Type (default output)"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID database"
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species"
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build"
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type"
        }
      ],
      "persistence": "CAC",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/s4q6j6e8/resolwebio/biox:2.0.0"
          }
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "NAME=`basename {{ alignment.bam.file }} .bam`\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}}\nre-checkrc \"Calculation of expression values failed.\"\nre-progress 0.5\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}} --mrna\nre-checkrc \"Calculation of expression values failed.\"\nsamtools idxstats {{ alignment.bam.file }} | cut -f -2 | head -n -1 \u003E chrom.sizes\nre-checkrc \"Samtools idxstats command failed.\"\n\nmv expression_rc.tab.gz ${NAME}_expression_rc.tab.gz\nre-save-file rc_raw ${NAME}_expression_rc.tab.gz\n\nmv expression_rc_polya.tab.gz ${NAME}_expression_rc_polya.tab.gz\nre-save-file rc ${NAME}_expression_rc_polya.tab.gz\n\nmv expression_rpkm.tab.gz ${NAME}_expression_rpkm.tab.gz\nre-save-file rpkm ${NAME}_expression_rpkm.tab.gz\n\nmv expression_rpkm_polya.tab.gz ${NAME}_expression_rpkm_polya.tab.gz\nre-save-file rpkmpolya ${NAME}_expression_rpkm_polya.tab.gz\n\nmv expression_rpkum.tab.gz ${NAME}_expression_rpkum.tab.gz\nre-save-file rpkum ${NAME}_expression_rpkum.tab.gz\n\nmv expression_rpkum_polya.tab.gz ${NAME}_expression_rpkum_polya.tab.gz\nexpression2storage.py ${NAME}_expression_rpkum_polya.tab.gz --output json.txt\nre-checkrc\nre-save exp_json json.txt\nre-save-file exp ${NAME}_expression_rpkum_polya.tab.gz\n\nre-save source {{gff.source}}\nre-save species {{alignment.species}}\nre-save build {{alignment.build}}\nre-save feature_type gene\nre-save exp_type polyA\n",
        "runtime": "polyglot",
        "language": "bash"
      },
      "scheduling_class": "BA",
      "slug": "expression-dicty",
      "type": "data:expression:polya:",
      "version": "1.4.1"
    },
    "collection": {
      "created": "2022-03-22T10:47:57.116905+0000",
      "duplicated": None,
      "id": 2217,
      "modified": "2022-05-17T10:01:35.314628+0000",
      "data_count": 46,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "dictyExpress Parikh A et. al. dataset",
      "name": "D. discoideum, AX4, Parikh et al. 2015 (Growth: K. pneumoniae, Treatment: Filter Development)",
      "settings": {

      },
      "slug": "dictyexpress-discoideum-parikh-et-al",
      "tags": [
        "community:bcm"
      ],
      "entity_count": 14,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-03-23T13:55:25.386187+0000",
      "duplicated": None,
      "id": 66391,
      "modified": "2022-03-23T13:55:26.560659+0000",
      "data_count": 3,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "dd_AX4_on_Ka_08Hr_bio2",
      "settings": {

      },
      "slug": "dd_ax4_on_ka_08hr_bio2fastqgz",
      "tags": [
        "community:bcm"
      ],
      "collection": 2217,
      "type": "sample"
    },
    "name": "dd_AX4_on_Ka_08Hr_bio2_mapped.bam",
    "slug": "dd_ax4_on_ka_08hr_bio2_mappedbam",
    "tags": [
      "community:bcm"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "aba8d5c7347b13a62ecafbb3018c9f873b26340daad0ab7743d4af92925ef802",
    "created": "2022-03-24T12:03:12.690833+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-03-24T12:50:44.862075+0000",
    "id": 387856,
    "modified": "2022-03-24T12:37:08.694679+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 16384,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "dd_AX4_on_Ka_04Hr_bio2_mapped_expression_rc_polya.tab.gz",
        "size": 50323,
        "total_size": 50323
      },
      "exp": {
        "file": "dd_AX4_on_Ka_04Hr_bio2_mapped_expression_rpkum_polya.tab.gz",
        "size": 115140,
        "total_size": 115140
      },
      "rpkm": {
        "file": "dd_AX4_on_Ka_04Hr_bio2_mapped_expression_rpkm.tab.gz",
        "size": 114035,
        "total_size": 114035
      },
      "build": "dd-05-13-2009",
      "rpkum": {
        "file": "dd_AX4_on_Ka_04Hr_bio2_mapped_expression_rpkum.tab.gz",
        "size": 114989,
        "total_size": 114989
      },
      "rc_raw": {
        "file": "dd_AX4_on_Ka_04Hr_bio2_mapped_expression_rc.tab.gz",
        "size": 50388,
        "total_size": 50388
      },
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_json": 475610,
      "exp_type": "polyA",
      "rpkmpolya": {
        "file": "dd_AX4_on_Ka_04Hr_bio2_mapped_expression_rpkm_polya.tab.gz",
        "size": 113967,
        "total_size": 113967
      },
      "feature_type": "gene"
    },
    "scheduled": "2022-03-24T12:37:09.050120+0000",
    "size": 15413328,
    "started": "2022-03-24T12:37:27.845579+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "gff": 387800,
      "mappable": 387852,
      "alignment": 387810
    },
    "process": {
      "created": "2021-02-24T02:23:18.320496+0000",
      "id": 2177,
      "modified": "2021-11-17T06:04:16.445726+0000",
      "is_active": True,
      "category": "Other:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ alignment.bam.file|basename|default('?') }}",
      "description": "Dictyostelium-specific pipeline. Developed by Bioinformatics Laboratory,\nFaculty of Computer and Information Science, University of Ljubljana,\nSlovenia and Shaulsky Lab, Department of Molecular and Human Genetics,\nBaylor College of Medicine, Houston, TX, USA.\n",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "alignment",
          "type": "data:alignment:bam:",
          "label": "Aligned sequence"
        },
        {
          "name": "gff",
          "type": "data:annotation:gff3:",
          "label": "Features (GFF3)"
        },
        {
          "name": "mappable",
          "type": "data:mappability:bcm:",
          "label": "Mappability"
        }
      ],
      "name": "Dictyostelium expressions",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Expression RPKUM (polyA)",
          "description": "mRNA reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkmpolya",
          "type": "basic:file:",
          "label": "Expression RPKM (polyA)",
          "description": "mRNA reads scaled by exon length."
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (polyA)",
          "description": "mRNA reads uniquely mapped to gene exons."
        },
        {
          "name": "rpkum",
          "type": "basic:file:",
          "label": "Expression RPKUM",
          "description": "Reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkm",
          "type": "basic:file:",
          "label": "Expression RPKM",
          "description": "Reads scaled by exon length."
        },
        {
          "name": "rc_raw",
          "type": "basic:file:",
          "label": "Read counts (raw)",
          "description": "Reads uniquely mapped to gene exons."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression RPKUM (polyA) (json)"
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression Type (default output)"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID database"
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species"
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build"
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type"
        }
      ],
      "persistence": "CAC",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/s4q6j6e8/resolwebio/biox:2.0.0"
          }
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "NAME=`basename {{ alignment.bam.file }} .bam`\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}}\nre-checkrc \"Calculation of expression values failed.\"\nre-progress 0.5\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}} --mrna\nre-checkrc \"Calculation of expression values failed.\"\nsamtools idxstats {{ alignment.bam.file }} | cut -f -2 | head -n -1 \u003E chrom.sizes\nre-checkrc \"Samtools idxstats command failed.\"\n\nmv expression_rc.tab.gz ${NAME}_expression_rc.tab.gz\nre-save-file rc_raw ${NAME}_expression_rc.tab.gz\n\nmv expression_rc_polya.tab.gz ${NAME}_expression_rc_polya.tab.gz\nre-save-file rc ${NAME}_expression_rc_polya.tab.gz\n\nmv expression_rpkm.tab.gz ${NAME}_expression_rpkm.tab.gz\nre-save-file rpkm ${NAME}_expression_rpkm.tab.gz\n\nmv expression_rpkm_polya.tab.gz ${NAME}_expression_rpkm_polya.tab.gz\nre-save-file rpkmpolya ${NAME}_expression_rpkm_polya.tab.gz\n\nmv expression_rpkum.tab.gz ${NAME}_expression_rpkum.tab.gz\nre-save-file rpkum ${NAME}_expression_rpkum.tab.gz\n\nmv expression_rpkum_polya.tab.gz ${NAME}_expression_rpkum_polya.tab.gz\nexpression2storage.py ${NAME}_expression_rpkum_polya.tab.gz --output json.txt\nre-checkrc\nre-save exp_json json.txt\nre-save-file exp ${NAME}_expression_rpkum_polya.tab.gz\n\nre-save source {{gff.source}}\nre-save species {{alignment.species}}\nre-save build {{alignment.build}}\nre-save feature_type gene\nre-save exp_type polyA\n",
        "runtime": "polyglot",
        "language": "bash"
      },
      "scheduling_class": "BA",
      "slug": "expression-dicty",
      "type": "data:expression:polya:",
      "version": "1.4.1"
    },
    "collection": {
      "created": "2022-03-22T10:47:57.116905+0000",
      "duplicated": None,
      "id": 2217,
      "modified": "2022-05-17T10:01:35.314628+0000",
      "data_count": 46,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "dictyExpress Parikh A et. al. dataset",
      "name": "D. discoideum, AX4, Parikh et al. 2015 (Growth: K. pneumoniae, Treatment: Filter Development)",
      "settings": {

      },
      "slug": "dictyexpress-discoideum-parikh-et-al",
      "tags": [
        "community:bcm"
      ],
      "entity_count": 14,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-03-23T13:51:57.383181+0000",
      "duplicated": None,
      "id": 66389,
      "modified": "2022-03-23T13:51:58.498320+0000",
      "data_count": 3,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "dd_AX4_on_Ka_04Hr_bio2",
      "settings": {

      },
      "slug": "dd_ax4_on_ka_04hr_bio2fastqgz",
      "tags": [
        "community:bcm"
      ],
      "collection": 2217,
      "type": "sample"
    },
    "name": "?",
    "slug": "data-271",
    "tags": [
      "community:bcm"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "486c498d2c561a8a4904441bc336b444096ec997a8b0e81673df01646cca9b37",
    "created": "2022-03-24T12:03:12.689406+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-03-24T12:17:03.055420+0000",
    "id": 387855,
    "modified": "2022-03-24T12:03:13.247542+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 16384,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "dd_AX4_on_Ka_00Hr_bio2_mapped_expression_rc_polya.tab.gz",
        "size": 45252,
        "total_size": 45252
      },
      "exp": {
        "file": "dd_AX4_on_Ka_00Hr_bio2_mapped_expression_rpkum_polya.tab.gz",
        "size": 103443,
        "total_size": 103443
      },
      "rpkm": {
        "file": "dd_AX4_on_Ka_00Hr_bio2_mapped_expression_rpkm.tab.gz",
        "size": 101982,
        "total_size": 101982
      },
      "build": "dd-05-13-2009",
      "rpkum": {
        "file": "dd_AX4_on_Ka_00Hr_bio2_mapped_expression_rpkum.tab.gz",
        "size": 103434,
        "total_size": 103434
      },
      "rc_raw": {
        "file": "dd_AX4_on_Ka_00Hr_bio2_mapped_expression_rc.tab.gz",
        "size": 45319,
        "total_size": 45319
      },
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_json": 475603,
      "exp_type": "polyA",
      "rpkmpolya": {
        "file": "dd_AX4_on_Ka_00Hr_bio2_mapped_expression_rpkm_polya.tab.gz",
        "size": 101903,
        "total_size": 101903
      },
      "feature_type": "gene"
    },
    "scheduled": "2022-03-24T12:03:13.705518+0000",
    "size": 15337905,
    "started": "2022-03-24T12:03:34.374406+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "gff": 387800,
      "mappable": 387852,
      "alignment": 387808
    },
    "process": {
      "created": "2021-02-24T02:23:18.320496+0000",
      "id": 2177,
      "modified": "2021-11-17T06:04:16.445726+0000",
      "is_active": True,
      "category": "Other:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ alignment.bam.file|basename|default('?') }}",
      "description": "Dictyostelium-specific pipeline. Developed by Bioinformatics Laboratory,\nFaculty of Computer and Information Science, University of Ljubljana,\nSlovenia and Shaulsky Lab, Department of Molecular and Human Genetics,\nBaylor College of Medicine, Houston, TX, USA.\n",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "alignment",
          "type": "data:alignment:bam:",
          "label": "Aligned sequence"
        },
        {
          "name": "gff",
          "type": "data:annotation:gff3:",
          "label": "Features (GFF3)"
        },
        {
          "name": "mappable",
          "type": "data:mappability:bcm:",
          "label": "Mappability"
        }
      ],
      "name": "Dictyostelium expressions",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Expression RPKUM (polyA)",
          "description": "mRNA reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkmpolya",
          "type": "basic:file:",
          "label": "Expression RPKM (polyA)",
          "description": "mRNA reads scaled by exon length."
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (polyA)",
          "description": "mRNA reads uniquely mapped to gene exons."
        },
        {
          "name": "rpkum",
          "type": "basic:file:",
          "label": "Expression RPKUM",
          "description": "Reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkm",
          "type": "basic:file:",
          "label": "Expression RPKM",
          "description": "Reads scaled by exon length."
        },
        {
          "name": "rc_raw",
          "type": "basic:file:",
          "label": "Read counts (raw)",
          "description": "Reads uniquely mapped to gene exons."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression RPKUM (polyA) (json)"
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression Type (default output)"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID database"
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species"
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build"
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type"
        }
      ],
      "persistence": "CAC",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/s4q6j6e8/resolwebio/biox:2.0.0"
          }
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "NAME=`basename {{ alignment.bam.file }} .bam`\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}}\nre-checkrc \"Calculation of expression values failed.\"\nre-progress 0.5\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}} --mrna\nre-checkrc \"Calculation of expression values failed.\"\nsamtools idxstats {{ alignment.bam.file }} | cut -f -2 | head -n -1 \u003E chrom.sizes\nre-checkrc \"Samtools idxstats command failed.\"\n\nmv expression_rc.tab.gz ${NAME}_expression_rc.tab.gz\nre-save-file rc_raw ${NAME}_expression_rc.tab.gz\n\nmv expression_rc_polya.tab.gz ${NAME}_expression_rc_polya.tab.gz\nre-save-file rc ${NAME}_expression_rc_polya.tab.gz\n\nmv expression_rpkm.tab.gz ${NAME}_expression_rpkm.tab.gz\nre-save-file rpkm ${NAME}_expression_rpkm.tab.gz\n\nmv expression_rpkm_polya.tab.gz ${NAME}_expression_rpkm_polya.tab.gz\nre-save-file rpkmpolya ${NAME}_expression_rpkm_polya.tab.gz\n\nmv expression_rpkum.tab.gz ${NAME}_expression_rpkum.tab.gz\nre-save-file rpkum ${NAME}_expression_rpkum.tab.gz\n\nmv expression_rpkum_polya.tab.gz ${NAME}_expression_rpkum_polya.tab.gz\nexpression2storage.py ${NAME}_expression_rpkum_polya.tab.gz --output json.txt\nre-checkrc\nre-save exp_json json.txt\nre-save-file exp ${NAME}_expression_rpkum_polya.tab.gz\n\nre-save source {{gff.source}}\nre-save species {{alignment.species}}\nre-save build {{alignment.build}}\nre-save feature_type gene\nre-save exp_type polyA\n",
        "runtime": "polyglot",
        "language": "bash"
      },
      "scheduling_class": "BA",
      "slug": "expression-dicty",
      "type": "data:expression:polya:",
      "version": "1.4.1"
    },
    "collection": {
      "created": "2022-03-22T10:47:57.116905+0000",
      "duplicated": None,
      "id": 2217,
      "modified": "2022-05-17T10:01:35.314628+0000",
      "data_count": 46,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "dictyExpress Parikh A et. al. dataset",
      "name": "D. discoideum, AX4, Parikh et al. 2015 (Growth: K. pneumoniae, Treatment: Filter Development)",
      "settings": {

      },
      "slug": "dictyexpress-discoideum-parikh-et-al",
      "tags": [
        "community:bcm"
      ],
      "entity_count": 14,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-03-23T13:47:15.294770+0000",
      "duplicated": None,
      "id": 66387,
      "modified": "2022-03-23T13:47:16.556012+0000",
      "data_count": 3,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "dd_AX4_on_Ka_00Hr_bio2",
      "settings": {

      },
      "slug": "dd_ax4_on_ka_00hr_bio2fastqgz",
      "tags": [
        "community:bcm"
      ],
      "collection": 2217,
      "type": "sample"
    },
    "name": "dd_AX4_on_Ka_00Hr_bio2_mapped.bam",
    "slug": "dd_ax4_on_ka_00hr_bio2_mappedbam",
    "tags": [
      "community:bcm"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "9e46524bebca9c7dca27a4e1a3aaf74edf37eb5caef44a4d5e33352eb0f1f6bd",
    "created": "2022-03-24T12:03:12.687829+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-03-24T12:17:46.151335+0000",
    "id": 387854,
    "modified": "2022-03-24T12:03:13.251730+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 16384,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "dd_AX4_on_Ka_04Hr_bio1_mapped_expression_rc_polya.tab.gz",
        "size": 47345,
        "total_size": 47345
      },
      "exp": {
        "file": "dd_AX4_on_Ka_04Hr_bio1_mapped_expression_rpkum_polya.tab.gz",
        "size": 109505,
        "total_size": 109505
      },
      "rpkm": {
        "file": "dd_AX4_on_Ka_04Hr_bio1_mapped_expression_rpkm.tab.gz",
        "size": 108253,
        "total_size": 108253
      },
      "build": "dd-05-13-2009",
      "rpkum": {
        "file": "dd_AX4_on_Ka_04Hr_bio1_mapped_expression_rpkum.tab.gz",
        "size": 109915,
        "total_size": 109915
      },
      "rc_raw": {
        "file": "dd_AX4_on_Ka_04Hr_bio1_mapped_expression_rc.tab.gz",
        "size": 47405,
        "total_size": 47405
      },
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_json": 475605,
      "exp_type": "polyA",
      "rpkmpolya": {
        "file": "dd_AX4_on_Ka_04Hr_bio1_mapped_expression_rpkm_polya.tab.gz",
        "size": 108119,
        "total_size": 108119
      },
      "feature_type": "gene"
    },
    "scheduled": "2022-03-24T12:03:13.613738+0000",
    "size": 15376967,
    "started": "2022-03-24T12:03:35.125754+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "gff": 387800,
      "mappable": 387852,
      "alignment": 387809
    },
    "process": {
      "created": "2021-02-24T02:23:18.320496+0000",
      "id": 2177,
      "modified": "2021-11-17T06:04:16.445726+0000",
      "is_active": True,
      "category": "Other:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ alignment.bam.file|basename|default('?') }}",
      "description": "Dictyostelium-specific pipeline. Developed by Bioinformatics Laboratory,\nFaculty of Computer and Information Science, University of Ljubljana,\nSlovenia and Shaulsky Lab, Department of Molecular and Human Genetics,\nBaylor College of Medicine, Houston, TX, USA.\n",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "alignment",
          "type": "data:alignment:bam:",
          "label": "Aligned sequence"
        },
        {
          "name": "gff",
          "type": "data:annotation:gff3:",
          "label": "Features (GFF3)"
        },
        {
          "name": "mappable",
          "type": "data:mappability:bcm:",
          "label": "Mappability"
        }
      ],
      "name": "Dictyostelium expressions",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Expression RPKUM (polyA)",
          "description": "mRNA reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkmpolya",
          "type": "basic:file:",
          "label": "Expression RPKM (polyA)",
          "description": "mRNA reads scaled by exon length."
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (polyA)",
          "description": "mRNA reads uniquely mapped to gene exons."
        },
        {
          "name": "rpkum",
          "type": "basic:file:",
          "label": "Expression RPKUM",
          "description": "Reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkm",
          "type": "basic:file:",
          "label": "Expression RPKM",
          "description": "Reads scaled by exon length."
        },
        {
          "name": "rc_raw",
          "type": "basic:file:",
          "label": "Read counts (raw)",
          "description": "Reads uniquely mapped to gene exons."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression RPKUM (polyA) (json)"
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression Type (default output)"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID database"
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species"
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build"
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type"
        }
      ],
      "persistence": "CAC",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/s4q6j6e8/resolwebio/biox:2.0.0"
          }
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "NAME=`basename {{ alignment.bam.file }} .bam`\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}}\nre-checkrc \"Calculation of expression values failed.\"\nre-progress 0.5\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}} --mrna\nre-checkrc \"Calculation of expression values failed.\"\nsamtools idxstats {{ alignment.bam.file }} | cut -f -2 | head -n -1 \u003E chrom.sizes\nre-checkrc \"Samtools idxstats command failed.\"\n\nmv expression_rc.tab.gz ${NAME}_expression_rc.tab.gz\nre-save-file rc_raw ${NAME}_expression_rc.tab.gz\n\nmv expression_rc_polya.tab.gz ${NAME}_expression_rc_polya.tab.gz\nre-save-file rc ${NAME}_expression_rc_polya.tab.gz\n\nmv expression_rpkm.tab.gz ${NAME}_expression_rpkm.tab.gz\nre-save-file rpkm ${NAME}_expression_rpkm.tab.gz\n\nmv expression_rpkm_polya.tab.gz ${NAME}_expression_rpkm_polya.tab.gz\nre-save-file rpkmpolya ${NAME}_expression_rpkm_polya.tab.gz\n\nmv expression_rpkum.tab.gz ${NAME}_expression_rpkum.tab.gz\nre-save-file rpkum ${NAME}_expression_rpkum.tab.gz\n\nmv expression_rpkum_polya.tab.gz ${NAME}_expression_rpkum_polya.tab.gz\nexpression2storage.py ${NAME}_expression_rpkum_polya.tab.gz --output json.txt\nre-checkrc\nre-save exp_json json.txt\nre-save-file exp ${NAME}_expression_rpkum_polya.tab.gz\n\nre-save source {{gff.source}}\nre-save species {{alignment.species}}\nre-save build {{alignment.build}}\nre-save feature_type gene\nre-save exp_type polyA\n",
        "runtime": "polyglot",
        "language": "bash"
      },
      "scheduling_class": "BA",
      "slug": "expression-dicty",
      "type": "data:expression:polya:",
      "version": "1.4.1"
    },
    "collection": {
      "created": "2022-03-22T10:47:57.116905+0000",
      "duplicated": None,
      "id": 2217,
      "modified": "2022-05-17T10:01:35.314628+0000",
      "data_count": 46,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "dictyExpress Parikh A et. al. dataset",
      "name": "D. discoideum, AX4, Parikh et al. 2015 (Growth: K. pneumoniae, Treatment: Filter Development)",
      "settings": {

      },
      "slug": "dictyexpress-discoideum-parikh-et-al",
      "tags": [
        "community:bcm"
      ],
      "entity_count": 14,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-03-23T13:49:25.684447+0000",
      "duplicated": None,
      "id": 66388,
      "modified": "2022-03-23T13:49:26.858831+0000",
      "data_count": 3,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "dd_AX4_on_Ka_04Hr_bio1",
      "settings": {

      },
      "slug": "dd_ax4_on_ka_04hr_bio1fastqgz",
      "tags": [
        "community:bcm"
      ],
      "collection": 2217,
      "type": "sample"
    },
    "name": "dd_AX4_on_Ka_04Hr_bio1_mapped.bam",
    "slug": "dd_ax4_on_ka_04hr_bio1_mappedbam",
    "tags": [
      "community:bcm"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
    "checksum": "1b4dfae4d7dd28d1d018b25c655c401f95ea745d6cea8191be1ef1820ec516cd",
    "created": "2022-03-24T12:03:12.686715+0000",
    "descriptor_dirty": False,
    "duplicated": None,
    "finished": "2022-03-24T12:17:37.021716+0000",
    "id": 387853,
    "modified": "2022-03-24T12:03:13.211799+0000",
    "process_cores": 1,
    "process_error": [],
    "process_info": [],
    "process_memory": 16384,
    "process_progress": 100,
    "process_rc": None,
    "process_warning": [],
    "output": {
      "rc": {
        "file": "dd_AX4_on_Ka_00Hr_bio1_mapped_expression_rc_polya.tab.gz",
        "size": 46293,
        "total_size": 46293
      },
      "exp": {
        "file": "dd_AX4_on_Ka_00Hr_bio1_mapped_expression_rpkum_polya.tab.gz",
        "size": 105264,
        "total_size": 105264
      },
      "rpkm": {
        "file": "dd_AX4_on_Ka_00Hr_bio1_mapped_expression_rpkm.tab.gz",
        "size": 103842,
        "total_size": 103842
      },
      "build": "dd-05-13-2009",
      "rpkum": {
        "file": "dd_AX4_on_Ka_00Hr_bio1_mapped_expression_rpkum.tab.gz",
        "size": 105299,
        "total_size": 105299
      },
      "rc_raw": {
        "file": "dd_AX4_on_Ka_00Hr_bio1_mapped_expression_rc.tab.gz",
        "size": 46357,
        "total_size": 46357
      },
      "source": "DICTYBASE",
      "species": "Dictyostelium discoideum",
      "exp_json": 475604,
      "exp_type": "polyA",
      "rpkmpolya": {
        "file": "dd_AX4_on_Ka_00Hr_bio1_mapped_expression_rpkm_polya.tab.gz",
        "size": 103917,
        "total_size": 103917
      },
      "feature_type": "gene"
    },
    "scheduled": "2022-03-24T12:03:13.674474+0000",
    "size": 15350678,
    "started": "2022-03-24T12:03:40.576694+0000",
    "status": "OK",
    "contributor": {
      "first_name": "Janez",
      "id": 3,
      "last_name": "Kokosar",
      "username": "janez@genialis.com"
    },
    "input": {
      "gff": 387800,
      "mappable": 387852,
      "alignment": 387811
    },
    "process": {
      "created": "2021-02-24T02:23:18.320496+0000",
      "id": 2177,
      "modified": "2021-11-17T06:04:16.445726+0000",
      "is_active": True,
      "category": "Other:",
      "contributor": {
        "first_name": "Adi",
        "id": 2,
        "last_name": "Genialis",
        "username": "admin"
      },
      "data_name": "{{ alignment.bam.file|basename|default('?') }}",
      "description": "Dictyostelium-specific pipeline. Developed by Bioinformatics Laboratory,\nFaculty of Computer and Information Science, University of Ljubljana,\nSlovenia and Shaulsky Lab, Department of Molecular and Human Genetics,\nBaylor College of Medicine, Houston, TX, USA.\n",
      "entity_always_create": False,
      "entity_input": None,
      "entity_type": "sample",
      "input_schema": [
        {
          "name": "alignment",
          "type": "data:alignment:bam:",
          "label": "Aligned sequence"
        },
        {
          "name": "gff",
          "type": "data:annotation:gff3:",
          "label": "Features (GFF3)"
        },
        {
          "name": "mappable",
          "type": "data:mappability:bcm:",
          "label": "Mappability"
        }
      ],
      "name": "Dictyostelium expressions",
      "output_schema": [
        {
          "name": "exp",
          "type": "basic:file:",
          "label": "Expression RPKUM (polyA)",
          "description": "mRNA reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkmpolya",
          "type": "basic:file:",
          "label": "Expression RPKM (polyA)",
          "description": "mRNA reads scaled by exon length."
        },
        {
          "name": "rc",
          "type": "basic:file:",
          "label": "Read counts (polyA)",
          "description": "mRNA reads uniquely mapped to gene exons."
        },
        {
          "name": "rpkum",
          "type": "basic:file:",
          "label": "Expression RPKUM",
          "description": "Reads scaled by uniquely mappable part of exons."
        },
        {
          "name": "rpkm",
          "type": "basic:file:",
          "label": "Expression RPKM",
          "description": "Reads scaled by exon length."
        },
        {
          "name": "rc_raw",
          "type": "basic:file:",
          "label": "Read counts (raw)",
          "description": "Reads uniquely mapped to gene exons."
        },
        {
          "name": "exp_json",
          "type": "basic:json:",
          "label": "Expression RPKUM (polyA) (json)"
        },
        {
          "name": "exp_type",
          "type": "basic:string:",
          "label": "Expression Type (default output)"
        },
        {
          "name": "source",
          "type": "basic:string:",
          "label": "Gene ID database"
        },
        {
          "name": "species",
          "type": "basic:string:",
          "label": "Species"
        },
        {
          "name": "build",
          "type": "basic:string:",
          "label": "Build"
        },
        {
          "name": "feature_type",
          "type": "basic:string:",
          "label": "Feature type"
        }
      ],
      "persistence": "CAC",
      "requirements": {
        "executor": {
          "docker": {
            "image": "public.ecr.aws/s4q6j6e8/resolwebio/biox:2.0.0"
          }
        },
        "expression-engine": "jinja"
      },
      "run": {
        "program": "NAME=`basename {{ alignment.bam.file }} .bam`\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}}\nre-checkrc \"Calculation of expression values failed.\"\nre-progress 0.5\n\nxexpression.py {{ gff.annot.file }} {{ alignment.bam.file }} --rc --rpkm --rpkum {{mappable.mappability.file}} --mrna\nre-checkrc \"Calculation of expression values failed.\"\nsamtools idxstats {{ alignment.bam.file }} | cut -f -2 | head -n -1 \u003E chrom.sizes\nre-checkrc \"Samtools idxstats command failed.\"\n\nmv expression_rc.tab.gz ${NAME}_expression_rc.tab.gz\nre-save-file rc_raw ${NAME}_expression_rc.tab.gz\n\nmv expression_rc_polya.tab.gz ${NAME}_expression_rc_polya.tab.gz\nre-save-file rc ${NAME}_expression_rc_polya.tab.gz\n\nmv expression_rpkm.tab.gz ${NAME}_expression_rpkm.tab.gz\nre-save-file rpkm ${NAME}_expression_rpkm.tab.gz\n\nmv expression_rpkm_polya.tab.gz ${NAME}_expression_rpkm_polya.tab.gz\nre-save-file rpkmpolya ${NAME}_expression_rpkm_polya.tab.gz\n\nmv expression_rpkum.tab.gz ${NAME}_expression_rpkum.tab.gz\nre-save-file rpkum ${NAME}_expression_rpkum.tab.gz\n\nmv expression_rpkum_polya.tab.gz ${NAME}_expression_rpkum_polya.tab.gz\nexpression2storage.py ${NAME}_expression_rpkum_polya.tab.gz --output json.txt\nre-checkrc\nre-save exp_json json.txt\nre-save-file exp ${NAME}_expression_rpkum_polya.tab.gz\n\nre-save source {{gff.source}}\nre-save species {{alignment.species}}\nre-save build {{alignment.build}}\nre-save feature_type gene\nre-save exp_type polyA\n",
        "runtime": "polyglot",
        "language": "bash"
      },
      "scheduling_class": "BA",
      "slug": "expression-dicty",
      "type": "data:expression:polya:",
      "version": "1.4.1"
    },
    "collection": {
      "created": "2022-03-22T10:47:57.116905+0000",
      "duplicated": None,
      "id": 2217,
      "modified": "2022-05-17T10:01:35.314628+0000",
      "data_count": 46,
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "dictyExpress Parikh A et. al. dataset",
      "name": "D. discoideum, AX4, Parikh et al. 2015 (Growth: K. pneumoniae, Treatment: Filter Development)",
      "settings": {

      },
      "slug": "dictyexpress-discoideum-parikh-et-al",
      "tags": [
        "community:bcm"
      ],
      "entity_count": 14,
      "descriptor": {

      },
      "descriptor_schema": None,
      "descriptor_dirty": False
    },
    "descriptor": {

    },
    "descriptor_schema": None,
    "entity": {
      "created": "2022-03-23T13:46:19.596200+0000",
      "duplicated": None,
      "id": 66386,
      "modified": "2022-03-23T13:46:20.876269+0000",
      "data_count": 3,
      "status": "OK",
      "contributor": {
        "first_name": "Janez",
        "id": 3,
        "last_name": "Kokosar",
        "username": "janez@genialis.com"
      },
      "description": "",
      "name": "dd_AX4_on_Ka_00Hr_bio1",
      "settings": {

      },
      "slug": "dd_ax4_on_ka_00hr_bio1fastqgz-2",
      "tags": [
        "community:bcm"
      ],
      "collection": 2217,
      "type": "sample"
    },
    "name": "dd_AX4_on_Ka_00Hr_bio1_mapped.bam",
    "slug": "dd_ax4_on_ka_00hr_bio1_mappedbam",
    "tags": [
      "community:bcm"
    ],
    "process_resources": {

    },
    "current_user_permissions": [
      {
        "type": "public",
        "permissions": [
          "view"
        ]
      }
    ]
  },
  {
        "checksum": "4b5223dadda6c1c8980431af246cba3aef1a0957901b519655e329cfd1f343ef",
        "created": "2022-03-24T13:09:09.971603+0000",
        "descriptor_dirty": False,
        "duplicated": None,
        "finished": "2022-03-24T13:09:41.698203+0000",
        "id": 387925,
        "modified": "2022-03-25T10:32:22.411885+0000",
        "process_cores": 1,
        "process_error": [],
        "process_info": [],
        "process_memory": 16384,
        "process_progress": 100,
        "process_rc": None,
        "process_warning": [],
        "output": {
            "raw": {
                "file": "Dd-prespore-prestalk.tab.gz",
                "size": 567291,
                "total_size": 567291
            },
            "build": "dd-05-13-2009",
            "source": "DICTYBASE",
            "de_file": {
                "file": "de_file.tab.gz",
                "size": 178494,
                "total_size": 178494
            },
            "de_json": 475617,
            "species": "Dictyostelium discoideum",
            "feature_type": "gene"
        },
        "scheduled": "2022-03-24T13:09:10.766965+0000",
        "size": 1311834,
        "started": "2022-03-24T13:09:29.698976+0000",
        "status": "OK",
        "contributor": {
            "first_name": "Janez",
            "id": 3,
            "last_name": "Kokosar",
            "username": "janez@genialis.com"
        },
        "input": {
            "fdr": "ebays.pval",
            "src": {
                "file": "Dd-prespore-prestalk.tab.gz",
                "file_temp": "https://genialis-prod-app-upload-us-east-1.s3.amazonaws.com/e3d4f2b54d5125ddda46d179ff801e6dd2e9cb37?response-content-disposition=inline&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIA6JSS2MQCXGFXT6UO%2F20220324%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220324T130909Z&X-Amz-Expires=604800&X-Amz-SignedHeaders=host&X-Amz-Security-Token=FwoGZXIvYXdzEOf%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaDK%2F7cT5lKUbDsF6N7yLIAWA%2Bop1NioYtPmtm21A%2BzNbUySdyEIzeupgBDj%2BuaWMf6%2BXNgQnBSQ2RnUEadKKxw9pFM0zFx7af7ls9xkIiG7JS24tXSsGmwWNaEymVjgIy7qPmyDf8HzCz0n%2BzmmnWHmsv72I%2F4QmhvNMupyvIP%2FiA22cb6j23ZXdZVh4TQrIMWB%2FnyahJYNt1zmzlNuR03ECpHDo1LaNJh5%2BDVpkU6bQK5HlUzzLOLbEsn7i0GblInwhs4aVNL33Ngvh5rY9R30CYNVl4eFUaKPXa8ZEGMi0t6IduPOfEBXkC4M%2FnksmfO4%2BZnxJPg%2FJ5jJP0LT0Pg3bvSz632D5m7wA0Cs8%3D&X-Amz-Signature=4332c9e22ed905c01020e17a1054becdaa910439cfca3263454fd42f9c113592"
            },
            "case": [
                387853
            ],
            "build": "dd-05-13-2009",
            "logfc": "paired_avg_FC",
            "source": "DICTYBASE",
            "control": [
                387855
            ],
            "gene_id": "ddb_g",
            "species": "Dictyostelium discoideum",
            "feature_type": "gene"
        },
        "process": {
            "created": "2022-02-16T00:06:30.216544+0000",
            "id": 2599,
            "modified": "2022-02-16T00:06:30.216563+0000",
            "is_active": True,
            "category": "Import:",
            "contributor": {
                "first_name": "Adi",
                "id": 2,
                "last_name": "Genialis",
                "username": "admin"
            },
            "data_name": "Differential expression ({{ src.file }})",
            "description": "Upload Differential Expression table.\n",
            "entity_always_create": False,
            "entity_input": None,
            "entity_type": None,
            "input_schema": [
                {
                    "name": "src",
                    "type": "basic:file:",
                    "label": "Differential expression file",
                    "description": "Differential expression file. Supported file types: *.xls, *.xlsx, *.tab (tab-delimited file), *.diff. DE file must include columns with log2(fold change) and FDR or pval information. DE file must contain header row with column names. Accepts DESeq, DESeq2, edgeR and CuffDiff output files.\n",
                    "validate_regex": "\\.(xls|xlsx|tab|tab.gz|diff|diff.gz)$"
                },
                {
                    "name": "gene_id",
                    "type": "basic:string:",
                    "label": "Gene ID label"
                },
                {
                    "name": "logfc",
                    "type": "basic:string:",
                    "label": "LogFC label"
                },
                {
                    "name": "fdr",
                    "type": "basic:string:",
                    "label": "FDR label",
                    "required": False
                },
                {
                    "name": "logodds",
                    "type": "basic:string:",
                    "label": "LogOdds label",
                    "required": False
                },
                {
                    "name": "fwer",
                    "type": "basic:string:",
                    "label": "FWER label",
                    "required": False
                },
                {
                    "name": "pvalue",
                    "type": "basic:string:",
                    "label": "Pvalue label",
                    "required": False
                },
                {
                    "name": "stat",
                    "type": "basic:string:",
                    "label": "Statistics label",
                    "required": False
                },
                {
                    "name": "source",
                    "type": "basic:string:",
                    "label": "Gene ID database",
                    "choices": [
                        {
                            "label": "AFFY",
                            "value": "AFFY"
                        },
                        {
                            "label": "DICTYBASE",
                            "value": "DICTYBASE"
                        },
                        {
                            "label": "ENSEMBL",
                            "value": "ENSEMBL"
                        },
                        {
                            "label": "NCBI",
                            "value": "NCBI"
                        },
                        {
                            "label": "UCSC",
                            "value": "UCSC"
                        }
                    ],
                    "allow_custom_choice": True
                },
                {
                    "name": "species",
                    "type": "basic:string:",
                    "label": "Species",
                    "choices": [
                        {
                            "label": "Homo sapiens",
                            "value": "Homo sapiens"
                        },
                        {
                            "label": "Mus musculus",
                            "value": "Mus musculus"
                        },
                        {
                            "label": "Rattus norvegicus",
                            "value": "Rattus norvegicus"
                        },
                        {
                            "label": "Dictyostelium discoideum",
                            "value": "Dictyostelium discoideum"
                        },
                        {
                            "label": "Odocoileus virginianus texanus",
                            "value": "Odocoileus virginianus texanus"
                        },
                        {
                            "label": "Solanum tuberosum",
                            "value": "Solanum tuberosum"
                        }
                    ],
                    "description": "Species latin name.\n",
                    "allow_custom_choice": True
                },
                {
                    "name": "build",
                    "type": "basic:string:",
                    "label": "Build",
                    "description": "Genome build or annotation version.\n"
                },
                {
                    "name": "feature_type",
                    "type": "basic:string:",
                    "label": "Feature type",
                    "choices": [
                        {
                            "label": "gene",
                            "value": "gene"
                        },
                        {
                            "label": "transcript",
                            "value": "transcript"
                        },
                        {
                            "label": "exon",
                            "value": "exon"
                        }
                    ],
                    "default": "gene"
                },
                {
                    "name": "case",
                    "type": "list:data:expression:",
                    "label": "Case",
                    "required": False,
                    "description": "Case samples (replicates)\n"
                },
                {
                    "name": "control",
                    "type": "list:data:expression:",
                    "label": "Control",
                    "required": False,
                    "description": "Control samples (replicates)\n"
                }
            ],
            "name": "Differential Expression (table)",
            "output_schema": [
                {
                    "name": "raw",
                    "type": "basic:file:",
                    "label": "Differential expression"
                },
                {
                    "name": "de_json",
                    "type": "basic:json:",
                    "label": "Results table (JSON)"
                },
                {
                    "name": "de_file",
                    "type": "basic:file:",
                    "label": "Results table (file)"
                },
                {
                    "name": "source",
                    "type": "basic:string:",
                    "label": "Gene ID database"
                },
                {
                    "name": "species",
                    "type": "basic:string:",
                    "label": "Species"
                },
                {
                    "name": "build",
                    "type": "basic:string:",
                    "label": "Build"
                },
                {
                    "name": "feature_type",
                    "type": "basic:string:",
                    "label": "Feature type"
                }
            ],
            "persistence": "RAW",
            "requirements": {
                "executor": {
                    "docker": {
                        "image": "public.ecr.aws/s4q6j6e8/resolwebio/common:3.0.0"
                    }
                },
                "resources": {
                    "network": True
                },
                "expression-engine": "jinja"
            },
            "run": {
                "program": "NAME={{ src.file }}\n\n{% if case and not control or control and not case %}\n  re-error \"Both case and control sample groups need to be provided\"\n{% endif %}\n\nGENE_ID='{% if gene_id %} --gene_id {{gene_id}} {% endif %}'\nLOGFC='{% if logfc %} --logfc {{logfc}} {% endif %}'\nFDR='{% if fdr %} --fdr {{fdr}} {% endif %}'\nLOGODDS='{% if logodds %} --logodds {{logodds}} {% endif %}'\nFWER='{% if fwer %} --fwer {{fwer}} {% endif %}'\nPVALUE='{% if pvalue %} --pvalue {{pvalue}} {% endif %}'\nSTAT='{% if stat %} --stat {{stat}} {% endif %}'\n\nif [[ '.{{ src.file }}' =~ \\.(xls)$ ]]; then\n  re-import {{ src.file_temp }} {{ src.file }} \"xls\" \"xls\" 0.3 extract\n  convert_DE_excel_table.py {{ src.file }} > \"${NAME}.tab\"\n  parse_diffexp.py ${NAME}.tab de_data.json de_file.tab.gz ${GENE_ID} ${LOGFC} ${FDR} ${LOGODDS} ${FWER} ${PVALUE} ${STAT}\n  re-checkrc\n  re-progress 0.7\n  gzip \"${NAME}.tab\"\nelif [[ '.{{ src.file }}' =~ \\.(xlsx)$ ]]; then\n  re-import {{ src.file_temp }} {{ src.file }} \"xlsx\" \"xlsx\" 0.3 extract\n  convert_DE_excel_table.py {{ src.file }} > \"${NAME}.tab\"\n  parse_diffexp.py ${NAME}.tab de_data.json de_file.tab.gz ${GENE_ID} ${LOGFC} ${FDR} ${LOGODDS} ${FWER} ${PVALUE} ${STAT}\n  re-checkrc\n  re-progress 0.7\n  gzip \"${NAME}.tab\"\nelse\n  re-import {{ src.file_temp }} {{ src.file }} \"diff|tab|gz\" \"tab\" 0.3\n  parse_diffexp.py ${NAME}.tab de_data.json de_file.tab.gz ${GENE_ID} ${LOGFC} ${FDR} ${LOGODDS} ${FWER} ${PVALUE} ${STAT}\n  re-checkrc\n  re-progress 0.7\n  gzip \"${NAME}.tab\"\nfi\nre-save-file raw ${NAME}.tab.gz\nre-save-file de_file de_file.tab.gz\nre-save de_json de_data.json\nre-save source {{ source }}\nre-save species {{ species }}\nre-save build {{ build }}\nre-save feature_type {{ feature_type }}\n",
                "runtime": "polyglot",
                "language": "bash"
            },
            "scheduling_class": "BA",
            "slug": "upload-diffexp",
            "type": "data:differentialexpression:upload:",
            "version": "1.5.0"
        },
        "collection": {
            "created": "2022-03-22T10:47:57.116905+0000",
            "duplicated": None,
            "id": 2217,
            "modified": "2022-05-17T10:01:35.314628+0000",
            "data_count": 46,
            "contributor": {
                "first_name": "Janez",
                "id": 3,
                "last_name": "Kokosar",
                "username": "janez@genialis.com"
            },
            "description": "dictyExpress Parikh A et. al. dataset",
            "name": "D. discoideum, AX4, Parikh et al. 2015 (Growth: K. pneumoniae, Treatment: Filter Development)",
            "settings": {},
            "slug": "dictyexpress-discoideum-parikh-et-al",
            "tags": [
                "community:bcm"
            ],
            "entity_count": 14,
            "descriptor": {},
            "descriptor_schema": None,
            "descriptor_dirty": False
        },
        "descriptor": {
            "case_label": "prespore",
            "thresholds": {
                "prob": 0.05,
                "logfc": 1,
                "prob_field": "fdr"
            },
            "control_label": "prestalk"
        },
        "descriptor_schema": {
            "created": "2017-06-28T14:23:34.527290+0000",
            "id": 31,
            "modified": "2021-11-17T06:04:12.203097+0000",
            "contributor": {
                "first_name": "Adi",
                "id": 2,
                "last_name": "Genialis",
                "username": "admin"
            },
            "version": "0.0.1",
            "description": "Differential expression details template",
            "name": "Differential expression details",
            "schema": [
                {
                    "name": "thresholds",
                    "group": [
                        {
                            "name": "logfc",
                            "type": "basic:decimal:",
                            "label": "Log2 FC",
                            "default": 1
                        },
                        {
                            "name": "prob",
                            "type": "basic:decimal:",
                            "label": "Probability",
                            "default": 0.05
                        },
                        {
                            "name": "prob_field",
                            "type": "basic:string:",
                            "label": "Probability field",
                            "choices": [
                                {
                                    "label": "fdr",
                                    "value": "fdr"
                                },
                                {
                                    "label": "fwer",
                                    "value": "fwer"
                                },
                                {
                                    "label": "pvalue",
                                    "value": "pvalue"
                                },
                                {
                                    "label": "logodds",
                                    "value": "logodds"
                                }
                            ],
                            "default": "fdr"
                        }
                    ],
                    "label": "thresholds"
                },
                {
                    "name": "case_label",
                    "type": "basic:text:",
                    "label": "Case label"
                },
                {
                    "name": "control_label",
                    "type": "basic:text:",
                    "label": "Control label"
                },
                {
                    "name": "description",
                    "type": "basic:text:",
                    "label": "Description",
                    "required": False
                }
            ],
            "slug": "diff-exp"
        },
        "entity": None,
        "name": "D. discoideum (prespore vs. prestalk)",
        "slug": "d-discoideum-prespore-vs-prestalk",
        "tags": [
            "community:bcm"
        ],
        "process_resources": {},
        "current_user_permissions": [
            {
                "type": "public",
                "permissions": [
                    "view"
                ]
            }
        ]
    },
    
]